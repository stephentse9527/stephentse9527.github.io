[{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"服务主要情况\n机器情况\n\n\n\n服务名称\n是否有整体限流\n单机qps(限流qps)\n服务器数量\n总体qps上限\n当前qps\n非缓存qps\n\n\n\ndz-rank\n是\n单机15\n28\n420\n120\n120\n\n\ndz-phoenix\n是\n单机200\n12\n2400\n600\n\n\n\n架构概览\n\n\n店长推荐引擎主要分为几个模块，从一次请求的链路流程来说的话，会有AB平台，召回引擎、统一过滤服务、特征平台、排序服务、干预服务、样本采集模块\n对于每个请求，首先都会过一遍AB实验平台，根据这个请求的一些信息，userid、所在业务线，来在AB平台的策略池中获取推荐策略，得到推荐策略之后，接下来会进行召回，召回指的是从海量的数据集当中快速圈出来一小部分用户可能感兴趣的数据，而具体的召回策略是通过从上一步的AB实验平台中拿到的配置中去解析属于召回的那一部分，解析出来的配置其实是一组插件，每个插件会表示这个召回从哪个数据源中获取数据，并且它的获取策略，也可以叫做query参数是什么，所以对于\n推荐引擎架构\n![当前店长推荐系统整体流程图 (1)的副本2](项目细节/当前店长推荐系统整体流程图 (1)的副本2.png)\n整体架构\n\n\n![索引数据同步流程 (1)](项目细节/索引数据同步流程 (1).png)\ndz es\n\n\n牛人索引\ndz_es\n\n\n20个分片， 5个主分片，每个分片有三个副本分片\nBz_es\n\n\n20个分片， 5个主分片，每个分片有三个副本分片\n12台机器\n","slug":"项目细节","date":"2022-09-15T14:22:17.576Z","categories_index":"","tags_index":"","author_index":"谢华客"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"好的确\n面试官你好，我叫谢华客，在2021年毕业于郑州轻工业大学计算机科学与技术专业，作为一个开发人员，我的常用语言是java，毕业之后， 我加入了BOSS zp担任推荐系统开发工程师，主要负责推荐系统的开发和维护，这也是我这一年主要开发的项目，项目的技术选型是使用Java作为开发语言，springboot作为整个项目的脚手架，使用远程通信框架dubbo作为服务之间的互相调用、底层数据使用mysql存储，并搭建es倒排索引来提供数据召回、使用kafka进行样本打印、监控数据上报、使用redis作为特征kv存储的载体和推荐数据的翻页缓存以及不可变数据的存储，所以在工作和日常学习中，我对spring、redis、kafka、es、reids等中间件都有了一定的理解和实践，同时我参与的项目是一个C端产品，对高并发和高可用的架构有一定要求，所以我自己也有了一些高并发和高可用知识，所以我相信这些理论知识和实践经验可以帮助我在下一份工作中更加快速的上手和产出。\n","slug":"自我介绍（待优化）","date":"2022-09-15T14:22:17.564Z","categories_index":"","tags_index":"","author_index":"谢华客"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"toodlist\n\n linux command\n Net\n jvm\n srping\n springboot\n redis\n kafka\n suanfa\n es\n project\n net\n advent\n juc\n youhua\n Mysql\n\n","slug":"todolist-review","date":"2022-09-15T14:22:17.560Z","categories_index":"","tags_index":"","author_index":"谢华客"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"面试官你好，我叫谢华客，21年毕业，有一年多的Java开发经验，目前是在BOSS直聘担任推荐系统工程师，主要负责推荐系统的开发维护和需求迭代，我的主要开发语言是Java，在工作过程中，我积累了对现阶段互联网常用中间件的使用经验，比如SpringBoot、kafka redis es double等等，也对这些中间件的原理有一定的理解。同时也有对高可用高并发的项目开发的实践经验。在工作和日常的时间中，我也学习过一些常用工具类的源码，如集合类源码和多线程并发包的常用API源码，这对我的编程能力也有很大的帮助，所以我相信我可以胜任目前应聘的这岗位所需要做的工作。\n","slug":"中文自我介绍","date":"2022-09-15T14:22:17.560Z","categories_index":"","tags_index":"","author_index":"谢华客"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"命令 retransform使用命令 retransform可以替换指定的.class文件，做到快速生效更改的代码\n操作步骤\n本地编辑好代码后，构建编译代码\n\n使用如下命令转换class文件为base64，保存到txt中\nbase64 &lt; Test.class > result.txt\n到服务器上，新建并编辑result.txt，复制本地的内容，粘贴再保存\n\n把服务器上的 result.txt还原为.class\n base64 -d &lt; result.txt &gt; Test.class\n\n替换\n retransform /tmp/MathGame.class\n\n\n\nretransform的限制\n不允许新增加field/method\n\n正在跑的函数，没有退出不能生效，比如下面新增加的System.out.println，只有run()函数里的会生效\n\n\n查看并清除retransform的影响查看：retransform -l\n删除指定retransform ：retransform -d 1\n删除所有：retransform --deleteAll\n\n","slug":"使用arthas快速替换代码","date":"2022-09-15T14:22:17.560Z","categories_index":"","tags_index":"","author_index":"谢华客"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"1、什么是 Spring Boot？\nSpring Boot 主要是简化了使用 Spring 的难度，提供了各种启动器、引入JavaConfig来减省了繁重的xml配置，开发者能快速上手，并且内置了web服务，不需要而外启动tomcat服务器\n\n\n2、为什么要用 Spring Boot？\n独立运行spring 项目。Springboot可以以jar包的形式直接运行，节省服务器资源\n提供starter，简化maven配置\n自动配置Spring：Spring Boot会根据项目依赖来自动配置Spring 框架，极大地减少项目要使用的配置\n包含Spring所有特性和优点，包括IOC容器自动管理Bean生命周期、依赖注入等\n\n3、Spring Boot 的核心配置文件有哪几个？它们的区别是什么？一共有\n\nbootstrap (.yml 或者 .properties)\napplication (.yml 或者 .properties)\n\n区别\n\n bootstrap 加载的优先级比 applicaton 高\n应用场景：application 配置文件这个容易理解，主要用于 Spring Boot 项目的自动化配置，bootstrap 主要用于从额外的资源来加载配置信息，还可以在本地外部配置文件中解密属性\n\n4、Spring Boot 的配置文件有哪几种格式？它们有什么区别？\nyml或者properties\nproperties每个属性都要写全名，而yml可以共用前缀，严格按照缩进形式\nyml 不支持通过@PeopertySource注解来倒入配置\n\n5、Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？\nSpringBootApplication注解\n通常在启动类上面，表明这是一个SpringBoot程序，并且会自动装配必要的配置，并且它是一个组合注解，组合中比较重要的有SpringBootConfiguration、EnableAutoConfiguration\n\nSpringBootConfiguration，本质上是一个Configuration注解，Configuration注解的作用搭配注解Bean来使用，是一个JavaConfig，会将带有Bean注解的方法返回的实例注入到IOC容器中\n\nComponentScan：Bean自动扫描，会扫描制定路径下的被@Componet、@Controller @Servicer @Repatriy注解的类，生成实例注入IOC容器中\n\n\n6、开启 Spring Boot 特性有哪几种方式？\n继承spring-boot-starter-parent项目\n导入spring-boot-dependencies项目依赖\n\n7、Spring Boot 需要独立的容器运行吗？\n不需要，其内置了tomcat，打包的时候是jar包的形式，可以直接运行\n\n8、运行 Spring Boot 有哪几种方式？\n打包jar包，打包war包\n\n9、Spring Boot 自动配置原理是什么？\nSpring Boot的自动配置注解是@EnableAutoConfiguration，它被组合在@SpringBootApplication中，在EnableAutoConfiguration中，使用@Import注解注入了一个AutoConfigurationImportSelector，这个类实现了ImportSelector接口，而ImportSelector接口有一个方法selectImports，在AutoConfigurationImportSelector这个类实现的逻辑中，会去引入的每个starter包下面的`MATE-INF/spring.factories下，读取保存的配置类文件，然后进行Bean的去重、剔除@exclution注解包含的Bean，然后就可以把所有外部引入的bean信息返回，然后根据Bean的conditional注解来判断是否可以加载这个Bean到IOC容器中，这样就完成了自动装配\n\n10、Spring Boot 的目录结构是怎样的？11、你如何理解 Spring Boot 中的 Starters？12、如何在 Spring Boot 启动的时候运行一些特定的代码？\n实现applicationRuner或者commendLineRunner接口\n\n13、Spring Boot 有哪几种读取配置的方式？​    三种\n\n@Value注解\n\n@ConfigurationProperties\n\n注入Environment类\n\n\n14、Spring Boot 支持哪些日志框架？推荐和默认的日志框架是哪个？15、SpringBoot 实现热部署有哪几种方式？16、你如何理解 Spring Boot 配置加载顺序？\n同目录层级下Perproties &gt; yml\n目录之间的关系\n根目录下的config &gt; 根目录 &gt; resource下的config &gt; resource\n\n\n也可以通过–spring.config.name 或者是sping.config.location来指定自定义的目录和文件名\n\n17、Spring Boot 如何定义多套不同环境配置？\nApplication.properties文件名中加上后缀prod prion dev 然后在启动参数添加spirng.profile.active来选择对应环境参数\n\n18、Spring Boot 可以兼容老 Spring 项目吗，如何做？19、保护 Spring Boot 应用有哪些方法？20、Spring Boot 2.X 有什么新特性？与 1.X 有什么区别？21、springboot和springcloud区别\nSpring Boot 是 Spring 的⼀套快速配置脚⼿架，可以基于Spring Boot 快速开发单个微服务，Spring Cloud是一个基于Spring Boot实现的云应⽤开发⼯具；\nSpring Boot专注于快速、⽅便集成的单个微服务个体，Spring Cloud关注全局的服务治理框架\n\n22.eureka和zookeeper都可以提供服务的注册与发现功能，他们的区别23.springcloud如何实现服务的注册和发现\n服务再部署时，会将自己注册到eureka或者zookeeper注册中心上去，完成注册流程，同一个服务名如果部署多个实例，而服务在调用其他服务的方法通过远程调用的形式，从服务中心中获取可用的实例列表，然后通过负载均衡算法选出一个实例，将自己的参数序列化，然后传递给远程服务，远程服务则在响应请求时，反序列化参数，然后调用内部方法，获得结果后将结果序列化返回给客户端。\n\n24.SpringBoot启动流程\n首先从main找到run()方法，在执行run()方法之前new一个SpringApplication对象\n进入run()方法，创建应用监听器SpringApplicationRunListeners开始监听\n然后加载SpringBoot配置环境(ConfigurableEnvironment)，然后把配置环境(Environment)加入监听对象中\n然后加载应用上下文(ConfigurableApplicationContext)，当做run方法的返回对象\n最后创建Spring容器，refreshContext(context)，实现starter自动化配置和bean的实例化等工作。\n\n25.Spring 事务Spring的事物隔离级别和数据库是一至的，同样有读未提交、读已提交，可重复读、可串行化这几个，\n如果spring配置的事务和数据库不一致，则根据spirngwei\n","slug":"springboot面试题","date":"2022-09-15T14:22:17.556Z","categories_index":"","tags_index":"","author_index":"谢华客"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"ES相关知识点倒排表执行过程\n\n切词：wod segmentation，把一句话切成一个一个的term\n\n规范化：normalization 把动词介词和相同词的不同形态统一或者过滤\n\n去重：distinct \n\n字典序：sorted\n\n\nTerm dictionary \nterm index\nposition list \n","slug":"es相关知识点","date":"2022-09-15T14:22:17.544Z","categories_index":"","tags_index":"","author_index":"谢华客"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new \"My New Post\"\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-09-15T14:22:17.544Z","categories_index":"","tags_index":"","author_index":"谢华客"},{"id":"b38e006a0ed784a6f0bb2ad5154dba4f","title":"JVM优化总结","content":"JVM优化总结前置知识-元空间的知识元空间内存分配规则Metaspace 空间被分配在本地内存中(非堆上)，默认不限制内存使用，可以使用 MaxMetaspaceSize 指定最大值。MetaspaceSize 指定最小值，默认 21 M，在元空间申请的内存会分成一个一个的 Matachunk，以Matachunk为单位分配给类加载器，每个 Metachunk 对应唯一一个类加载器，一个类加载器可以有多个 Metachunk\n\nused: chunk 中已经使用的 block 内存，这些 block 中都加载了类的数据。\ncapacity：在使用的 chunk 内存。\ncommited：所有分配的 chunk 内存，这里包含空闲可以再次被利用的。\nreserved：是可以使用的内存大小\n\n元空间出发Full GC时机参数 MinMetaspaceFreeRatio，默认40，也就是40%，\n案例一个关于JVM 元空间mataspace OOM的优化实例，服务频繁出现FULL GC\n解决过程\n\n打开了GC日志，然后发现GC日志当中\n元空间使用信息中，capacity比use多出来很多，说明分配了很多chunk，占用了很多空间，但是却没有完全使用它\n所以推断出mataspace中应该是碎片化了\n因为chunk分配是根据类加载器来分配的，所以只用那三个类加载器一般是不会出现碎片化的，所以初步定位为有大量的自定义类加载器加载了一堆类进来\n\n所以dump jvm内存下来，然后观察Objects使用较高的元素，排除Java内部的那些常见类之后，发现一个叫做DelegatingClassLoader数量特别高，然后再分析是谁引用了这个类加载器\n\n 然后发现是因为反射调用method的方法引用的，所以呢就初步判定了是反射造成的\n\n最后发现，原来是Method类中，invoke方法里面会有一个优化，指的是有一个膨胀阈值，为15，当发现一个类中的方法被调用超过阈值15次时，会做一个优化，会使用字节码的形式，为这个方法去定义出一个类，这个类的类加载器叫做DelegatingClassLoader，所以创建了大量的类加载器\n\n最后在定位到代码上，发现我们需要传递上下文对象到一个排序rank引擎中给召回item做一次精排打分，需要把上下文对象做一次转换，所以大量使用了BeanUtils.copy…的方法，找个方法里面就是通过invoke对象的getSet方法来做属性赋值的，所以问题就定位到了\n\n\n","slug":"jvm优化总结","date":"2022-05-29T17:00:48.000Z","categories_index":"","tags_index":"Java,JVM","author_index":"谢华客"},{"id":"9fe79a5e2d58fcbcba8e87cdea7a0f13","title":"Spring笔记","content":"Spring笔记Spring核心要点\n控制反转IOC：使用Spring之前，对象的使用和创建是绑定在一起的，除了主要的逻辑代码外，还需要为依赖的其他对象做很多复杂的创建工作，引入了Spring之后，就可以将创建和使用分离开，把对象的创建工作交由Spring框架来进行处理，需要用到的时候从Spring的容器中获取即可\n面向切面AOP：不同业务模块的解耦\n\n控制反转IOC配置方式\nXML、JavaConfig\n注解配置：@Component、@Controller、@Service、@Repository\n\n依赖注入的方式\n构造方法注入（Construct注入），\nsetter注入\n基于注解的注入（接口注入）\n@Autowired：根据Type类型，c出现多个就根据name来匹配\n\n\n\nSpring MVC一个基于MVC模式设计的轻量级web 框架\nSpring MVC请求流程\n\n\n首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行 处理，作为统一访问点，进行全局的流程控制；进入DispatcherServlet之前还会有Filter，可以做preFilter以及postFilter\nDispatcherServlet——&gt;HandlerMapping， HandlerMapping 将会把请求映射为 HandlerExecutionChain 对象（包含一 个Handler 处理器（页面控制器）对象、多个HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新的映射策略；目的：获得请求映射到的handler处理器以及拦截器\nDispatcherServlet——&gt;HandlerAdapter，HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器， 即适配器设计模式的应用，从而很容易支持很多类型的处理器；\nHandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处 理方法，完成功能处理；并返回一个ModelAndView 对象（包含模型数据、逻辑视图名）；\nModelAndView 的逻辑视图名——&gt; ViewResolver，ViewResolver 将把逻辑视图名解析为具体的View，通过这种策 略模式，很容易更换其他视图技术；\nView——&gt;渲染，View 会根据传进来的Model 模型数据进行渲染，此处的Model 实际是一个Map 数据结构，因此 很容易支持其他视图技术；\n返回控制权给DispatcherServlet，由DispatcherServlet 返回响应给用户，到此一个流程结束。\n\nSpring IOC实现原理Spring顶层设计围绕BeanFactory和BeanRegistry来进行\n\nBeanFactory：工厂模式定义了IOC容器的基本功能规范\nBeanRegistry： 向IOC容器手工注册 BeanDefinition 对象的方法\n\nBeanDefinition：各种Bean对象及其相互的关系Bean对象存在依赖嵌套等关系，所以设计者设计了BeanDefinition，它用来对Bean对象及关系定义；我们在理解时只需要抓住如下三个要点\n\nBeanDefinition 定义了各种Bean对象及其相互的关系\n\n BeanDefinitionReader 这是BeanDefinition的解析器\n\n BeanDefinitionHolder 这是BeanDefination的包装类，用来存储BeanDefinition，name以及aliases等\n\n\nIOC初始化流程\n\n\n首先定位资源文件，通过ResourceLoader来完成资源文件的定位，并将其抽象成Resource对象\n接下来就是解析资源文件，通过 BeanDefinitionReader来完成定义信息的解析获取Bean的定义信息\n获取到BeanDefinition后，需要将其注册到IOC容器中，这由 IOC 实现 BeanDefinitionRegistry 接口来实现。注册过程就是在 IOC 容器内部维护的一个HashMap 来保存得到的 BeanDefinition 的过程。这个 HashMap 是 IoC 容器持有 bean 信息的场所，以后对 bean 的操作都是围绕这个HashMap 来实现的.\n\nBean实例化从定义信息中将BeanDefinition信息注册到IOC容器中后，只是保存了Bean信息，使用这些Bean的话还需要去进行Bean的实例化\nSpring容器初始化\n创建IOC容器也就是创建一个ApplicationContext接口的实现类，\n\n\nSpring容器初始化时，会调用 refresh() 刷新IOC容器\nrefresh 里面先调用 prepareRefresh() ，记录容器启动时间，标记已启动状态\n接下来会进入obtainFreshBeanFactory() 先重置BeanFactory，获得该BeanFactory对象\n接下来使用loadBeanDefinitions，将Bean的元信息存放到BeanDefinition当中\n获得BeanFactory后，进入prepareBeanFacotry为获得的BeanFacotory设置属性\n这时候所有的Bean定义已经加载完成，但是都没实例化，这一步可以去修改bean 的定义或者增加Bean的定义\n接下来会如果bean没有设置懒加载，就会加载这些单例bean\n\nSpringBean的生命周期\n当要获取一个bean时，会调用getBean方法，实际的逻辑在doGetBean当中，首先会调用getSingleton方法，尝试从一级二级三级缓存中获取bean\n\n创建实例：如果都没有，就会调用createBean方法来创建bean，通过beanDefinition获取bean 的信息，创建出一个原始对象，并将这个Bean的创建工厂放到三级缓存中\n\n属性注入：接下来进行属性注入，初始化bean，把值和Bean的引用注入进Bean对应的属性中\n\n执行Aware方法：执行Aware将在初始化前如果bean实现了Aware接口，就会执行这些Aware方法\n\nBefore-init：如果Bean实现了BeanPostProcessor，执行postProcessbeforeInitialization，相当于初始化前的操作\n\ninit：如果Bean实现了InitializingBean，执行InitializingBean的afterPropertiesSet方法，相当于初始化Bean\n\nAfter-init：同样，如果实现了BeanPostProcess，就执行BeanPostProcessor的postProcessAfterInitialization方法，而将原始对象变成代理对象是发生在BeanPostProcessor的postProcessAfterInitialization中的wrapIfNecessary方法中\n\nprotected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123;\n   if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123;\n      return bean;\n   &#125;\n   if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123;\n      return bean;\n   &#125;\n   if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123;\n      this.advisedBeans.put(cacheKey, Boolean.FALSE);\n      return bean;\n   &#125;\n\n   // Create proxy if we have advice.\n   Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);\n   if (specificInterceptors != DO_NOT_PROXY) &#123;\n      this.advisedBeans.put(cacheKey, Boolean.TRUE);\n      Object proxy = createProxy(\n            bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));\n      this.proxyTypes.put(cacheKey, proxy.getClass());\n      return proxy;\n   &#125;\n\n   this.advisedBeans.put(cacheKey, Boolean.FALSE);\n   return bean;\n&#125;\n\n\n最后把完整的对象放进一级缓存中，同时删除其他缓存\n\n\nSpring解决循环依赖的问题\n当要获取一个bean时，会调用getBean方法，实际的逻辑在doGetBean当中，首先会调用getSingleton方法，尝试从一级二级三级缓存中获取bean\n如果都没有，就会调用createBean方法来创建bean，通过beanDefinition获取bean 的信息，创建出一个原始对象，并将它放到三级缓存当中，三级缓存是以beanname做为key，创建工厂执行函数作为value的map\n当进行populaBean属性注入时，发现依赖B，就会去走getBean那一套，直到进行属性注入，这时候会发现A在三级缓存中已经有了，所以从三级缓存中拿出A的创建工厂，获得A的实例，B就顺利创建完成\n而回到A这边B也创建好了，只需要进行后面的初始化就可以了，然后将bean从二级缓存中放到一级缓存\n\n为什么要三级缓存解决循环依赖如果单纯解决循环依赖，不需要第三级缓存，只需要一个缓存（三级缓存）即可\n而如果A进行了AOP操作的话，生成代理对象是在属性注入之后，如果发生循环依赖，在B的创建过程中获取A就需要提前获取到A的代理对象，而不是A的原始对象，所以要有第三个Map，来存放singletonFactory，在B中提前获得A的代理对象，这样B中注入的对象才会是和最后A的对象是一致的\n为什么只有一级缓存是ConcHashMap，其他是普通Map因为二级缓存和三级缓存的put操作都会伴随着另一个的删除操作，要保证这两个操作的原子性，如果直接使用两个concmap，不能保证原子性，所以在对应的方法里面都是使用的sync关键字来直接加锁\n","slug":"spring笔记","date":"2022-05-21T12:37:38.000Z","categories_index":"","tags_index":"","author_index":"谢华客"},{"id":"eaecd65a22befc3caf0b52e72c0ff526","title":"kafka笔记","content":"Kafka笔记工作中有大量的kafka使用场景，学习记录一下kafka的架构和原理\n为什么要引入消息队列\n各个组件间的解藕\n流程之间的异步处理\n流量控制\n\n核心概念\nBroker：broker指的就是一个kafka服务器\nProducer：消息生产者，就是向broker发送消息的客户端\nConsumer：消息消费者，向kafka borker拉取消息的客户端\nConsumer group：消费者组，由多个消费者组成，不同组通过group id进行区分，一条消息只能被一个组里面的某个消费者消费，但是不同组之间可以同时消费一条消息，换句话来说消费者组是逻辑上的一个订阅者\ntopic：主题队列，可以理解为一个存放特定消息的队列\npartition：一个topic可以分布在不同的broker上，用不同partition表示，这是为了方便拓展和提高并发\n拓展：一个topic可以有多个partition，所以可以通过拓展partition也就是拓展机器来应付增长的数量\n提高并发：不是以topic为读写单位，而是已partition为读写单位，可以多个消费者组并发消费数据，提高消息的处理效率\n\n\n\nKafka消息存储分区(partition)对于一个topic，可以将数据分散存储在多个服务器上，每一部分称为一个分区(partition)，通过参数num.partition 来进行控制，默认为1，\n分区结构分区设计：分段+索引的结构设计，一个分区由多个段组成\n\n\n\nSegment：文件段\n.log：日志文体，在kafka中把数据文件就叫做日志文件，\n.index/.：位移索引\n.timeindex：时间戳索引\n\npartition 全局的第一个 segment 从 0 开始，后续每个 segment 文件名为上一个segment 文件最后一条消息的 offset 值。数值大小为 64 位，20 位数字字符长度，没有数字用 0 填充\nkafka在写入日志文件时，同时会维护索引文件，在往日志文件中写入了一定量的数据后，就会往索引文件中写入一条索引，所以索引本身是稀疏格式的索引，索引文件里的数据是按照位移和时间戳升序排序的，所以kafka在查找索引的时候，会用二分查找，时间复杂度是O(logN)，找到索引，就可以在.log文件里定位到数据了，如下图所示，[1, 3, 4, 8…]表示消息在segment的index, [0, 348, 476…]表示数据在磁盘中的物理偏移地址。\n索引文件中 [3, 348] , 3 在 .log 文件中表示第 3 个消息，那么在全局 partition 表中表示为 160420 + 3 = 160423。\n\n\n\n参数 log.index.interval.bytes 控制写入多少量的日志后添加索引，默认值为4KB\n\nKafka生产者生产者发送消息流程\n\n\n分区器partitionor假设知道了要发往哪个分区，一般情况下，kafka都是以集群的形式部署的，而写入操作是会写到leader节点上的，那怎么知道哪个broker上的分区是这个分区的leader呢，使用的是partitionor分区器，来获取kafka集群的元数据，从而知道哪个是leader partition\n分区的计算生产者需要把一个batch的消息发送到Topic的某个partition中，那到底发送到哪个分区中呢，这个是和消息的key和分区器有关的，\n\n默认分区器(DefaultPartitioner)\n当没有给消息设置key时，消息会以带有粘性的随机的形式发送到下一个分区中\n也可以给消息指定一个key，会根据key计算出hash值，然后对分区数取余，这样可以保证同样的key肯定会发送到同一个分区上\n\n\n轮询分区器(RoundRobinPartitioner) ：字面意思，以轮询的形式，获取该topic的下一个分区进行发送\n根据业务自定义自己的分区器：实现接口Partitioner，并在初始化生产者时，把自己的实现类放进参数map中的partitioner.class即可\n\n缓冲区kafka并不会立即将消息发送出去，而是包装成RecordBatch，放入缓冲区BufferPool中\n\n缓存区的模型和内存和其他细节，打算放在kafka源码阅读笔记中\n\nSender发送时机先了解两个参数\n\nlinger.ms：发送延迟时间，默认0\nbatch.size：每个RecordBatch的最大容量，默认：16384，16K\n\n为减少负载和客户端的请求数量，生产者不会一条一条发送，而是会逗留一段时间批量发送。batch.size和linger.ms满足任何一个条件都会发送\n生产者投递消息的可靠性为了能保证kafka生产者能够尽最大可能的不丢失发送的数据，kafka加入了ack确认机制，这涉及到两个重要的参数\n\nacks：acks确认机制\nvalue=0，表示生产者在消息写入之前不会等待来自服务器的任何应答，一旦消息发送失败，生产者无法感知到\nvalue=1（默认），表示生产者只要接收到partition leader的ack确认，就认为消息写入成功了，如果写入失败，会收到错误的响应，会重新发送消息\nvalue=all，表示生产者只有自接收到partition leader和partition的ISR列表所有的从节点\n\n\n\n高并发网络架构kafka能支持超大并发的请求，有很大的功劳来自于kakfa基于Reactor 事件处理设计模式的超高并发网络架构\n\n\nAcceptor 线程在Reactor网络设计模式中，会有一个Dispatcher模块用来接收各种请求并请求分发给对应的handler，而Acceptor线程就起到Dispatcher的作用。\n在kafka broker中只会创建一个Acceptor线程用来创建连接，并将接收到的请求放到到Processor线程中去进行处理，所以Acceptor线程做的工作非常轻量\nProcess 线程真正创建网络连接以及分发网络请求是由 Processor 线程来完成的，每个Process线程在创建时都会创建三个队列\n\nnewConnections 队列: 它主要是用来保存要创建的新连接信息，也就是SocketChannel 对象，队列长度大小为20。每当 Processor 线程接收到新的连接请求时，都会将对应的 SocketChannel 对象放入队列，等到后面创建连接时，从该队列中获取 SocketChannel，然后注册新的连接。\nResponseQueue 队列：它主要是存放需要返回给Request 发送方的所有 Response 对象。每个 Processor 线程都会维护自己的 Response 队列\ninflightResponse 队列：它是一个临时的 Response 队列， 当 Processor 线程将 Repsonse 返回给 Client 之后，要将 Response 放入该队列。它存在的意义：由于有些 Response callback要在 Response 被发送回 Request 发送方后，才能执行，因此需要暂存到临时队列\n\nKafkaRequestHandler 线程而具体的读写IO请求是由KafkaRequestHandler来进行处理的，默认会有8个KafkaRequestHandler被维护在 RequestHandlerPool中，通过参数num.io.threads来控制\n请求处理流程\n客户端、其他broker请求连接都会被Acceptor线程接管\nAcceptor线程在首次初始化时，会创建出Java NIO Selector、ServerSocketChannel，并将ServerSocketChannel的OP_ACCPECT事件注册到Selector上，并创建默认3个processor线程，可以由num.network.threads控制\nAcceptor会不断的将连接请求SocketChannel放入到 Processor线程中的newConnections队列中\n\n\nProcessor 线程源源不断的从newConnections队列中poll SocketChannel，并将其OP_WRITE/OP_READ事件注册到Selector中\n这样客户端就可以源源不断的发送请求了，而processor线程就不断通过Selector获取到就绪的IO事件，构建 Request 对象并放入Requestchannel中的 RequestQueue中\nKafkaRequestHandler 线程会不断的从RequestQueue 队列中获取请求，然后处理逻辑，比如读写消息，处理完成后，将结果包装成 Response ，放入ResponseQueue 中\n最后 Processor 线程通过 Request 中的 ProcessorID 不停地从 Response 队列中来定位并取出 Response 对象，返回结果\n\nKafka消费者offset每个消费者都在内存中保存着对topic分区的消费offset，定期会提交offset，会往__consumer_offsets这个kafka内部topic提交，key为group.id+topic+分区号， value为对应的offset\n每隔一段时间，kafka会对相同key对offset进行合并，只保留最大的那个offset\n\nKafka 0.8版本之前offset是保存在zk上的，之后才是保存在本地内存中\n\n从哪开始消费offset就是用来控制当消费者应该从分区中的哪里进行消费的，如果当前分区没有该group.id的offset时，同时受另一个参数auto.offset.reset的影响\n\nearliest：无提交的offset时，从头开始消费\nlatest：无提交的offset时，消费新产生的数据\nnone：没有提交的offset时，抛出异常\n\n消费者组消费者是以 consumer group 消费者组的方式工作，由一个或者多个消费者组成一个组， 共同消费一个 topic。每个分区在同一时间只能由 group 中的一个消费者读取，但是多个 group 可以同时消费这个 partition。\n\n\nCoordinator一个消费者组中哪个消费者消费哪几个partition，也就是分区分配策略，以及如果某些消费者挂了应该怎么重新分配其消费的分区等待问题，需要有统一的管理，而这由Coordinator来实现\n每个consumer group都会选择一个broker作为自己的coordinator，他是负责监控这个消费组里的各个消费者的心跳，以及判断是否宕机，然后开启rebalance的\n如何选择Coordinator首先对groupId进行hash，接着对_consumer_offsets的分区数量取模，默认是50，_consumer_offsets的分区数可以通过offsets.topic.num.partitions来设置，找到分区以后，这个分区所在的broker机器就是coordinator机器\n消费方案的确定流程\n每个consumer都发送 join-group请求到Coordinator\n然后Coordinator从consumer group中选择第一个成功加入Group的consumer作为leader\n具体的消费策略是由leader consumer来制定的，所以Coordinator把consumer group情况发送给这个leader\nCoordinator会给所有发送join-group的consumer发送response，consumer收到Coordinator的response后，如果是leader，就会将具体的消费策略发送给Coordinator，而其他follower则发送一个空列表\n接着Coordinator就把消费方案下发给各个consumer，他们会从指定的分区的 leader broker 开始进行socket连接以及消费消息\n\n分区分配策略\nRange：按照范围依次给各个消费者均匀的分配消费分区\n\n\n缺点：同一个组内的消费者消费的分区可能差距很大，如下图所示\n\nround-robin轮询分配：按顺序一个一个的分配给消费者，直到分配完成\n\n\n\nrange和轮询都有一个缺点，就是在某个消费者挂了之后，重新分配消费分区可能会导致原本自己消费的分区被分给了其他消费者，相当于丢失了分区，比如当consumerA挂了，对于range来说，partition0~3会分配给consumerB，4～6会分配给consumerC，这导致了B丢失了原本消费的partition4，同理，对于round-robin来说B丢失了分区1，C丢失了分区2\n\n\nsticky：sticky策略在rebalance的时候，会在保持原有消费的分区的情况下，再把多余的分区均匀的分配给剩下的消费者\n\n\nKafka高可用、高性能机制高可⽤性(High Availability)，指系统无间断地执⾏其功能的能力，代表系统的可⽤性程度。Kafka从0.8版本开始提供了高可⽤机制， 可保障⼀个或多个Broker宕机后，其他Broker及所有Partition都能继续提供服务，且存储的消息不丢失。所以kafka使用多机备份和消息应答机制\n多机备份多机备份指的是对于某个partition，可以存在多个副本，副本由一个leader和多个fllower组成，消息的写入只会写入到leader中\n高可用机制","slug":"kafka笔记","date":"2022-04-05T23:26:59.000Z","categories_index":"","tags_index":"中间件,kafka,原理","author_index":"谢华客"},{"id":"3a0a2a0a822e5f2cb6d51229a61d0c76","title":"线程池原理","content":"线程池原理","slug":"线程池原理","date":"2021-06-26T11:16:08.000Z","categories_index":"","tags_index":"并发编程","author_index":"谢华客"},{"id":"8aa5caddac1db643c41479b403f9dcc5","title":"Scurm笔记","content":"Scurm笔记Scurm是一个敏捷开发框架，是一个增量的、迭代的开发过程，在这个框架中，整个开发周期包括若干个小的迭代周期，\n称为Sprint,每个Sprint的建议周期在2～4周，使用BackLog    来管理产品或者项目的需求\n\nbacklog是一个案子中商业价值排序的需求列表，Scrum的开发团队总是先开发对客户具有较高价值的需求\n然后在每个Sprint中，通过Sprint计划会议上的分析、讨论、估算获得Sprint任务列表，叫做Spirnt backlog，在每个迭代结束时，团队将交付潜在可交付的产品增量\n\nScurm术语\nSprint：冲刺，指的是一个迭代周期\nBacklog：代办列表，等待认领或者开发的任务列表\nProduct Backlog：产品代办列表，一般指产品需求列表\nUser Story: 用户故事，指一条需求，一个功能点\nStroy Point: 衡量User Story工作量的计量单位，一般为天/小时\nProduct Own：产品负责人，PO，产品经理\nSprint Task：实现一条需求需要做的一个技术任务\n\nScurm开发流程\n使用产品backlog (Product Backlog)来管理有商业价值的需求列表\n将整个开发周期分为若干个小的开发周期，每个小的开发周期称为Sprint，而每个Sprint包含一部分需求，这个需求称为Sprint Backlog.而spirnt中的需求通过Sprint 计划会议上的分析、讨论、估算得到，然后交由Scurm Team开发，每个Sprint结束后，Scurm Team将交付潜在可交付的产品增量。\n\nScurm重要概念反应健康状况的两个工具\nBacklog\nSprint-Burm-Down Chart(Sprint燃尽图)、Release-Burm-Down Chart(发布燃尽图)\n\n三种角色\nProduct Owner 产品经理\nScurm Master 项目经理\nScurm Team 开发团队\n\n四种会议\nSprint Planning Meeting 计划会议\nSprint计划会议有两部分：\n\n决定需要完成哪些工作：产品负责人（Product Owner）向开发团队介绍排好序的产品待办事项，由整个Scrum团队共同理解这些工作\n决定这些工作如何完成：开发团队需要根据当前的“完成的定义”一起决定如何实现下一个产品增量。他们进行足够的设计和计划，从而有信心可以在Sprint中完成所有工作。决定如何完成工作是开发团队的职责，决定做什么则是产品负责人的职责\n\n\nDaily Scrum Meeting 每日站会\n每日站会需要提供三个信息：\n\n从昨天的站立会到现在，我完成了什么\n从现在到明天的站立会，我计划完成什么\n有什么阻碍了我的进展\n\n\nSprint Review Meeting 评审会议\nSprint结束时，Scrum团队和相关人员一起评审Sprint的产出，Sprint评审会议向每个人展示了当前产品增量的概况。通常都会在Sprint评审会议中调整产品待办事项列表\n\nSprint Retrospective  [ˌretrəˈspektɪv] Meeting 回顾会议\n在每个Sprint结束后，Scrum团队会聚在一起开Sprint回顾会议，目的是回顾一下团队在流程、人际关系以及工具方面做得如何。团队识别出哪些做得好，哪些做得不好，并找出潜在的改进事项\n\n\n总结Scrum团队成员（包括产品负责人、开发团队，以及ScrumMaster）一起合作完成一系列的产品增量，他们采用称为Sprint的短时间周期。每个产品增量符合产品负责人的接受条件，并满足团队的“完成的定义”。所有工作来自于产品待办事项列表（Product Backlog）。Sprint总是从Sprint计划会议开始，团队在会议中制定出Sprint待办事项列表（SprintBacklog）。团队自组织地去开发，利用每日Scrum会议来协调并确保团队产出最好的产品增量。团队通过产品待办事项列表梳理来为下个Sprint计划会议做准备。在Sprint结束时会有Sprint评审会议以及Sprint回顾会议，来审视产品以及团队流程\n","slug":"scurm笔记","date":"2021-06-21T11:16:08.000Z","categories_index":"","tags_index":"面试","author_index":"谢华客"},{"id":"e553701e824962b098d31ab72c61c499","title":"英文HR问题","content":"Software engineer behavioral interview questions1. How do you respond when you disagree with a coworker?I think the best way is commanication. In the part, one of my team members suggested we used a method of coding that I found inefficient. In this situation,we discuss  the project and codei method that  we found most useful.*After our discussion, we both understood each other’s suggestions and presented our ideas to the rest of the team, so we were able to come to a mutual decision as a group after commanication\n2.Can you give me an example of how you set goals for yourself?the first step is write down the goal, and that goal should be very concrete(specific),think about what are the exact steps i can take to achieve this goal? How long will it take me to accomplish[əˈkɑːmplɪʃ] it? What will your life look like once i’ve been promoted，and then do an action plan, make sure include  information such as what steps you’ll be taking and what strategies you’ll be using.\n3.Tell me about a time you were new to a situation or environment. How did you adapt?When I started my last job, I had never worked as a full-time software engineer and knew that I had a lot to learn. However, I  ask many questions and take notes about what I learned, reviewing them at the end of each workday. Eventually, I became familiar with the systems and exceeded my goals within the first six months of employment\n4.Examples of positive reasons for leaving a job\nI want to develop a new skill that isn’t required in my current job, which is full stack dev ，and go through the whole product life clay and I want to work in an international environment,because this is something that I am passionate about and I believe I will succeed in this type of environment.\nAnd the next reason is I want to change city to  life\n\n5.Why did you decide to apply to this role?I have some experience for delivering technical solutions, especially backend experience, and my technical stack  fits this job description\nand This is really exciting for me that I will be able to work in an international environment.\n6.What are your salary expectations?I’ve done some research on the average salaries for this type of role and I think I would expect this role to pay between X and Y. But I think we can discuss at a later time if you think I’d be a good fit for the role. Could you tell me the salary range you have in mind?\n7.What are your greatest strengths and weaknesses?I think one of my greatest strengths is that I am also a self-motivated and quick learning person. Whatever task that I set to do, I always give my best and complete it well, and my weaknesses i think is \n8.What do you know about our company This is a company that hlep customers be more competitive by deliveringsolutions through best-in-class engineering combined withstrategy, design, consulting and innovation services.\n学校情况8.你在学校参加什么社团吗I have joined many clubs, and my fav club is  Fishing Club. I think fishing is something that requires a lot of attention. I can relax my body and mind while fishing. Although I often fail to catch event a single fish, but after that, my whole body was able to recover to a state of full energy.\n9.在学校有什么值得骄傲的事情吗I would have to say the thing is my first time to delivery a project for my school app, this is a sign-in system that all students in the school are using, and when i develop it, i’m a new to the lab, i don’t know any thing, but that task is set to me and my senior, so I have been speeding up my studies, in order to be able to help, in about two weeks,I can join the development, and finlay we complete the project, Whenever I think about what they’ use app is develop by me, i realy prod\n10.项目中如何分配First of all, we are each responsible for one or more modules, so when there is a demand, we will discuss according to development plan, determine the development details, when the details are worked out, which module need to be developed are identified, then the need to develop a module owners will go to join the development, and those who don’t have to develop, can be used as a technical support, Help when needed\n11.How do you prioritize tasksEach day when I go to work, I create a to-do list for myself that includes the items I need to complete within that day. I order my list by level of importance and deadline so I can focus on the most  urgent tasks\n12.职业规划in the long term, I hope to work as a project manager, I will prepare for this goal by focus on develop into a position that allows me to continue to use my skills  which will give me the experience I’ll need in order to excel in an developer, and  attending  conferences to developing my professional career\n单词发音\n\n\nWord\nPhonetic\nChinese\n\n\n\nCoworker\n[‘kəu,wə:kə]\n同事\n\n\ntechnical\n[ˈteknək(ə)l]\n技术的\n\n\npassionate\npaSH(ə)nət\n热爱的\n\n\n想了解我的：\n\n为什么离职\n你现在的技术栈是什么\n期望薪资\n现在的技术水平\n优点和缺点\n介绍一下你在学校做了些什么\n介绍一下你上一份工作做一些什么\n你上一份工作又什么成就\n一个产品的生命周期\nPlan requirementsDevelop productTest softwareDeliver iterationget feedback \n\n\n\n对公司的了解\n\n为什么要应聘我们\n\n对我们的岗位有什么了解\n\nAGILE PRODUCT ENGINEERING\n\n\n我们的岗位和你现在的岗位的不同是什么\n\n了解我们公司是做什么的吗\n\n\n","slug":"english behavior questions","date":"2021-06-05T11:16:08.000Z","categories_index":"","tags_index":"面试","author_index":"谢华客"},{"id":"727fdd30d270ab93f20b48b627af8396","title":"英文面试合集","content":"英文面试合集自我介绍Good afternon sir&#x2F;madam, it&#39;s my pleasure to introduce myself. My name&#39;s Xiehuake, In the summer of 2021, I graduated from Zhengzhou University of Light Industry with a bachelor’s degree in Computer Science and Technology.After graduation, I started my career as a Recommondation system engineer at ZP LAB in Beijing city.As a Java Dep, I have a core Java based,good programming style,kown about CICD workflow and Agile software development, and I familiar with Spring reids kafka Es and other famours open source framework.And i also familiar with Java multi-thread programming and read the source code of Java current Utils pakage.And  I’m experienced with high concurrency and high availability architecture practice.\n\nAs for my personal qualities, I’m very self-driven, responsible and hardworking. I like to read book or online blog to brush up on my skills in my free time. I’m a good team player and I believe I have the combination of experience to contribute to the success of this job. That’s all. Thank you for your listening.\n\n项目介绍The project I'm going to introduce is called the ZHIPIN LAB recommendation system.  It's a subclass of information filtering systems that predict the preference for job-seeker or company .In simple words, it is a System that suggests most instersting items to users.\n\nIn this project, It consists of multiple levels, the first levels is AB Testing, also known as split testing, it's in order to compare two versions of strategy to see which performs better.\n\nAnd then the next lary is recall, after get the strategys from AB Testing, we search Top-1000 items from tens of millions  data by  elasticsearch with each subrecall strategy. by the way, the  subrecall services exists in the form of Dubbo remote service and local plug-in, other level is also too. \n\n\nAnd we fusion the data from each recall, by fusion strategy. also keep top-1000 items, and next step we fill these items into rank system to predict the item score and get the top-200.\n\nafter sorting, we sort item one more time, becase we have to controlle some item position in page by our business strategy. In the end we store the item in redis cache, and return  the result, when the same user request the next page, we dont run the recmoond logic once again, but get result from redis to reutrn. And in each Level, we use elk to log major info, such as cost time or data middle status to help we analysis when we get bad case.\n\nthis project run in average 600 QPS and max 1000 QSP envement, and it keep tp999 in 200ms.\n\nfourteen million job-seeker\nnine million job\n项目难点This project has many level, and the total request time required cannot exceed 300 milliseconds, and each levele cannot be parallelized. I mainly develop the recall layer,Recalls are time-consuming because the data size is hight, and this are many recall should be run, so in recall level, i use I use multi threadi to execute thoses recall and use thread pool to controller, and set the threadpool core size is the cpu cores size plus one, to avoid Threads compete for resources，and i Increase the eland to 1g, \n\n\n\nJava基础1.What are the concepts of OOP?Object Oriented Programming (OOP) includes:\n\nAbstraction 抽象\nEncapsulation 封装\nPolymorphism 多态\nInheritance 继承\n\n2.Mention some features of JavaSome of the features which play important role in the popularity of java are as follows:\n\nObject-Oriented\nPlatform independent\n\n3.Is Java 100% Object-oriented?Not 100%. Java does not satisfy all the OOP conditions (predefined types must be objects) because it uses eight primitive data types(Boolean, byte, char, int, float, double, long, short) which are not objects.\n4. what is Abstraction?The abstraction wants to separate the implementation details of a class from its behavior.\n5.What is Encapsulation? 封装Encapsulation provides objects with the ability to hide their internal data and behavior，each object provides a number of methods,which can be accessed by other objects and change its internal data,in Java, there are three access modifiers: public, private and protected,\n6.What is Inheritance 继承acquire the fields and methods of another class,Inheritance provides reusability of code and can be used to add additional features to an existing class, without modifying it.\n7.What is a Constructor?A constructor gets invoked when a new object is created. Every class has a constructor. In case the programmer does not provide a constructor for a class, the Java compiler (Javac) creates a default constructor for that class.\n8.What is the difference between an Interface and an Abstract class?Java provides and supports the creation of both the abstract classes and interfaces. Both implementations share some common characteristics, but they differ in the following features:\n\nAll methods in an interface are implicitly abstract. On the other hand, an abstract class may contain both abstract and non-abstract methods.\nA class may implement a number of Interfaces but can extend only one abstract class.\nIn order for a class to implement an interface, it must implement all its declared methods. However, a class may not implement all declared methods of an abstract class. Though, in this case, the sub-class must also be declared as abstract.\nAbstract classes can implement interfaces without even providing the implementation of interface methods.\nVariables declared in a Java interface is by default final. An abstract class may contain non-final variables.\nMembers of a Java interface are public by default. A member of an abstract class can either be private, protected or public.\nAn interface is absolutely abstract and cannot be instantiated. An abstract class also cannot be instantiated but can be invoked if it contains the main method.\n\n9.What is the purpose of a Volatile Variableaviod reorderding and add memory visibility to each cpu core. some variable can be modified by different threads, and each thread run in the one of cup core, and there is l1 l2 l3 cache in one core, when core acc varilable, it copy the value into the cache, and modify it, and reflush it to share memory, so in mutiple thread, the value mighth be cover by other thread, so add Volatile  modifier\n10.Explain the available thread states in a high-level.During its execution, a thread can reside in one of the following states:\n\nNEW: The thread becomes ready to run, but does not necessarily start running immediately.\nRUNNABLE: The Java Virtual Machine (JVM) is actively executing the thread’s code.\nBLOCKED: The thread is in a blocked state while waiting for a monitor lock.\nWAITING: The thread waits for another thread to perform a particular action.\nTIMED_WAITING: The thread waits for another thread to perform a particular action up to a specified waiting time.\nTERMINATED: The thread has finished its execution\n\n11.what is necessary Conditions of Deadlock\nMutual Exclusion: Two or more resources are non-shareable (Only one process can use at a time) \nHold and Wait: A process is holding at least one resource and waiting for resources. \nNo Preemption: A resource cannot be taken from a process unless the process releases the resource. \nCircular Wait: A set of processes are waiting for each other in circular form. \n\n12.What is the purpose of garbage collection in Java, and when is it used identify and discard those objects that are no longer needed by the application, in order for the resources to be reclaimed and reused\n13.synchronized\n1 unlocked\n2 Biased locking\n3 Lightweight lock\n4 Heavyweight lock\n\n14.MySQL ACID\nA: atomicity. ea de mi xi ti  : Each transaction is considered as one unit and either runs to completion or is not executed at all\nC: consistency. 肯西死ten 洗 this mean in one transaction, it ensures same query will return the smame result\nI:: isolation. 爱西雷神 multiple transactions c\nD: durability. 滴eo逼了第：ensures that once the transaction has completed execution，and never lost\n\nJVM1.What is the difference between JVM, JRE and JDK is a virtual machine that understands and runs java bytecodes.\n2.What is JRE?java runtime environmen,provides an implementation of the JVM, supporting libraries and other components required to run Java programs\n3.What is JDKJava Development Kit, contains the JRE plus tools such as compilers, debuggers etc. which are required for developers to develop Java programs.\n4.What are Java class loaders? What are the key features of Java class loaderJava class loaders are components in JVM that load Java class file at runtime,Each class loader has its own specific namespace, in which it stores the classes that it loads.\nFeatures:\n\nDelegation model :Before a class loader loads a class, it check if its  parent class loader can load the class, if the  parent class loader can load, then the class load by pranet, if not, the child class loader try to load the class, \n\nBootstrap class loader , Extension class loader, application class loader, user defined class loader\n\n\n5.What are the benefits and negatives of the garbage collector\non the positive size:\nthe developer can worry much less about memory management \nthe gc has a lot of smart algorithms for memory management which work automatically in the background\n\n\non the negative size:\nwhen a garbage collection occurs it has an effect on the application performance, which slowing it down or stopping it.\n\n\n\n6.What is “stop the world”when a gc happens it is necessary to completely pause the threads in an application,this is known as stop the world\n7.What is new generationmost applications have a lot of short lived objects,so it therefore makes sense to separate the shortlived objects so that they can be quickly collected.as a result all new objects are placed into the new generation. new gen is split up further\n\neden space: all new objects are placed in here.  when it becomes full, a minor gc occurs.  all objects that are still referenced are then promoted to a survivor space\n\ntwo survivor spaces, a from space and a to space. during each collection these will swap roles, with all promoted eden objects and surviving objects move to the to space, leaving from empty。\n\n\n8.collector\nserial gc：designed when computers only had one cpu and stops the entire application,because it only use one thread, it use it uses mark-sweep-compact\nparallel gc: similar to serial, except that it uses multiple threads to perform the gc so should be faster.\n\nCICDCI 持续集成（Continuous Integration）中文：帮助开发人员更加频繁地（有时甚至每天）将代码更改合并到共享分支或”主干”中。一旦开发人员对应用所做的更改被合并，系统就会通过自动构建应用并运行不同级别的自动化测试（通常是单元测试和集成测试）来验证这些更改，那问题：那开发到一半的代码怎么办？\nCI and CD stand for continuous integration and continuous delivery, CI is a software development practice that automated build-and-test steps triggered by CI ensure that code changes being merged into the repository auto.\nCD 持续交付（Continuous Delivery） The code is then delivered quickly as a part of the CD process\nWhat are the benefits of CI/CD?\nAutomated testing enables continuous delivery, which ensures software quality of code in production.\nCI/CD enable a much shorter time to market for new product features\nAutomation frees team members to focus on what they do best\n\nWhat is AgileAgile software development .a set of engineering best practices intended to allow for fast delivery of high-quality software, and a business approach that aligns development with customer needs and company goals. Agile development refers to any development process that is aligned with the concepts \n敏捷开发五大工作\nsprint planning meeting 类似需求评审\ndaily standupdo meeting 同步进度\nsprint review 回顾冲刺\n\n什么是TDD（测试驱动开发）\nTest-Driven-Dev 在开发功能之前，先编写测试用例，然后编写可以通过测试用例的代码\n\nWHAT IS SCRUM?Scrum is a subset of Agile. It is a lightweight process framework for agile development, and the most widely-used one.\nSCURM rule\nSCURM MASTER\nPRODUCT OWNER\nSCURM TEAM\n\nDesign Patternshttps://www.tutorialspoint.com/design_pattern/builder_pattern.htm\nWhat is Design Patterns?Design patterns are solutions to general problems that software developers faced during software development.\nTypes of Design Patterns\n\n\nS.N.\nPattern &amp; Description\n\n\n\n1\nCreational Patterns These design patterns provide a way to create objects while hiding the creation logic, rather than create objects directly using new operator. This gives program more flexibility in deciding which objects need to be created for a given use case.\n\n\n2\nStructural Patterns These design patterns concern object composition. Concept of inheritance is used to compose interfaces and define ways to compose objects to obtain new functionalities.\n\n\n3\nBehavioral Patterns These design patterns are specifically concerned with communication between objects.\n\n\n4\nJ2EE Patterns These design patterns are specifically concerned with the presentation tier. These patterns are identified by Sun Java Center.\n\n\nDesign Pattern - Factory PatternIn Factory pattern, we create object without exposing the creation logic to the client and refer to newly created object using a common interface\nDesign Pattern - Abstract Factory PatternAbstract Factory patterns work around a super-factory which creates other factories. This factory is also called as factory of factories\nDesign Pattern - Singleton PatternThis pattern involves a single class which is responsible to create an object while making sure that only single object gets created. This class provides a way to access its only object which can be accessed directly without need to instantiate the object of the class.\nDesign Pattern - Builder PatternBuilder pattern builds a complex object using simple objects and using a step by step approach\nDesign Patterns - Adapter PatternAdapter pattern works as a bridge between two incompatible interfaces.\nDesign Patterns - Proxy PatternIn proxy pattern, a class represents functionality of another class. This type of design pattern comes under structural pattern.\nIn proxy pattern, we create object having original object to interface its functionality to outer world.\nDesign Patterns - Strategy PatternIn Strategy pattern, a class behavior or its algorithm can be changed at run time\nDesign Patterns - Strategy PatternSOLID principles\nSingle Responsibility\n Single Responsibility states that a class should only have one responsibility. Furthermore, it should only have one reason to change\n\nOpen/Closed\n\n\n​        Open for Extension, Closed for Modification\n\nLiskov Substitution\nstates that objects of a superclass should be replaceable with objects of its subclasses without breaking the application\n\nInterface Segregation\nlarger interfaces should be split into smaller ones\n\nDependency Inversion\nRefers to the decoupling of software modules,     modules comniucation will depend to abstractions not implementation.\n\n\n反问1.What challenges will I encounter in this positionbook\nHow to Win Friends\nalgorithm 4 base with java \n单词发音\n\n\nWord\nPhonetic\nTranslation\n\n\n\ncareer\nkəˈrɪə\n职业生涯\n\n\ngraduated\nˈgræʤuːeɪtɪd\n毕业\n\n\nbachelor\nbæʧələ\n学士\n\n\npleasure\n\n\n\n\nfamiliar\nfəˈmɪljə\n\n\n\nframework\nˈfreɪmwɜːk\n\n\n\nexperienced\nɪkˈspɪəriːənst\n\n\n\nconcurrency\n\n\n\n\navailability\nəˌveɪləˈbɪlətiː\n\n\n\narchitecture\nˈɑːkətekʧə\n\n\n\ndriven\n\n\n\n\nenthusiasm\nɪnˈθjuːziːæzəm\n\n\n\nanalysis\nəˈnæləsɪs\n\n\n\noriented\nˈɔːriːəntɪd\n\n\n\nEncapsulation\n\n\n\n\noccurs\n\n\n\n\npromoted\nprəˈmōt\n晋升\n\n\nIntegration\nˌɪntɪˈgreɪʃən\n一体化\n\n\nDelivery\ndɪˈlɪvəri\n交付\n\n\ninitialization\n[ɪˌnɪʃələˈzeɪʃn]\n刷\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"英文面试合集","date":"2021-06-05T11:16:08.000Z","categories_index":"","tags_index":"面试","author_index":"谢华客"},{"id":"a4246540661d717dae121d955eded9b9","title":"ActiveMQ整合SpringBoot","content":"ActiveMQ 整合 SpringBoot引入 activemq 依赖&lt;dependency>\n\t&lt;groupId>org.springframework.boot&lt;/groupId>\n\t&lt;artifactId>spring-boot-starter-activemq&lt;/artifactId>\n&lt;/dependency>\n\n配置 yml 文件\nserver:\n  port: 7777\n\nspring:\n  activemq:\n    broker-url: tcp:&#x2F;&#x2F;localhost:61617\n    user: admin\n    password: admin\n  jms:\n    # false &#x3D; Queue\n    # true &#x3D; Topic 不写默认值 false\n    pub-sub-domain: false\n\nqueue-name: boot-activemq-queue\n\n\n\n因为有时候公司框架的原因，很多都无法使用，所以当配置文件无法使用时，可以使用JavaConfig 的方式配置\n\n\n配置连接工厂\n配置存放主题和队列的 Container\n有了容器，自然就是创建主题或者是队列\n最后要有一个 JmsMessagingTemplate  来发送消息\n再设置一个接收消息的服务\n因为有时候需要支持使用POJO来包装消息，默认的消息转换器不合适，所以要注入一个Json转换消息的转换器\n\n@Configuration\npublic class AmqConfig &#123;\n    // 1. 配置连接工厂\n        @Bean\n    public ConnectionFactory connectionFactory() &#123;\n        AmqServer amqServer = serverDiscovery.findServer();\n        String brokerUrl = \"tcp://\" + amqServer.getIp() + \":7018\";\n        String username = amqServer.getUsername();\n        String password = amqServer.getPassword();\n\n        log.info(\"url：&#123;&#125;, 账号:&#123;&#125;, 密码: &#123;&#125;\", brokerUrl, username, password);\n        // 设置账号密码\n        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(username, password, brokerUrl);\n        // 当需要发送接收序列化的POJO类时，在新版本中需要相信类所在包，所以打开此开关\n        factory.setTrustAllPackages(true);\n        return factory;\n    &#125;\n    \n    // 2. 配置 containerFactory\n    // 在Topic模式中，对消息的监听需要对containerFactory进行配置\n    @Bean(\"topicListener\")\n    public JmsListenerContainerFactory&lt;?> topicJmsListenerContainerFactory(ConnectionFactory connectionFactory)&#123;\n        SimpleJmsListenerContainerFactory factory = new SimpleJmsListenerContainerFactory();\n        factory.setConnectionFactory(connectionFactory);\n        // 设置为true表示存放 topic\n        factory.setPubSubDomain(true);\n        return factory;\n    &#125;\n    // 3. 创建一个收发消息的主题\n    @Bean(\"topic\")\n    public Topic topic() &#123;\n        return new ActiveMQTopic(AmqDestination.SOPS_TOPIC);\n    &#125;\n    \n    // 4. 创建一个操作消息的JmsMessagingtemplate\n        @Bean\n    public JmsMessagingTemplate jmsMessagingTemplate() &#123;\n        return new JmsMessagingTemplate(connectionFactory());\n    &#125;  \n    // 5. 注入消息转化器，使其可以转换序列化的类\n        /**\n     *\n     *  Serialize message content to json using TextMessage\n     *  使用 TextMessage 转化成 序列化后的 json\n     *  注意要POJO类要序列化\n     * */\n    @Bean\n    public MessageConverter jacksonJmsMessageConverter() &#123;\n        MappingJackson2MessageConverter converter = new MappingJackson2MessageConverter();\n        converter.setTargetType(MessageType.TEXT);\n        converter.setTypeIdPropertyName(\"_type\");\n        return converter;\n    &#125;\n&#125;\n\n需要 Spring Boot 支持消息队列，在启动类上加上 @EnableJms 注解就可以实现\n生产者使用方法@RestController\npublic class AmqController &#123;\n\n    @Autowired\n    private JmsMessagingTemplate jmsMessagingTemplate;\n\n    @Autowired\n    private Topic topic;\n\n    @PostMapping(\"/send\")\n    public TlncMessageDto send(@RequestBody TlncMessageDto message) &#123;\n        sendMessage(topic, message);\n        return message;\n    &#125;\n\t\n    // 因为已经注入了Json转化器，所以可以直接传入Object作为消息的payload\n    protected void sendMessage(Destination destination, Object payload) &#123;\n        jmsMessagingTemplate.convertAndSend(destination, payload);\n    &#125;\n\n&#125;\n\n对应消息对象// JsonInclude表示对null字段的序列化策略，ALways表示总是序列化null字段，NON_NULL表示不序列化\n@JsonInclude(JsonInclude.Include.ALWAYS)\n// JsonPropertyOrder 表示序列化和反序列化的时候，字段的顺序\n@JsonPropertyOrder(&#123;\n        \"listType\",\n        \"params\"\n&#125;)\n@Data\n// 需要实现Serializable接口来序列化\npublic class TlncMessageDto implements Serializable &#123;\n\n    // 表示Json字段名对应类的这个成员变量\n    @JsonProperty(\"listType\")\n    public String listType;\n    @JsonProperty(\"params\")\n    public ParamsDto params;\n    // 表示序列化时如果没发现匹配的字段可以忽略\n    @JsonIgnore\n    private Map&lt;String, Object> additionalProperties = new HashMap&lt;String, Object>();\n    private final static long serialVersionUID = -201428069813570775L;\n\n    // 表示额外字段，可以获得成员变量没有的字段\n    @JsonAnyGetter\n    public Map&lt;String, Object> getAdditionalProperties() &#123;\n        return this.additionalProperties;\n    &#125;\n\n    // 表示添加额外的字段，配合@JsonAnyGetter使用\n    @JsonAnySetter\n    public void setAdditionalProperty(String name, Object value) &#123;\n        this.additionalProperties.put(name, value);\n    &#125;\n\n&#125;\n\n还可以定时投放消息在方法上添加 @Scheduled 注解，启动主启动类即可，3000L指的是3秒钟\n@Service\npublic class MQService &#123;\n    @Autowired\n    private JmsMessagingTemplate jmsMessagingTemplate;\n\n    @Autowired\n    private Queue queue;\n\n    @Scheduled(fixedDelay = 3000L)\n    public void sendScheduledMessage() &#123;\n        jmsMessagingTemplate.convertAndSend(queue, \"holy shit!!!!!\" + UUID.randomUUID().toString());\n    &#125;\n&#125;\n\n消费者使用方法消费者只需要在方法上添加 @JmsListener 即可\n@Slf4j\n@Service\npublic class   &#123;\n    @JmsListener(destination = \"$&#123;queue-name&#125;\", containerFactory = \"topicListener\")\n    // 参数直接写对应的类\n    public void receive(TlncMessageDto message) &#123;\n\t\t// TO-DO\n    &#125;\n&#125;\n\n","slug":"ActiveMQ整合SpringBoot","date":"2021-05-03T21:16:08.000Z","categories_index":"","tags_index":"中间件,ActiveMQ,使用心得","author_index":"谢华客"},{"id":"1b5a7d45e32f32d8b53151bc92581ac8","title":"不同中间件的高并发架构","content":"不同中间件的高并发MySQL的高并发对于高并发阶段，MySQL 要做的就是基于主从复制架构，进行读写分离\nMySQL主从复制的原理主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的\n\n\nMySQL 主从同步延时问题（精华）从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行\n解决主库数据丢失问题主库写入binlog日志后，就会强制此时立即将数据同步到从库\n从库将日志写入自己本地的relay log后，会返回一个ack给主库\n主库接收到至少一个从库的ack之后才会认为写操作完成\nRedis的高并发-主从架构模式主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。\n\n\nRedis 主从复制的核心原理当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。\n\n如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。\n此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。 RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中\n接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。\nslave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。\n\n主从复制的断点续传从 Redis2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份（增量复制）\n关键字：backlong, replica offset, run id\nmaster node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 resynchronization 。\n\n如果根据 host+ip 定位 master node，是不靠谱的，如果 master node 重启或者数据出现了变化，那么 slave node 应该根据不同的 run id 区分。\n\nheartbeat主从节点互相都会发送 heartbeat 信息。\nmaster 默认每隔 10 秒发送一次 heartbeat，slave node 每隔 1 秒发送一个 heartbeat。\n异步复制master 每次接收到写命令之后，先在内部写入数据，然后异步发送给 slave node。\n","slug":"不同中间件的高并发架构","date":"2021-05-03T21:13:48.000Z","categories_index":"","tags_index":"系统设计,高并发","author_index":"谢华客"},{"id":"8cad178e2e225e1e2dd25040facb3e5a","title":"MySQL之索引底层原理","content":"InnoDB 页结构页是MySQL管理存储空间的基本单位，一个页的大小一般是16KB，记录是被存放在页中的，如果记录占用的空间太大还可能造成行溢出现象，这会导致一条记录被分散存储在多个页中。\n页的本质就是一块16KB大小的存储空间，InnoDB为了不同的目的而把页分为不同的类型，其中用于存放记录的页也称为数据页，我们先看看这个用于存放记录的页长什么样。数据页代表的这块16KB大小的存储空间可以被划分为多个部分，不同部分有不同的功能，各个部分如图所示：\n\n\n\n\n页结构解释\n\n\n名称\n中文名\n占用空间\n简单描述\n\n\n\nFile Header\n文件头部\n38字节\n页的一些通用信息\n\n\nPage Header\n页面头部\n56字节\n数据页专有的一些信息\n\n\n* Infimum + Supremum\n最小记录和最大记录\n26字节\n两个虚拟的行记录\n\n\n* User Records\n用户记录\n不确定\n实际存储的行记录内容\n\n\n* Free Space\n空闲空间\n不确定\n页中尚未使用的空间\n\n\n* Page Directory\n页面目录\n不确定\n页中的某些记录的相对位置\n\n\nFile Trailer\n文件尾部\n8字节\n校验页是否完整\n\n\n在页的7个组成部分中，存储的记录会按照指定的行格式存储到 User Records 部分。但是在一开始生成页的时候，其实并没有User Records这个部分，每当插入一条记录，都会从 Free Space 部分，也就是尚未使用的存储空间中申请一个记录大小的空间划分到User Records部分，当Free Space部分的空间全部被User Records部分替代掉之后，也就意味着这个页使用完了，如果还有新的记录插入的话，就需要去申请新的页了，这个过程的图示如下：\n\n\n\n\n\n各个数据页之间可以组成一个双向链表 （就是B+树的各个页之间都按照索引值顺序用双向链表连接起来）\n而每个数据页中的记录又可以组成一个单向链表\n每个数据页都会为存储在它里边的记录生成一个页目录，该目录页是用数组进行管理，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录\n以其他列(非主键)作为搜索条件：只能从最小记录开始依次遍历单链表中的每条记录。\n\nInnoDB的行存储结构一页存放多条行记录，InnoDB支持以下四种行记录格式：\n\nCompact\nRedundant\nCompressed\nDynamic (现阶段默认)\n\n\n因为后续的行记录都是根据Compact来做改变的，所以只介绍Compact格式\n\n行记录格式：\n\n\n记录头信息除了变长字段长度列表、NULL值列表之外，还有一个用于描述记录的记录头信息，它是由固定的5个字节组成。 5个字节也就是40个二进制位，不同的位代表不同的意思，如下表：\n\n\n\n名称\n大小（单位：bit）\n描述\n\n\n\n预留位1\n1\n没有使用\n\n\n预留位2\n1\n没有使用\n\n\ndelete_mask\n1\n这个属性标记着当前记录是否被删除，占用1个二进制位，值为0的时候代表记录并没有被删除，为1的时候代表记录被删除掉了。\n\n\nmin_rec_mask\n1\nB+树的每层非叶子节点中的最小记录都会添加该标记，目的是为了加快检索速度\n\n\nn_owned\n4\n表示当前记录拥有的记录数\n\n\nheap_no\n13\n表示当前记录在本页中的位置信息\n\n\nrecord_type\n3\n当前记录的类型，0表示普通记录，1表示非叶子节点记录，2表示最小记录，3表示最大记录\n\n\nnext_record\n16\n表示下一条记录的相对位置\n\n\n\ndelete_mask：这个属性标记着当前记录是否被删除，占用1个二进制位，值为0的时候代表记录并没有被删除，为1的时候代表记录被删除掉了，这些被删除的记录之所以不立即从磁盘上移除，是因为移除它们之后把其他的记录在磁盘上重新排列需要性能消耗，所以只是打个删除标记而已，而且这部分存储空间之后还可以重用，也就是说之后如果有新记录插入到表中的话，可能把这些被删除的记录占用的存储空\nmin_rec_mask： B+树的每层非叶子节点中的最小记录都会添加该标记，目的是为了加快检索速度\nheap_no ：这个属性表示当前记录在本页中的位置。InnoDB自动给每个页里加了两个记录，由于这两个记录并不是自己插入的，所以有时候也称为伪记录或者虚拟记录。这两个伪记录一个代表最小记录，一个代表最大记录。对于一条完整的记录来说，比较记录的大小就是比较主键的大小。不管我们向页中插入了多少自己的记录，InnoDB都定义的两条伪记录分别为最小记录与最大记录。这两条记录的构造十分简单，都是由5字节大小的记录头信息和8字节大小的一个固定的部分组成的\n\n\n\n​        最小记录和最大记录的heap_no值分别是0和1，也就是说它们的位置最靠前\n\nnext_record：这个非常重要，它表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量。比方说第一条记录的next_record值为36，意味着从第一条记录的真实数据的地址处向后找36个字节便是下一条记录的真实数据。这其实是个链表，可以通过一条记录找到它的下一条记录。但是需要注意注意再注意的一点是，下一条记录指得并不是按照插入顺序的下一条记录，而是按照主键值由小到大的顺序的下一条记录。而且规定 最小记录 的下一条记录就本页中主键值最小的记录，而本页中主键值最大的记录的下一条记录就是 最大记录 ，为了更形象的表示一下这个next_record起到的作用，用箭头来替代一下next_record中的地址偏移量：\n\n\n\n记录真实数据记录的真实数据除了我们自己定义的列的数据以外，还会有三个隐藏列：\n\n\n\n列名\n是否必须\n占用空间\n描述\n\n\n\nrow_id\n否\n6字节\n行ID，唯一标识一条记录\n\n\ntransaction_id\n是\n6字节\n事务ID\n\n\nroll_pointer\n是\n7字节\n回滚指针\n\n\n\n只有未设置主键时，innodb才会创建row_id来作为主键列\n\n页目录InnoDB为记录制作了一个目录，制作过程是这样的：\n\n将所有正常的记录（包括最大和最小记录，不包括标记为已删除的记录）划分为几个组\n对于最小记录所在的分组只能有 **1 **条记录，最大记录所在的分组拥有的记录条数只能在 1~8 条之间\n剩下的分组中记录的条数范围只能在是 4~8 条之间\n初始情况下一个数据页里只有最小记录和最大记录两条记录，它们分属于两个分组。 之后每插入一跳记录都把这条记录放到最大记录所在的组，直到最大记录所在组中的记录数等于8个。 在最大记录所在组中的记录数等于8个的时候再插入一条记录时，将最大记录所在组平均分裂成2个组，然后最大记录所在的组就剩下4条记录了，然后就可以把即将插入的那条记录放到对应的组中\n\n\n每个组的最后一条记录的头信息中的 n_owned 属性表示该组内共有几条记录\n将每个组的最后一条记录的地址偏移量按顺序存储起来，每个地址偏移量也被称为一个槽（英文名：Slot）\n\n这些地址偏移量会被存储到页结构中的 Page Directory 中，（可以看前面页的结构 ），比方说现在的表中正常的记录共有6条，InnoDB会把它们分成两组，第一组中只有一个最小记录，第二组中是剩余的5条记录，看下边的示意图：\n\n\n现在Page Directory部分中有两个槽，也就意味着我们的记录被分成了两个组，槽0中的值是99，代表最小记录的地址偏移量；槽1中的值是122，代表最大记录的地址偏移量。 注意最小和最大记录的头信息中的n_owned属性，最小记录的n_owned值为1，这就代表着以最小记录结尾的这个分组中只有1条记录，也就是最小记录本身。 最大记录的n_owned值为5，这就代表着以最大记录结尾的这个分组中只有5条记录，包括最大记录本身还有自己插入的4条记录。\nB+树索引InnoDB数据页的主要组成部分。各个数据页可以组成一个双向链表，而每个数据页中的记录会按照主键值从小到大的顺序组成一个单向链表，每个数据页都会为存储在它里边儿的记录生成一个页目录。再通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽。\n\n\n在一个页中的查找\n\n以主键为搜索条件这个查找过程我们已经很熟悉了，可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录。\n以其他列作为搜索条件对非主键列的查找的过程可就不这么幸运了，因为在数据页中并没有对非主键列建立所谓的页目录，所以我们无法通过二分法快速定位相应的槽。这种情况下只能从最小记录开始依次遍历单链表中的每条记录，然后对比每条记录是不是符合搜索条件\n\n在很多页中查找\n\n定位到记录所在的页。\n从所在的页内中查找相应的记录。\n\n在没有索引的情况下，不论是根据主键列或者其他列的值进行查找，由于我们并不能快速的定位到记录所在的页，所以只能从第一个页沿着双向链表一直往下找，在每一个页中根据我们刚刚唠叨过的查找方式去查找指定的记录\n索引\n为了我们理解上的方便，我们简化了一下index_demo表的行格式示意图\n\n\n\n\nrecord_type这个属性表示当前记录的类型，一共有4种类型的记录，0表示普通记录，1表示B+树非叶节点记录，2表示最小记录，3表示最大记录。next_record记录头信息的一项属性，表示下一条地址相对于本条记录的地址偏移量\n把一些记录放到页里边的示意图就是：\n\n\n由于数据页的编号可能并不是连续的，所以在向表中插入许多条记录后，可能是这样的效果：\n\n\n\n\n因为这些16KB的页在物理存储上可能并不挨着，所以如果想从这么多页中根据主键值快速定位某些记录所在的页，我们需要给它们做个目录，每个页对应一个目录项，每个目录项包括下边两个部分：    * 页的记录中最小的主键值，我们用key来表示。    * 页号，我们用page_no表示。\n在InnoDB中复用了之前存储用户记录的数据页来存储目录项，为了和用户记录做一下区分，我们把这些用来表示目录项的记录称为目录项记录\n\n\n如果我们表中的数据非常多则会产生很多存储目录项记录的页，那我们怎么根据主键值快速定位一个存储目录项记录的页呢？其实也简单，为这些存储目录项记录的页再生成一个更高级的目录，就像是一个多级目录一样，大目录里嵌套小目录，小目录里才是实际的数据，所以现在各个页的示意图就是这样子：\n\n\n所以随着目录的增加，目录的层级就继续增加：\n\n\n聚簇索引\n我们上边介绍的B+树本身就是一个目录，或者说本身就是一个索引。它有两个特点：\n\n使用记录主键值的大小进行记录和页的排序\nB+树的叶子节点存储的是完整的用户记录。\n\n我们把具有这两种特性的B+树称为聚簇索引，所有完整的用户记录都存放在这个聚簇索引的叶子节点处。这种聚簇索引并不需要我们在MySQL语句中显式的使用INDEX语句去创建MySQL中事务的创建\n二级索引\n\n\n这个B+树与上边介绍的聚簇索引有几处不同：\n\n使用记录c2列的大小进行记录和页的排序，这包括三个方面的含义：\n\n页内的记录是按照c2列的大小顺序排成一个单向链表。\n各个存放用户记录的页也是根据页中记录的c2列大小顺序排成一个双向链表。\n存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的c2列大小顺序排成一个双向链表。\n\n\nB+树的叶子节点存储的并不是完整的用户记录，而只是c2列+主键这两个列的值。\n目录项记录中不再是主键+页号的搭配，而变成了c2列+页号的搭配。\n\n联合索引\n\n\n如图所示，我们需要注意一下几点：\n\n每条目录项记录都由c2、c3、页号这三个部分组成，各条记录先按照c2列的值进行排序，如果记录的c2列相同，则按照c3列的值进行排序。\nB+树叶子节点处的用户记录由c2、c3和主键c1列组成。\n\nB+树适用的条件\n那么再次建议回过头把前边的内容看完了再来，要不然读文章对你来说是一种折磨。首先，B+树索引并不是万能的，并不是所有的查询语句都能用到我们建立的索引。下边介绍几个我们可能使用B+树索引来进行查询的情况。\nCopyCREATE TABLE person_info(\n    id INT NOT NULL auto_increment,\n    name VARCHAR(100) NOT NULL,\n    birthday DATE NOT NULL,\n    phone_number CHAR(11) NOT NULL,\n    country varchar(100) NOT NULL,\n    PRIMARY KEY (id),\n    KEY idx_name_birthday_phone_number (name, birthday, phone_number)\n);\n\nperson_info表会为聚簇索引和idx_name_birthday_phone_number索引建立2棵B+树。\n在记录结构中只保留name、birthday、phone_number、id这四个列的真实数据值，所以示意图就长这样：\n\n\n内节点中存储的是目录项记录，叶子节点中存储的是用户记录（由于不是聚簇索引，所以用户记录是不完整的，缺少country列的值）。\n\n先按照name列的值进行排序。\n如果name列的值相同，则按照birthday列的值进行排序。\n如果birthday列的值也相同，则按照phone_number的值进行排序。\n\n全值匹配如果我们的搜索条件中的列和索引列一致的话，这种情况就称为全值匹配，比方说下边这个查找语句：\nCopySELECT * FROM person_info WHERE name &#x3D; &#39;Ashburn&#39; AND birthday &#x3D; &#39;1990-09-27&#39; AND phone_number &#x3D; &#39;15123983239&#39;;\n\n\n因为B+树的数据页和记录先是按照name列的值进行排序的，所以先可以很快定位name列的值是Ashburn的记录位置。\n在name列相同的记录里又是按照birthday列的值进行排序的，所以在name列的值是Ashburn的记录里又可以快速定位birthday列的值是’1990-09-27’的记录。\n如果很不幸，name和birthday列的值都是相同的，那记录是按照phone_number列的值排序的，所以联合索引中的三个列都可能被用到。\n\n调换name、birthday、phone_number这几个搜索列的顺序对查询的执行过程是没有影响的。\n匹配左边的列CopySELECT * FROM person_info WHERE name &#x3D; &#39;Ashburn&#39;;\n\n或者包含多个左边的列也行：\nCopySELECT * FROM person_info WHERE name &#x3D; &#39;Ashburn&#39; AND birthday &#x3D; &#39;1990-09-27&#39;;\n\n只有左边的列才能匹配，下边的语句就用不到这个B+树索引：\nCopySELECT * FROM person_info WHERE birthday &#x3D; &#39;1990-09-27&#39;;\n\n因为B+树的数据页和记录先是按照name列的值排序的，在name列的值相同的情况下才使用birthday列进行排序，也就是说name列的值不同的记录中birthday的值可能是无序的。\n如果我们想使用联合索引中尽可能多的列，搜索条件中的各个列必须是联合索引中从最左边连续的列。\n匹配列前缀person_info表上建立的联合索引idx_name_birthday_phone_number会先用name列的值进行排序。\n也就是说这些字符串的前n个字符，也就是前缀都是排好序的，所以对于字符串类型的索引列来说，我们只匹配它的前缀也是可以快速定位记录的，比方说我们想查询名字以’As’开头的记录，那就可以这么写查询语句：\nCopySELECT * FROM person_info WHERE name LIKE &#39;As%&#39;;\n\n同理，这样也是无法匹配的：\nCopySELECT * FROM person_info WHERE name LIKE &#39;%As%&#39;;\n\n匹配范围值所有记录都是按照索引列的值从小到大的顺序排好序的，所以这极大的方便我们查找索引列的值在某个范围内的记录。\nCopySELECT * FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39;;\n\n由于所有记录都是由链表连起来的（记录之间用单链表，数据页之间用双链表），所以他们之间的记录都可以很容易的取出来喽～找到这些记录的主键值，再到聚簇索引中回表查找完整的记录。\n如果对多个列同时进行范围查找的话，只有对索引最左边的那个列进行范围查找的时候才能用到B+树索引，比方说这样：\nCopySELECT * FROM person_info WHERE name &gt; ‘Asa’ AND name &lt; ‘Barlow’\nAND birthday &gt; &#39;1980-01-01&#39;;\n\n上边这个查询可以分成两个部分：\n\n通过条件name &gt; ‘Asa’ AND name &lt; ‘Barlow’来对name进行范围。\n对这些name值不同的记录继续通过birthday &gt; ‘1980-01-01’条件继续过滤。\n\n对于联合索引idx_name_birthday_phone_number来说，只能用到name列的部分，而用不到birthday列的部分，因为只有name值相同的情况下才能用birthday列的值进行排序，而这个查询中通过name进行范围查找的记录中可能并不是按照birthday列进行排序的，所以在搜索条件中继续以birthday列进行查找时是用不到这个B+树索引的。\n精确匹配某一列并范围匹配另外一列虽然对多个列都进行范围查找时只能用到最左边那个索引列，但是如果左边的列是精确查找，则右边的列可以进行范围查找，比方说这样：\nCopySELECT * FROM person_info WHERE name &#x3D; &#39;Ashburn&#39; AND birthday &gt; &#39;1980-01-01&#39; AND birthday &lt; &#39;2000-12-31&#39; AND phone_number &gt; &#39;15100000000&#39;;\n\n由于name列是精确查找，所以通过name = ‘Ashburn’条件查找后得到的结果的name值都是相同的，它们会再按照birthday的值进行排序。所以此时对birthday列进行范围查找是可以用到B+树索引的。\nphone_number &gt; ‘15100000000’，通过birthday的范围查找的记录的birthday的值可能不同，所以这个条件无法再利用B+树索引了，只能遍历上一步查询得到的记录。\n用于排序有的时候可能查询的结果集太大以至于不能在内存中进行排序的话，还可能暂时借助磁盘的空间来存放中间结果，排序操作完成后再把排好序的结果集返回到客户端。在MySQL中，把这种在内存中或者磁盘上进行排序的方式统称为文件排序（英文名：filesort）。\n但是如果ORDER BY子句里使用到了我们的索引列，就有可能省去在内存或文件中排序的步骤，比如下边这个简单的查询语句：\nCopySELECT * FROM person_info ORDER BY name, birthday, phone_number LIMIT 10;\n\n因为这个B+树索引本身就是按照上述规则排好序的，所以直接从索引中提取数据，然后进行回表操作取出该索引中不包含的列就好了。\n使用联合索引进行排序注意事项ORDER BY的子句后边的列的顺序也必须按照索引列的顺序给出，如果给出ORDER BY phone_number, birthday, name的顺序，那也是用不了B+树索引。\n不可以使用索引进行排序的几种情况1.ASC、DESC混用对于使用联合索引进行排序的场景，我们要求各个排序列的排序顺序是一致的，也就是要么各个列都是ASC规则排序，要么都是DESC规则排序。\nidx_name_birthday_phone_number联合索引中记录的结构：\n\n先按照记录的name列的值进行升序排列。\n如果记录的name列的值相同，再按照birthday列的值进行升序排列。\n如果记录的birthday列的值相同，再按照phone_number列的值进行升序排列。\n\n2.WHERE子句中出现非排序使用到的索引列如果WHERE子句中出现了非排序使用到的索引列，那么排序依然是使用不到索引的，比方说这样：\nCopySELECT * FROM person_info WHERE country &#x3D; ‘China’ ORDER BY name LIMIT 10;\n\n这个查询只能先把符合搜索条件country = ‘China’的记录提取出来后再进行排序，是使用不到索引。\n3.排序列包含非同一个索引的列有时候用来排序的多个列不是一个索引里的，这种情况也不能使用索引进行排序，比方说：\nCopySELECT * FROM person_info ORDER BY name, country LIMIT 10;\n\n4.排序列使用了复杂的表达式要想使用索引进行排序操作，必须保证索引列是以单独列的形式出现，而不是修饰过的形式，比方说这样：\nCopySELECT * FROM person_info ORDER BY UPPER(name) LIMIT 10;\n\n回表的代价还是用idx_name_birthday_phone_number索引为例，看下边这个查询：\nCopySELECT * FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39;;\n\n在使用idx_name_birthday_phone_number索引进行查询时大致可以分为这两个步骤：\n\n从索引idx_name_birthday_phone_number对应的B+树中取出name值在Asa～Barlow之间的用户记录。\n由于索引idx_name_birthday_phone_number对应的B+树用户记录中只包含name、birthday、phone_number、id这4个字段，而查询列表是*，意味着要查询表中所有字段，也就是还要包括country字段。这时需要把从上一步中获取到的每一条记录的id字段都到聚簇索引对应的B+树中找到完整的用户记录，也就是我们通常所说的回表，然后把完整的用户记录返回给查询用户。\n\n读取索引idx_name_birthday_phone_number数据中，在Asa～Barlow之间的记录在磁盘中的存储是相连的，集中分布在一个或几个数据页中，我们可以很快的把这些连着的记录从磁盘中读出来，这种读取方式我们也可以称为顺序I/O。\n而获取到的记录的id字段的值可能并不相连，而在聚簇索引中记录是根据id（也就是主键）的顺序排列的，所以根据这些并不连续的id值到聚簇索引中访问完整的用户记录可能分布在不同的数据页中，这样读取完整的用户记录可能要访问更多的数据页，这种读取方式我们也可以称为随机I/O。\n所以这个使用索引idx_name_birthday_phone_number的查询有这么两个特点：\n\n会使用到两个B+树索引，一个二级索引，一个聚簇索引。\n访问二级索引使用顺序I/O，访问聚簇索引使用随机I/O。\n\n需要回表的记录越多，使用二级索引的性能就越低，甚至让某些查询宁愿使用全表扫描也不使用二级索引。比方说name值在Asa～Barlow之间的用户记录数量占全部记录数量90%以上，那么如果使用idx_name_birthday_phone_number索引的话，有90%多的id值需要回表，这不是吃力不讨好么，还不如直接去扫描聚簇索引（也就是全表扫描）。\n查询优化器做的工作，查询优化器会事先对表中的记录计算一些统计数据，然后再利用这些统计数据根据查询的条件来计算一下需要回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描，反之倾向于使用二级索引 + 回表的方式。\n比方说上边的查询可以改写成这样：\nCopySELECT * FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39; LIMIT 10;\n\n添加了LIMIT 10的查询更容易让优化器采用二级索引 + 回表的方式进行查询。\n覆盖索引为了彻底告别回表操作带来的性能损耗，我们建议：最好在查询列表里只包含索引列。\nCopySELECT name, birthday, phone_number FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39;\n\n因为我们只查询name, birthday, phone_number这三个索引列的值，所以在通过idx_name_birthday_phone_number索引得到结果后就不必到聚簇索引中再查找记录的剩余列，也就是country列的值了，这样就省去了回表操作带来的性能损耗。\n我们把这种只需要用到索引的查询方式称为索引覆盖。\n我们很不鼓励用*号作为查询列表，最好把我们需要查询的列依次标明。\n索引失效的情况\n\n具体情况参考网站\n如何挑选索引只为用于搜索、排序或分组的列创建索引也就是说，只为出现在WHERE子句中的列、连接子句中的连接列，或者出现在ORDER BY或GROUP BY子句中的列创建索引。而出现在查询列表中的列就没必要建立索引了\nCopySELECT birthday, country FROM person_name WHERE name &#x3D; &#39;Ashburn&#39;;\n\n考虑列的基数记录行数一定的情况下，列的基数越大，该列中的值越分散，列的基数越小，该列中的值越集中。\n假设某个列的基数为1，也就是所有记录在该列中的值都一样，那为该列建立索引是没有用的，因为所有值都一样就无法排序，无法进行快速查找了。\n而且如果某个建立了二级索引的列的重复值特别多，那么使用这个二级索引查出的记录还可能要做回表操作，这样性能损耗就更大了。\n索引列的类型尽量小如果我们想要对某个整数列建立索引的话，在表示的整数范围允许的情况下，尽量让索引列使用较小的类型。因为：\n\n数据类型越小，在查询时进行的比较操作越快（这是CPU层次的东东）\n数据类型越小，索引占用的存储空间就越少，在一个数据页内就可以放下更多的记录，从而减少磁盘I/O带来的性能损耗，也就意味着可以把更多的数据页缓存在内存中，从而加快读写效率。\n\n因为不仅是聚簇索引中会存储主键值，其他所有的二级索引的节点处都会存储一份记录的主键值，如果主键适用更小的数据类型，也就意味着节省更多的存储空间和更高效的I/O。\n让索引列在比较表达式中单独出现如：\n\nWHERE my_col * 2 &lt; 4\nWHERE my_col &lt; 4/2\n\n第1个WHERE子句中my_col列并不是以单独列的形式出现的，而是以my_col * 2这样的表达式的形式出现的，存储引擎会依次遍历所有的记录，计算这个表达式的值是不是小于4。\n如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式，或者函数调用形式出现的话，是用不到索引的。\n主键插入顺序对于一个使用InnoDB存储引擎的表来说，在我们没有显式的创建索引时，表中的数据实际上都是存储在聚簇索引的叶子节点的。而记录又是存储在数据页中的，数据页和记录又是按照记录主键值从小到大的顺序进行排序，所以如果我们插入的记录的主键值是依次增大的话，那我们每插满一个数据页就换到下一个数据页继续插。\n如果我们插入的主键值忽大忽小的话，就会需要页分裂和记录移位，意味着：性能损耗！所以如果我们想尽量避免这样无谓的性能损耗，最好让插入的记录的主键值依次递增，这样就不会发生这样的性能损耗了。\n所以我们建议：让主键具有AUTO_INCREMENT，让存储引擎自己为表生成主键，而不是我们手动插入。\n","slug":"MySQL之索引底层原理","date":"2021-05-03T21:08:22.000Z","categories_index":"","tags_index":"底层原理,MySQL","author_index":"谢华客"},{"id":"9fff64f3cbe68428f83c74019add044a","title":"RabbitMQ整合SpringBoot","content":"RabbitMQ的使用\n\n在 Rabbitmq 的模型中，Server 中会包含很多个虚拟主机 Virtual Host ，这就类似于数据库中的库，用来和项目做一一的映射，不同的项目建立不同的主机，达到隔离每个项目的目的。\n所以在创建项目前先创建一个主机\n在 RabbitMQ 中创建一个虚拟主机\n\n添加了一个虚拟主机，应该设置一个可以访问其的用户，guest 用户默认可以访问所有虚拟主机，这里创建一个用户只允许访问我们刚刚创建的主机\n\n\n新创建的用户默认是不能访问任何虚拟主机的，需要为其设置可以访问的虚拟主机\n\n\n\n\n\n\n添加依赖&lt;dependency>\n        &lt;groupId>org.springframework.boot&lt;/groupId>\n        &lt;artifactId>spring-boot-starter-amqp&lt;/artifactId>\n    &lt;/dependency>\n\n    &lt;dependency>\n        &lt;groupId>org.springframework.boot&lt;/groupId>\n        &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId>\n    &lt;/dependency>\n\n向 application.yml 中添加 RabbitMQ 的配置信息\nspring:\n  rabbitmq:\n    host: 自己rabbit的路径\n    port: 自己rabbit的端口\n    virtual-host: &#x2F;\n    username: 自己rabbit的账号\n    password: 自己rabbit的密码\n    publisher-confirms: true\n\n配置完成，整合SpringBoot需要完成下列步骤：\n\n\nRabbitMQ 的配置文件需要应用到Java中，所以我们增加获取配置文件信息的实体类\n增加获取配置文件信息的实体类@Configuration\npublic class RabbitProperties &#123;\n\n    /**\n     * rabbitmq 服务器地址\n     */\n    @Value(\"$&#123;spring.rabbitmq.host&#125;\")\n    private String host;\n\n    /**\n     * rabbitmq 服务器端口\n     */\n    @Value(\"$&#123;spring.rabbitmq.port&#125;\")\n    private int port;\n\n    /**\n     * rabbitmq 账号\n     */\n    @Value(\"$&#123;spring.rabbitmq.username&#125;\")\n    private String username;\n\n    /**\n     * rabbitmq 密码\n     */\n    @Value(\"$&#123;spring.rabbitmq.password&#125;\")\n    private String password;\n    \n    // seter and getter\n    \n    // To-String menthod\n    \n&#125;\n\n\n获取到配置信息后，需要应用到我们的 RabbitMQ 程序中\n增加配置类@Configuration\npublic class RabbitConfiguration &#123;\n\n    @Autowired\n    private RabbitProperties rabbitProperties;\n\n    @Bean\n    public ConnectionFactory connectionFactory() &#123;\n        CachingConnectionFactory connectionFactory = new CachingConnectionFactory(rabbitProperties.getHost(), rabbitProperties.getPort());\n        connectionFactory.setUsername(rabbitProperties.getUsername());\n        connectionFactory.setPassword(rabbitProperties.getPassword());\n        connectionFactory.setVirtualHost(\"/\");\n        connectionFactory.setPublisherConfirms(true);\n        return connectionFactory;\n    &#125;\n\n    /**\n     * @return\n     * @Scope(value=ConfigurableBeanFactory.SCOPE_PROTOTYPE)这个是说在每次注入的时候回自动创建一个新的bean实例\n     * @Scope(value=ConfigurableBeanFactory.SCOPE_SINGLETON)单例模式，在整个应用中只能创建一个实例\n     * @Scope(value=WebApplicationContext.SCOPE_GLOBAL_SESSION)全局session中的一般不常用\n     * @Scope(value=WebApplicationContext.SCOPE_APPLICATION)在一个web应用中只创建一个实例\n     * @Scope(value=WebApplicationContext.SCOPE_REQUEST)在一个请求中创建一个实例\n     * @Scope(value=WebApplicationContext.SCOPE_SESSION)每次创建一个会话中创建一个实例\n     * proxyMode=ScopedProxyMode.INTERFACES创建一个JDK代理模式\n     * proxyMode=ScopedProxyMode.TARGET_CLASS基于类的代理模式\n     * proxyMode=ScopedProxyMode.NO（默认）不进行代理\n     */\n    @Bean\n    @Scope(ConfigurableBeanFactory.SCOPE_SINGLETON)\n    public RabbitTemplate rabbitTemplate() &#123;\n        RabbitTemplate template = new RabbitTemplate(connectionFactory());\n        // 消息发送失败返回到队列中, yml需要配置 publisher-returns: true\n        // template.setMandatory(true);\n        return template;\n    &#125;\n&#125;\n\n\nRabbitMQ 中需要存在队列、交换机等组件，需要将其用Java的方式定义出来\n定义 RabbitMQ 各个组件public class RabbitMqKey &#123;\n\n    /**\n     * 订单-队列\n     */\n    public static final String TRADE_ORDER_QUEUE = \"trade-order-queue\";\n\n    /**\n     * 订单-交换器\n     */\n    public static final String TRADE_ORDER_EXCHANGE = \"trade-order-exchange\";\n\n&#125;\n\n每个组件都是单独存在的，需要将他们联系起来\n初始化队列、交换机等并绑定关系\n由Exchange、Queue、Routing Key三个才能决定一个从Exchange到Queue的唯一的线路。\n\n@Component\npublic class TradeOrderQueueConfig &#123;\n\n\n    private final static Logger logger = LoggerFactory.getLogger(TradeOrderQueueConfig.class);\n\n    /**\n     * 创建队列\n     * Queue 可以有4个参数\n     * String name: 队列名\n     * boolean durable: 持久化消息队列，rabbitmq 重启的时候不需要创建新的队列，默认为 true\n     * boolean exclusive: 表示该消息队列是否只在当前的connection生效，默认为 false\n     * boolean autoDelete: 表示消息队列在没有使用时将自动被删除，默认为 false\n     * Map&lt;String, Object> arguments:\n     *\n     * @return\n     */\n    @Bean(name = \"queue\")\n    public Queue queue() &#123;\n        logger.info(\"queue : &#123;&#125;\", RabbitMqKey.TRADE_ORDER_QUEUE);\n        // 队列持久化\n        return new Queue(RabbitMqKey.TRADE_ORDER_QUEUE, true);\n    &#125;\n\n    /**\n     * 创建一个 Fanout 类型的交换器\n     * &lt;p>\n     * rabbitmq中，Exchange 有4个类型：Direct，Topic，Fanout，Headers\n     * Direct Exchange：将消息中的Routing key与该Exchange关联的所有Binding中的Routing key进行比较，如果相等，则发送到该Binding对应的Queue中；\n     * Topic Exchange：将消息中的Routing key与该Exchange关联的所有Binding中的Routing key进行对比，如果匹配上了，则发送到该Binding对应的Queue中；\n     * Fanout Exchange：直接将消息转发到所有binding的对应queue中，这种exchange在路由转发的时候，忽略Routing key；\n     * Headers Exchange：将消息中的headers与该Exchange相关联的所有Binging中的参数进行匹配，如果匹配上了，则发送到该Binding对应的Queue中；\n     *\n     * @return\n     */\n    @Bean(name = \"fanoutExchange\")\n    public FanoutExchange fanoutExchange() &#123;\n        logger.info(\"exchange : &#123;&#125;\", RabbitMqKey.TRADE_ORDER_EXCHANGE);\n        return new FanoutExchange(RabbitMqKey.TRADE_ORDER_EXCHANGE);\n    &#125;\n\n    /**\n     * 把队列（Queue）绑定到交换器（Exchange）\n     * topic 使用路由键（routingKey）\n     *\n     * @return\n     */\n    @Bean\n    Binding fanoutBinding(@Qualifier(\"queue\") Queue queue,\n                    @Qualifier(\"fanoutExchange\") FanoutExchange fanoutExchange) &#123;\n        return BindingBuilder.bind(queue).to(fanoutExchange);\n    &#125;\n&#125;\n\n到此，RabbitMQ 的所有服务组件已经搭建和连接完成了，可以使用 Sender 发送消息和接收者接收消息了。\n新建发送消息类@Component\npublic class Sender &#123;\n\n    private final Logger logger = LoggerFactory.getLogger(this.getClass());\n\n    /**\n     * 如果rabbitTemplate的scope属性设置为ConfigurableBeanFactory.SCOPE_PROTOTYPE，所以不能自动注入\n     * 需手动注入\n     */\n    \n    @Autowired\n    private RabbitTemplate rabbitTemplate;\n\n    /**\n     * 订单信息（发送至交换器）\n     *\n     * @param payload\n     * @return\n     */\n    public String orderSendExchange(Object payload)&#123;\n        return baseSend(RabbitMqKey.TRADE_ORDER_EXCHANGE, \"\", payload, null, null);\n    &#125;\n\n    /**\n     * 订单信息（发送至队列）\n     *\n     * @param payload\n     * @return\n     */\n    public String orderSendQueue(Object payload)&#123;\n        return baseSend(\"\", RabbitMqKey.TRADE_ORDER_QUEUE, payload, null, null);\n    &#125;\n\n    /**\n     * MQ 发送数据基础方法\n     *\n     * @param exchange  交换器名\n     * @param routingKey  队列名\n     * @param payload 消息信息\n     * @param uniqueMessageId  标示id，不传可自动生成\n     * @param messageExpirationTime  持久化时间\n     * @return 消息编号\n     */\n    public String baseSend(String exchange, String routingKey, Object payload, String uniqueMessageId, Long messageExpirationTime) &#123;\n        // 生成消息ID\n        String finalUniqueMessageId = uniqueMessageId;\n        if (StringUtils.isBlank(uniqueMessageId)) &#123;\n            uniqueMessageId = UUID.randomUUID().toString();\n        &#125;\n        logger.info(\"SEND --- unique message id：&#123;&#125;\", uniqueMessageId);\n\n        // 消息属性\n        MessagePostProcessor messagePostProcessor = new MessagePostProcessor() &#123;\n            @Override\n            public Message postProcessMessage(Message message) throws AmqpException &#123;\n                // 消息属性中写入消息编号\n                message.getMessageProperties().setMessageId(finalUniqueMessageId);\n                // 消息持久化时间\n                if (!StringUtils.isEmpty(String.valueOf(messageExpirationTime))) &#123;\n                    logger.info(\"设置消息持久化时间：&#123;&#125;\", messageExpirationTime);\n                    message.getMessageProperties().setExpiration(Long.toString(messageExpirationTime));\n                &#125;\n                // 设置持久化模式\n                message.getMessageProperties().setDeliveryMode(MessageDeliveryMode.PERSISTENT);\n                return message;\n            &#125;\n        &#125;;\n\n        logger.info(\"SEND --- messagePostProcessor：&#123;&#125;\", messagePostProcessor);\n\n        // 消息\n        Message message = null;\n        try &#123;\n            ObjectMapper objectMapper = new ObjectMapper();\n            String json = objectMapper.writeValueAsString(payload);\n            logger.info(\"发送消息：&#123;&#125;\", payload.toString());\n            // 转换数据格式\n            MessageProperties messageProperties = new MessageProperties();\n            messageProperties.setContentEncoding(MessageProperties.CONTENT_TYPE_JSON);\n            message = new Message(json.getBytes(), messageProperties);\n        &#125; catch (JsonProcessingException e) &#123;\n            e.printStackTrace();\n        &#125;\n\n        // correlationData\n        CorrelationData correlationData = new CorrelationData(uniqueMessageId);\n\n        /**\n         * convertAndSend(String exchange, String routingKey, Object message, MessagePostProcessor messagePostProcessor, CorrelationData correlationData)\n         * exchange: 路由\n         * routingKey: 绑定key\n         * message: 发送消息\n         * messagePostProcessor: 消息属性处理类\n         * correlationData: 对象内部只有一个 id 属性，用来表示当前消息唯一性\n         */\n        rabbitTemplate.convertAndSend(exchange, routingKey, message, messagePostProcessor, correlationData);\n\n        return finalUniqueMessageId;\n    &#125;\n&#125;\n\n\n发送的消息不一定会成功送到队列中，所以要增加一个确认机制\n确认消息@Component\npublic class RabbitAck implements RabbitTemplate.ConfirmCallback &#123;\n\n    private final static Logger logger = LoggerFactory.getLogger(RabbitAck.class);\n\n    @Autowired\n    private RabbitTemplate rabbitTemplate;\n\n    @PostConstruct\n    public void init() &#123;\n        //指定 ConfirmCallback\n        //rabbitTemplate如果为单例的话，那回调就是最后设置的内容\n        rabbitTemplate.setConfirmCallback(this);\n    &#125;\n\n    /**\n     * @param correlationData\n     * @param ack\n     * @param cause\n     */\n    @Override\n    public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123;\n        logger.info(\"ACK --- MQ message id: &#123;&#125;\" + correlationData);\n        if (ack) &#123;\n            logger.info(\"ACK --- Message sent confirmation success！\");\n        &#125; else &#123;\n            logger.info(\"ACK --- MQ message id: &#123;&#125;\", correlationData.getId());\n            logger.info(\"ACK --- MQ confirmetion: &#123;&#125;\", ack);\n            logger.info(\"ACK --- Message sending confirmation failed, reason for failure:\" + cause);\n        &#125;\n    &#125;\n&#125;\n\n\n接收消息@Component\npublic class OrderQueueListener &#123;\n\n    private static final Logger logger = LoggerFactory.getLogger(OrderQueueListener.class);\n\n    /**\n     * 接收消息\n     *\n     * @param message\n     */\n    @RabbitListener(queues = RabbitMqKey.TRADE_ORDER_QUEUE)\n    public void process(Message message) &#123;\n        try &#123;\n            String msg = new String(message.getBody());\n            if (StringUtils.isBlank(msg)) &#123;\n                logger.warn(\"接收的数据为空\");\n                return;\n            &#125;\n            System.out.println(msg);\n        &#125; catch (Exception e) &#123;\n            logger.warn(\"处理接收到数据，发生异常：&#123;&#125;\", e.getMessage());\n            e.printStackTrace();\n        &#125;\n    &#125;\n&#125;\n\n\n","slug":"RabbitMQ整合SpringBoot","date":"2021-05-03T21:03:59.000Z","categories_index":"","tags_index":"中间件,使用心得,RabbitMQ","author_index":"谢华客"},{"id":"e70e2ff17ca94471876ef71091a97a2a","title":"Synchronized关键字底层原理","content":"Synchronized 关键字底层原理其实在 jdk1.6 之前的 synchronized 锁都是重量级锁，从 jdk1.6 开始对锁进行了优化，加入了从无锁-偏向锁-轻量级锁-自旋-重量级锁的升级流程，锁的状态都保存在对象的对象头中，所以需要了解Java对象头\n理解Java对象头与Monitor在JVM中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充\n\n\n对象的运行时数据都放在MarkWord当中，其中也包括对象的锁的信息，分布如下：\n\n\n\nJava对象的信息比较多，所以在不同的锁状态下，MarkWord存储的内容是不一样的\n\n锁膨胀过程\n\n\n当我们创建一个对象LockObject时，该对象的部分Markword关键数据如下。\n\n\n\nbit fields\n是否偏向锁\n锁标志位\n\n\n\nhash\n0\n01\n\n\n　　从图中可以看出，偏向锁的标志位是“01”，状态是“0”，表示该对象还没有被加上偏向锁。（“1”是表示被加上偏向锁）。该对象被创建出来的那一刻，就有了偏向锁的标志位，这也说明了所有对象都是可偏向的，但所有对象的状态都为“0”，也同时说明所有被创建的对象的偏向锁并没有生效。\n偏向锁不过，当线程执行到临界区（critical section）时，此时会利用CAS(Compare and Swap)操作，将线程ID插入到Markword中，同时修改偏向锁的标志位。\n\n所谓临界区，就是只允许一个线程进去执行操作的区域，即同步代码块。CAS是一个原子性操作\n\n此时的Mark word的结构信息如下：\n\n\n\nbit fields\n\n是否偏向锁\n锁标志位\n\n\n\nthreadId\nepoch\n1\n01\n\n\n此时偏向锁的状态为“1”，说明对象的偏向锁生效了，同时也可以看到，哪个线程获得了该对象的锁。\n那么，什么是偏向锁?　　偏向锁是jdk1.6引入的一项锁优化，其中的“偏”是偏心的偏。它的意思就是说，这个锁会偏向于第一个获得它的线程，在接下来的执行过程中，假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。也就是说:在此线程之后的执行过程中，如果再次进入或者退出同一段同步块代码，并不再需要去进行加锁或者解锁操作，而是会做以下的步骤：\n\nLoad-and-test，也就是简单判断一下当前线程id是否与Markword当中的线程id是否一致.\n如果一致，则说明此线程已经成功获得了锁，继续执行下面的代码.\n如果不一致，则要检查一下对象是否还是可偏向，即“是否偏向锁”标志位的值。\n如果还未偏向，则利用CAS操作来竞争锁，也即是第一次获取锁时的操作。\n\n　　如果此对象已经偏向了，并且不是偏向自己，则说明存在了竞争。此时可能就要根据另外线程的情况，可能是重新偏向，也有可能是做偏向撤销，但大部分情况下就是升级成轻量级锁了。　　可以看出，偏向锁是针对于一个线程而言的，线程获得锁之后就不会再有解锁等操作了，这样可以省略很多开销。假如有两个线程来竞争该锁话，那么偏向锁就失效了，进而升级成轻量级锁了。　　为什么要这样做呢？因为经验表明，其实大部分情况下，都会是同一个线程进入同一块同步代码块的。这也是为什么会有偏向锁出现的原因。　　在Jdk1.6中，偏向锁的开关是默认开启的，适用于只有一个线程访问同步块的场景。\n锁膨胀　　当出现有两个线程来竞争锁的话，那么偏向锁就失效了，此时锁就会膨胀，升级为轻量级锁。这也是我们经常所说的锁膨胀\n锁撤销由于偏向锁失效了，那么接下来就得把该锁撤销，锁撤销的开销花费还是挺大的，其大概的过程如下：\n\n在一个安全点停止拥有锁的线程。\n遍历线程栈，如果存在锁记录的话，需要修复锁记录和Markword，使其变成无锁状态。\n唤醒当前线程，将当前锁升级成轻量级锁。所以，如果某些同步代码块大多数情况下都是有两个及以上的线程竞争的话，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭\n\n轻量级锁锁撤销升级为轻量级锁之后，那么对象的Markword也会进行相应的的变化。下面先简单描述下锁撤销之后，升级为轻量级锁的过程：\n\n线程在自己的栈桢中创建锁记录 LockRecord。\n将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。\n将锁记录中的Owner指针指向锁对象。\n将锁对象的对象头的MarkWord替换为指向锁记录的指针。\n\n对应的图描述如下(图来自周志明深入java虚拟机)\n\n\n\n\n\n\n之后Markwork如下：\n\n\n\nbit fields\n锁标志位\n\n\n\n指向LockRecord的指针\n00\n\n\n注：锁标志位”00”表示轻量级锁轻量级锁主要有两种\n\n自旋锁\n自适应自旋锁\n\n自旋锁所谓自旋，就是指当有另外一个线程来竞争锁时，这个线程会在原地循环等待，而不是把该线程给阻塞，直到那个获得锁的线程释放锁之后，这个线程就可以马上获得锁的。注意，锁在原地循环的时候，是会消耗cpu的，就相当于在执行一个啥也没有的for循环。所以，轻量级锁适用于那些同步代码块执行的很快的场景，这样，线程原地等待很短很短的时间就能够获得锁了。经验表明，大部分同步代码块执行的时间都是很短很短的，也正是基于这个原因，才有了轻量级锁这么个东西。\n自旋锁的一些问题\n如果同步代码块执行的很慢，需要消耗大量的时间，那么这个时侯，其他线程在原地等待空消耗cpu，这会让人很难受。\n本来一个线程把锁释放之后，当前线程是能够获得锁的，但是假如这个时候有好几个线程都在竞争这个锁的话，那么有可能当前线程会获取不到锁，还得原地等待继续空循环消耗cup，甚至有可能一直获取不到锁。\n\n基于这个问题，我们必须给线程空循环设置一个次数，当线程超过了这个次数，我们就认为，继续使用自旋锁就不适合了，此时锁会再次膨胀，升级为重量级锁。默认情况下，自旋的次数为10次，用户可以通过-XX:PreBlockSpin来进行更改。\n\n自旋锁是在JDK1.4.2的时候引入的\n\n自适应自旋锁所谓自适应自旋锁就是线程空循环等待的自旋次数并非是固定的，而是会动态着根据实际情况来改变自旋等待的次数。其大概原理是这样的：假如一个线程1刚刚成功获得一个锁，当它把锁释放了之后，线程2获得该锁，并且线程2在运行的过程中，此时线程1又想来获得该锁了，但线程2还没有释放该锁，所以线程1只能自旋等待，但是虚拟机认为，由于线程1刚刚获得过该锁，那么虚拟机觉得线程1这次自旋也是很有可能能够再次成功获得该锁的，所以会延长线程1自旋的次数。另外，如果对于某一个锁，一个线程自旋之后，很少成功获得该锁，那么以后这个线程要获取该锁时，是有可能直接忽略掉自旋过程，直接升级为重量级锁的，以免空循环等待浪费资源。\n\n轻量级锁也被称为非阻塞同步、乐观锁，因为这个过程并没有把线程阻塞挂起，而是让线程空循环等待，串行执行。\n\n重量级锁轻量级锁膨胀之后，就升级为重量级锁了。重量级锁是依赖对象内部的monitor锁来实现的，而monitor又依赖操作系统的MutexLock(互斥锁)来实现的，所以重量级锁也被成为互斥锁。当轻量级所经过锁撤销等步骤升级为重量级锁之后，它的Markword部分数据大体如下\n\n\n\nbit fields\n锁标志位\n\n\n\n指向Mutex的指针\n10\n\n\n为什么说重量级锁开销大呢主要是，当系统检查到锁是重量级锁之后，会把等待想要获得锁的线程进行阻塞，被阻塞的线程不会消耗cup。但是阻塞或者唤醒一个线程时，都需要操作系统来帮忙，这就需要从用户态转换到内核态，而转换状态是需要消耗很多时间的，有可能比用户执行代码的时间还要长。这就是说为什么重量级线程开销很大的。\n\n互斥锁(重量级锁)也称为阻塞同步、悲观锁\n\n重量级锁是什么样的一个形式在重量级锁下，每个对象对应着一个Monitor监视器，在HotSpot下，monitor是由C++实现的ObjectMonitor类来控制的，数据结构如下：\n\nC++源码位置：openjdk\\hotspot\\src\\share\\vm\\runtime\\objectMonitor.hpp\n\nObjectMonitor() &#123;\n    _header       &#x3D; NULL;\n    _owner        &#x3D; NULL; \t&#x2F;&#x2F; 指向获得该监视器的线程\n    _count        &#x3D; 0; \t\t&#x2F;&#x2F; 记录个数\n    _EntryList    &#x3D; NULL ; \t&#x2F;&#x2F; 处于等待锁block状态的线程，会被加入到该列表 类型：ObjectWaiter*\n    _WaitSet      &#x3D; NULL; \t&#x2F;&#x2F; 处于wait状态的线程，会被加入到_WaitSet 类型：ObjectWaiter*\n    _waiters      &#x3D; 0, \n    _recursions   &#x3D; 0;\n    _object       &#x3D; NULL;\n    _WaitSetLock  &#x3D; 0 ;\n    _Responsible  &#x3D; NULL ;\n    _succ         &#x3D; NULL ;\n    _cxq          &#x3D; NULL ;\n    FreeNext      &#x3D; NULL ;\n    _SpinFreq     &#x3D; 0 ;\n    _SpinClock    &#x3D; 0 ;\n    OwnerIsThread &#x3D; 0 ;\n  &#125;\n\n\nObjectMonitor，其中Owner字段指向持有这个对象的线程，并且ObjectMonitor有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter（每个等待锁的线程都会被封装成ObjectWaiter对象）\n多个线程同时访问同步代码时，首先都会进入_EntryList 集合，当线程获取到对象monitor后，进入 _owner 区域将其指向直接，并累加count，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示\n\n\n\n\n而Java对象头MarkWord中就会指向这个ObjectMonitor，进行关联\n\n","slug":"Synchronized关键字底层原理","date":"2021-05-03T20:50:19.000Z","categories_index":"","tags_index":"Java,多线程,底层原理","author_index":"谢华客"},{"id":"33521bd94ee66cdecae1afca83643ee9","title":"中间件高可用知识点","content":"不同中间件的高可用架构RabbitMQ高可用\nRabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现 RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。\n\n\n单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的?，没人生产用单机模式\n普通集群模式：\n意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。\n你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作\n\n\n镜像集群模式：\n这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。\n这样的好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据\n\n\n\nRedis高可用Redis高可用集群一般是和支撑高并发的主从架构配合使用的\n前置知识：\nquorumquorum的值是手动设置的，每次做主备切换，需要 quorum 数量的哨兵认为主节点客观宕机(odown)\n\nquorum 的值一般设置为 Sentinel 个数的二分之一加 1，例如 3 个 Sentinel 就设置为 2\n\nmajority进行主备切换时，选举出一个哨兵来做切换，这个哨兵需要 majority 的士兵的授权才能正式授权，majority是哨兵数量 / 2 + 1\n\n当 quorum &lt; majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换\n但是如果 quorum &gt;= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。\n\n哨兵的介绍sentinel，中文名是哨兵。哨兵是 Redis 集群架构中非常重要的一个组件，主要有以下功能：\n\n集群监控：负责监控 Redis 主节点和 从节点 进程是否正常工作。\n消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。\n故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。\n配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。\n\n哨兵用于实现 Redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。\n\n故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。\n即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。\n\n哨兵模式工作原理\n每个 Sentinel 以每秒一次的频率向它所知的 Master，Slave 以及其他 Sentinel 节点发送一个 PING 命令；\n如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过配置文件 own-after-milliseconds 选项所指定的值，则这个实例会被 Sentinel 标记为主观下线；\n如果一个 主节点 被标记为主观下线，那么正在监视这个 Master 的所有 Sentinel 要以每秒一次的频率确认主节点是否真的进入主观下线状态；\n当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认 Master 的确进入了主观下线状态，则 Master 会被标记为客观下线；\n如果 Master 处于 ODOWN 状态，则投票自动选出新的主节点。将剩余的从节点指向新的主节点继续进行数据复制；\n在正常情况下，每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 INFO 命令；当 Master 被 Sentinel 标记为客观下线时，Sentinel 向已下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次；\n若没有足够数量的 Sentinel 同意 Master 已经下线，Master 的客观下线状态就会被移除。若 Master 重新向 Sentinel 的 PING 命令返回有效回复，Master 的主观下线状态就会被移除。\n\n而哨兵之间是如何进行互相发现和交换信息的呢？\n哨兵集群的自动发现机制每隔2秒钟，每个哨兵都会往自己监控的某个 主从节点 对应的 __sentinel__:hello channel 里发送一个消息，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。\n每个哨兵也会去监听自己监控的每个 主从节点 对应的 __sentinel__:hello channel，然后去感知到同样在监听这个 节点 的其他哨兵的存在。\n每个哨兵还会跟其他哨兵交换对 master 的监控配置，互相进行监控配置的同步。\n定时任务Sentinel 内部有 3 个定时任务，分别是：\n\n每 1 秒每个 Sentinel 对其他 Sentinel 和 Redis 节点执行 PING 操作（监控），这是一个心跳检测，是失败判定的依据。\n每 2 秒每个 Sentinel 通过 Master 节点的 channel 交换信息（Publish/Subscribe）；\n每 10 秒每个 Sentinel 会对 Master 和 Slave 执行INFO命令，这个任务主要达到两个目的：\n发现 Slave 节点；\n确认主从关系。\n\n\n\nsdown 和 odown 转换机制\nsdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机\nodown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机\n\nsdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 is-master-down-after-milliseconds 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。\nslave-&gt;master 选举算法如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：\n\nslave 优先级\n复制 offset\nrun id\n\n如果一个 slave 跟 master 断开连接的时间已经超过了 down-after-milliseconds 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。\n(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state\n\n接下来会对 slave 进行排序：\n\n按照 slave 优先级进行排序，slave priority 越低，优先级就越高\n如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高\n如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave\n\nRedis clusterRedis cluster是Redis的另一种集群方案\nRedis cluster 介绍\n自动将数据进行分片，每个 master 上放一部分数据\n提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的\n要开放两个端口号，比如一个是6379，另外一个就是 + 1W的端口号，比如16379\n\n节点是如何进行通信Redis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更\n\ngossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后\n\ngossip 协议gossip 协议包含多种消息，包含 ping , pong , meet , fail 等等。\n\nmeet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信\n\n其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群\n\nping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据\npong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新\nfail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦\n\n分布式寻址算法\nhash 算法（大量缓存重建）\n一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）\nRedis cluster 的 hash slot 算法\n\nhash 算法来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库。\n一致性 hash 算法一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。\n来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，遇到的第一个 master 节点就是 key 所在位置。\n在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。\n然而，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。\nRedis cluster 的 hash slot 算法Redis cluster 有固定的 16384 个 hash slot，对每个 key 计算 CRC16 值，然后对 16384 取模，可以获取 key 对应的 hash slot。\nRedis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 hash tag 来实现。\n任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器\nRedis cluster 的高可用与主备切换原理Redis cluster 的高可用的原理，几乎跟哨兵是类似的。\n判断节点宕机如果一个节点认为另外一个节点宕机，那么就是 pfail ，主观宕机。如果多个节点都认为另外一个节点宕机了，那么就是 fail ，客观宕机，跟哨兵的原理几乎一样，sdown，odown。\n在 cluster-node-timeout 内，某个节点一直没有返回 pong ，那么就被认为 pfail 。\n如果一个节点认为某个节点 pfail 了，那么会在 gossip ping 消息中， ping 给其他节点，如果超过半数的节点都认为 pfail 了，那么就会变成 fail 。\n从节点过滤对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。\n检查每个 slave node 与 master node 断开连接的时间，如果超过了 cluster-node-timeout * cluster-slave-validity-factor ，那么就没有资格切换成 master 。\n从节点选举每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。\n所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node （N/2 + 1） 都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。\n从节点执行主备切换，从节点切换为主节点。\n与哨兵比较整个流程跟哨兵相比，非常类似，所以说，Redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。\n","slug":"中间件高可用知识点","date":"2021-05-03T20:47:18.000Z","categories_index":"","tags_index":"系统设计,高可用","author_index":"谢华客"},{"id":"6cd30b54600ff936f0e357293094df28","title":"操作系统之IO多路复用详解","content":"用户空间与内核空间操作系统为了保证内核安全，将内存空间分为两部分：用户空间和内核空间，用户的程序都运行在用户空间上，而对于管理系统的进程，内存，设备，文件等操作，都只能由运行在内核空间的核心进程来进行\n文件描述符fd文件描述符（File descriptor）是一个用于表述指向文件的引用的抽象化概念。\n文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统\n缓存 I/O缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。\n缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。\n从阻塞 I/O 到 I/O 多路复用阻塞 I/O，是指进程发起调用后，会被挂起（阻塞），直到收到数据再返回。如果调用一直不返回，进程就会一直被挂起。因此，当使用阻塞 I/O 时，需要使用多线程来处理多个文件描述符。\n多线程切换有一定的开销，因此引入非阻塞 I/O。非阻塞 I/O 不会将进程挂起，调用时会立即返回成功或错误，因此可以在一个线程里轮询多个文件描述符是否就绪。\n但是非阻塞 I/O 的缺点是：每次发起系统调用，只能检查一个文件描述符是否就绪。当文件描述符很多时，系统调用的成本很高。\n因此引入了 I/O 多路复用，可以通过一次系统调用，检查多个文件描述符的状态。这是 I/O 多路复用的主要优点，相比于非阻塞 I/O，在文件描述符较多的场景下，避免了频繁的用户态和内核态的切换，减少了系统调用的开销。\n\nI/O 多路复用相当于将「遍历所有文件描述符、通过非阻塞 I/O 查看其是否就绪」的过程从用户线程移到了内核中，由内核来负责轮询\n\nI/O 多路复用之select、poll、epoll详解selectselect函数将监视的文件描述符分为三类：readfds，writefds，errorfds，采用位图的形式，对于未就绪的文件描述符，使用0表示，而就绪则采用1表示。\n调用select后，会顺序遍历文件描述符列表检查每个文件描述符是否就绪，如果每个文件描述符都未就绪，那么select就会阻塞timeout时长，再返回，这期间如果某个文件描述符发生可读事件，则select会将对应位置为1，并立即返回\nselect的缺点：\n\n性能开销大：需要遍历传递进来的每个文件描述符，不管他们是否就绪\n同时能够监听的文件描述符数量太少，受限于fd_set的大小\n\npollpoll和select的区别是：poll是采用链表的方式来存储文件描述符，没有最大的存储数量的限制\nepollepoll是对select和poll的改进，避免了性能开销过大，和文件描述符数量少的两个缺点\nepoll有以下三个特点：\n\n使用红黑树存储文件描述符集合\n使用队列存储就绪的文件描述符\n每个文件描述符只需要在添加时传入一次，通过事件更改文件描述符状态\n\nepoll使用三个函数来进行操作，分别是 epoll_create，epoll_ctl  和 epoll_wait\nepoll_createepoll_create 会创建一个 epoll 实例，同时返回一个引用该实例的文件描述符。\n返回的文件描述符仅仅指向对应的 epoll 实例，并不表示真实的磁盘文件节点。其他 API 如 epoll_ctl、epoll_wait 会使用这个文件描述符来操作相应的 epoll 实例。\n当创建好 epoll 句柄后，它会占用一个 fd 值，在 linux 下查看 /proc/进程id/fd/，就能够看到这个 fd。所以在使用完 epoll 后，必须调用 close(epfd) 关闭对应的文件描述符，否则可能导致 fd 被耗尽。当指向同一个 epoll 实例的所有文件描述符都被关闭后，操作系统会销毁这个 epoll 实例\nepoll 实例内部存储：\n\n监听列表：所有要监听的文件描述符，使用红黑树\n就绪列表：所有就绪的文件描述符，使用链表\n\nepoll_ctlepoll_ctl 会将文件描述符 fd 添加到 epoll 实例的监听列表里，同时为 fd 设置一个回调函数，并监听事件 event。当 fd 上发生相应事件时，会调用回调函数，将 fd 添加到 epoll 实例的就绪队列上\nepoll_wait这是 epoll 模型的主要函数，功能相当于 select\n如果没有文件描述符就绪，即就绪队列为空，则epoll_wait会阻塞timeout秒，直到有文件描述符就绪，如果timeout为0，则立即返回\nepoll的优点(面试可能会问)\n避免了性能开销大：epoll_ctl中为每个文件描述符指定了回调函数，并在就绪时将器加入到就绪队列当中，使用不需要遍历每个文件描述符，只需要判断就绪队列列表是否为空即可，这样在没有描述符就绪时，epoll能更早的让出系统资源\n而低于文件描述符少，select采用位图存储文件描述符，而epoll使用红黑树存储，数量较大\n\n三者对比\nselect：调用开销大（需要复制集合）；集合大小有限制；需要遍历整个集合找到就绪的描述符\npoll：poll 采用链表的方式存储文件描述符，没有最大存储数量的限制，其他方面和 select 没有区别\nepoll：调用开销小（不需要复制）；集合大小无限制；采用回调机制，不需要遍历整个集合\n\nselect、poll 都是在用户态维护文件描述符集合，因此每次需要将完整集合传给内核；epoll 由操作系统在内核中维护文件描述符集合，因此只需要在创建的时候传入文件描述符\n","slug":"操作系统之IO多路复用详解","date":"2021-05-03T20:44:59.000Z","categories_index":"","tags_index":"计算机基础,操作系统","author_index":"谢华客"},{"id":"2ef40044afb1f095a6625b5d86ae265d","title":"操作系统之死锁","content":"死锁产生的条件\n互斥：一个临界资源只能同时被一个进程所占有\n不可抢占：一个进程获取的资源只能由这个线程主动释放，不能被抢占\n占有且等待：一个进程占有某些资源，并尝试去获取被其他进程占有的其他的资源\n循环等待：进程等待形成环形等待链，每个进程都占有着上一个进程想要获取的资源，并且等待着下一个进程占有的资源\n\n怎么处理死锁？死锁的处理主要分为 死锁的预防，死锁的避免，以及死锁的检测和解除\n死锁的预防\n死锁的预防是指破环死锁产生的四个必要条件的一个或多个\n\n\n破坏不可抢占模式，一个进程申请被其他进程占有的资源时，要先释放自己手上的资源，这也可以认为是资源可以被抢占了\n破坏占有且等待：系统在给进程分配资源时，直接把进程所需资源一次性分配给进程\n破坏循环等待：将临界资源进行标记，进程进行资源的申请只能按照标记的某个方向进行申请\n\n死锁的避免前置知识：系统安全状态，是指系统能按照某种进程推进顺序来为每个进程分配所需的资源，直至满足每个进程对资源的最大需求，如果系统无法找到这样的序列，那么就说系统处于不安全状态\n而找出系统安全状态，是使用的银行家算法\n银行家算法\n\n\n\n\n\n死锁的检测死锁的检测是指将系统资源和进程申请资源的关系画成 资源分配图，然后再进行资源分配图的简化，如果简化完成后资源分配图上还剩余线程，说明产生了死锁\n死锁的解除\n可以不使用死锁的预防和避免，允许死锁的产生，直到产生死锁后进行死锁的解除，主要方法又：\n\n资源剥夺法：挂起死锁进程，并抢占它的资源，分配给其他死锁进程\n撤销进程法：强制撤销部分或者是全部进程。\n进程回退法：让一个或者多个\n\n","slug":"操作系统之死锁","date":"2021-05-03T20:43:12.000Z","categories_index":"","tags_index":"计算机基础,操作系统","author_index":"谢华客"},{"id":"c48274d266bd8fce81f6183578ffb524","title":"操作系统之内存管理","content":"逻辑地址和物理地址在进程当中，地址是从0号单元开始编址的，这叫做进程的逻辑地址\n而物理地址是指的内存中物理单元的位置，进程在运行时执行指令和访问数据，最后都要通过物理地址从主存当中获取，而逻辑地址和物理地址的转换称为地址重定位\n内存保护系统需要保护用户进程不受其他用户进程的影响，采用基址寄存器和界地址寄存器来实现保护\n基址寄存器保存的是进程最小的物理地址，界地址寄存器保存的是进程中最大的逻辑地址。当需要访问某个数据时，也就是在进程当中访问某个逻辑地址，先通过与界地址寄存器进行比较，如果大于则表示越界。\n\n基址寄存器是用来进行 “+” 操作的，而界地址寄存器是用来进行合法检验的，如果目标逻辑地址小于界地址，那么就可用 基址 + 逻辑地址来定位物理地址\n\n内存分配\n为了同时将多个进程保留在内存中，如果对每个进程都申请连续的内存空间，那么就极有可能产生大量的内存碎片，导致即使拥有足够下一个进程所需的内存空间，也无法将这个进程加载进来。\n无论是页式管理还是段式存储管理，都是为了增加内存的利用率，减少内存碎片，而之前的存储管理是固定分区方式\n\n页式存储管理操作系统将主存分为大小相等且固定的块，作为主存的基本单位，而每个进程也是以块作为单位进行划分，进程在执行时，以块作为单位逐个申请空间，所以进程申请的空间在主存当中是可以不连续的。\n块在进程当中被称为页，而在主存当中被称为页框，进程当中页会有自己的页号，从0开始，为了使得通过页找到主存当中的页框，使用的时页表来对页和页框做映射\n而又可以根据是否要把所有的页面都装入内存才可以运行分为基本分页存储和请求分页存储\n段式存储管理分页管理方式是从计算机的角度设计的，目的是增加内存利用率，减少内存碎片，而段式管理是根据用户进程中的自然段划分的，比如一个进程从有两个子进程，就可以划分为3个段。每个段从0开始编址，并分配一段连续的内存空间（段中要求连续，而段之间不要求连续），同样使用段表来对每个段进行段在内存空间的映射\n段页式存储管理页式管理能有效的提高内存利用率，而分段式管理能反映程序的逻辑结构，将两种方式结合起来，就形成了段页式存储管理\n进程的地址空间先根据程序的逻辑结构分成不同的段，每个段都有自己的段号，然后在段当中分成若干大小固定的页，而对于每个段或者是段中的页，管理和段式和页式没什么区别，每个段使用段表来进行段在主存的起始地址的映射，而段中的块则采用页表的形式来做页和页框的映射\n\n所以段页式存储管理下，最多有一个段表，而页表可能有很多个\n\n虚拟内存局部性原理局部性原理表现在两个方面：\n\n时间局部性：程序当中的指令在在某一时刻被执行后，在接下来的时间内可能会再次被执行，某个数据在被访问过后，接下来可能会再次被访问\n空间局部性：某个内存单元在被访问后，它相邻的内存单元也可能会被访问\n\n\n为什么呢？因为程序当中的指令是顺序存放，顺序执行的，而数据一般也是按照向量、数组、表的形式以聚簇的形式进行存储，所以访问可能会有关联性\n\n所以基于局部性原理，在程序装入内存时，只将程序的一部分装入，其余留在外存当中，当访问的数据不在内存当中时，操作系统将该部分装入内存当中，这样系统好像就为用户进程提供了一个比实际内存大得多的存储空间，称为虚拟内存\n虚拟内存技术的实现虚拟内存技术允许将一个主页分多次调入内存，所以要求进程是按照离散的形式调入内存的，所以虚拟内存的实现有三种形式：\n\n请求分页存储管理\n请求分段存储管理\n请求段页式存储管理\n\n\n请求和基本管理\n\n而需要硬件支持：\n\n页表或段表机制\n中断机制，当用户程序访问的数据的部分没有装入内存中时，产生中断\n地址变化机构，逻辑地址到物理地址的变换\n\n页表机制\n\n缺页中断机构当所访问的页面不在内存块中时，便会产生一个缺页中断，请求操作系统将所缺的页调入内存当中，如果内存中有空闲块，则分配一个块，将装入的页放在该块，如果没有空余的块，则要淘汰某块\n页面置换算法\n最佳算法：淘汰的总是以后不再使用的页，但是无法预测，所以无法实现，是用来衡量其他算法的标准\n先进先出页面置换算法：总是淘汰最先进入内存的页面，而这个算法会出现所分配的块数越多产生缺页中断的次数不减反增的异常现象，叫做belady异常\n最近最久未使用LRU算法：选择最近最长时间未访问的页进行淘汰，通过页表中的访问字段来判断大小\n时钟置换算法：使用使用位和修改位来标记一个页。当进行淘汰时，优先淘汰第一个遇到的未使用的，也未修改的页，如果没有，则淘汰第一个使用的，但未修改的页\n\n抖动在页面置换过程中，如果换出的页马上又要装入内存，装入内存的页马上要换出内存，这种频繁的页面调度行为则被称为抖动\n\n产生抖动原因：进程频繁访问的页面数大于系统可用的页框数，装入换出的页都是进程需要访问的页\n\n虚拟内存空间的大小由上面因素决定\n虚拟内存的大小 &lt;= 内存容量和外存容量之和，如果超过了这个容量，则没有相应的空间来供虚拟内存使用\n&lt;= 计算机地址位数能容纳的最大容量，假设是32位，一个地址代表1B存储空间，那么虚存的大小就小于4GB (2^32B)\n\n","slug":"操作系统之内存管理","date":"2021-05-03T20:40:59.000Z","categories_index":"","tags_index":"计算机基础,操作系统","author_index":"谢华客"},{"id":"26f886a7c89a2304aec3bf49d8ad4b85","title":"Zookeeper工作原理和机制","content":"Zookeeper工作机制是一个分布式服务管理框架，负责存储和管理数据，然后接受观察者的注册，一旦这些数据发生变化，zookeeper就负责通知这些观察者做出相应的反应\nZookeeper服务器角色一般zookeeper都是以集群的形式存在的，是一个基于主从复制的高可用集群，每个服务器承担三个角色的一种：\n\nLeader：一个集群只有有一个Leader，他会发起并维护各Follwer和Observer间的心跳，所有的写操作都会Leader来进行完成并将写操作广播给其他Follwer\nFollower：可同时存在多个，它会响应Leader的心跳，它可以直接处理并返回客户端的读请求，但如果是写请求，会将请求转发给Leader处理，并负责对Leader的写请求进行投票\nObserver：和Follower类似，但是无投票权\n\n\n\nZookeeper怎么保证读写操作的一致性和可用性？使用的是原子广播(ZAB)来实现，根据ZAB协议，所有的写操作都需要通过 Leader 来完成，Leader 写入本地日志后再复制到所有的Follower节点上，而一旦Leader节点无法工作，ZAB协议能够自动从Follower节点中重新选出一个合适的替代者\n写Leader\n\n如果通过Leader进行写操作，会进行下列步骤：\n\n客户端向Leader发送写请求\nLeader将写请求以提议的形式发送给所有的Follower并等待确认\nFollower收到Leader的提议后返回确认\nLeader得到过半数的确认(Leader对自己默认有一个ACK)后向所有的Follower发送commit，并将结果返回客户端\n\n\n对于上图的4各Follower，那就是一共有5个节点(不用计算Observer)，那就是需要3个确认，也就是两个Follower的ACK即可\n\n写Follower\nFollower/Observer均可接受写请求，但不能直接处理，而需要将写请求转发给Leader处理\n除了多了一步请求转发，其它流程与直接写Leader无任何区别\n\n读操作所有服务器都可以接受客户端的读操作\n领导选举算法 - FastLeaderElectionFastLeaderElection 是基于TCP的\n1.myid每个zookeeper服务器都要在数据文件夹下创建一个叫做myid的文件，这个文件包含整个zookeeper集群的唯一id\n2.zxid用来标识一次更新操作的提议ID，64位表示，高32位是Leader的轮次，从1开始，每换一个leader都会递增1，而低32位用来标记一次事务\n3.服务器状态\nLOOKING：不确定Leader状态，会发起Leader选举\nFOLLOWING：跟随者状态，表明当前服务器是follower状态\nLEADING：表示整个服务器是leader，它会维护与follower的心跳\nOBSERVING：观察者状态。表明当前服务器角色是Observer，与Folower唯一的不同在于不参与选举，也不参与集群写操作时的投票\n\n4、选票数据结构\n 每个服务器在进行领导选举时，会发送如下关键信息：\n\nlogicClock 每个服务器会维护一个自增的整数，名为logicClock，它表示这是该服务器发起的第多少轮投票\nstate 当前服务器的状态\nself_id 当前服务器的myid\nself_zxid 当前服务器上所保存的数据的最大zxid\nvote_id 被推举的服务器的myid\nvote_zxid 被推举的服务器上所保存的数据的最大zxid\n\n投票流程\n当开始投票时，每个服务器都会先把票投给自己，然后进行广播，\n\n接下来接受外部投票\n\n判断选举轮次，如果外部投票的轮次大于自己的轮次，说明自己的轮次已经落后，就会将自己的轮次更新为这个轮次，然后进行选票PK\n\nPK的规则是：比较自己推举的服务器的Zxid，也就是事务id，如果小的话，就会将票投给大的，并广播出去，如果相等，就会投给myid大的\n\n如果有过半的服务器投给了某个服务器，投票结束，更换服务器的状态\n\n\n\n每次某个FOLLOWER重启都会进行一次投票\n\n使用Zookeeper来实现分布式的锁zookeeper有持久型节点和非持久型节点，有可以细分为持久型顺序节点和非顺序节点，以此类推\n而zookeeper可以用非持久型节点来实现分布式锁\n非公平锁的实现\n在zookeeper当中，非公平锁指的是锁被释放后，参与排队获取这个锁的所有客户端都可以去竞争，这和多线程中的非公平锁是有点区别的\n\n采用 非持久型非顺序节点来完成\n\n多个客户端尝试在zookeeper中创建非持久型非顺序节点，肯定只会有一个创建成功，这个客户端就获得了锁\n创建失败的客户端会在这个节点上注册一个Watch，一旦锁被释放，也就是节点被删除，那么那些客户端就会收到推送，再次进行抢占\n\n公平锁的实现\n公平锁指的是获取锁失败的客户端按照顺序去获得锁\n\n采用 非持久型顺序节点 来完成\n\n多个客户端会尝试获得锁的节点下创建出多个顺序节点，当尝试获取锁时，判断自己的节点是不是最小的，如果是则获取到锁\n如果获取锁失败，就注册Watch在比自己小的节点上，不是全部，所以当锁被释放时，只会有第一个排队的客户端收到Watch通知，其他不会\n收到通知后，并不会立即进行锁的获取，而是判断一下自己的顺序是否最小，如果不是，就还是会注册一个Watch到第一个比自己小的节点上\n\nZookeeper的Watch原理\n对于创建一个zookeeper客户端时，会创建出两个线程，一个是用来连接服务器的contect线程，一个负责监听的listener线程\n然后通过contect线程将监听事件发送给zookeeper服务器\n服务器将这个监听事件注册到监听列表当中\n当节点发生变化后，zookeeper服务器会将消息发送到listener线程当中\nlistener线程调用precsss()方法进行处理\n\n","slug":"Zookeeper工作原理和机制","date":"2021-05-03T20:37:38.000Z","categories_index":"","tags_index":"中间件,底层原理,Zookeeper","author_index":"谢华客"},{"id":"66fbda97c6061d29db33ae44cd19310f","title":"Hystrix底层原理","content":"Hystrix 是什么？在分布式系统中，每个服务都可能会调用很多其他服务，被调用的那些服务就是依赖服务，有的时候某些依赖服务出现故障也是很正常的。\nHystrix可以提供那些功能Hystrix可以提供：\n\n服务熔断\n服务降级\n服务限流\n\nHystrix 更加细节的设计原则\n阻止任何一个依赖服务耗尽所有的资源，比如 tomcat 中的所有线程资源。\n避免请求排队和积压，采用限流和 fail fast 来控制故障。\n提供 fallback 降级机制来应对故障。\n使用资源隔离技术，比如 bulkhead（舱壁隔离技术）、swimlane（泳道技术）、circuit breaker（断路技术）来限制任何一个依赖服务的故障的影响。\n\nHystrixCommand的调用方法\nexecute：同步堵塞，调用了queue().get()方法，execute()执行完后，会创建一个新线程运行run()；\nqueue：异步非堵塞，它调用了toObservable().toBlocking().toFuture()方法，queue()执行完后，会创建一个新线程运行run()。Future.get()是堵塞的，它等待run()运行完才返回结果；\nobserve() ：异步热响应调用，它调用了toObservable().subscribe(subject)方法，observe()执行完后，会创建一个新线程运行run()。toBlocking().single()是堵塞的，需要等run()运行完才返回结果；\n**toObservable()**：异步的冷响应调用，该方法不会主动创建线程运行run()，只有当调用了toBlocking().single()或subscribe()时，才会去创建线程运行run()。\n\nHystrix 实现资源隔离，主要有两种技术：\n\n线程池\n\n第三方客户端（执行Hystrix的run()方法）会在单独的线程执行，会与调用的该任务的线程进行隔离，以此来防止调用者调用依赖所消耗的时间过长而阻塞调用者的线程。\n使用线程隔离的好处：\n\n应用程序可以不受失控的第三方客户端的威胁，如果第三方客户端出现问题，可以通过降级来隔离依赖。\n当失败的客户端服务恢复时，线程池将会被清除，应用程序也会恢复，而不至于使整个Tomcat容器出现故障。\n如果一个客户端库的配置错误，线程池可以很快的感知这一错误（通过增加错误比例，延迟，超时，拒绝等），并可以在不影响应用程序的功能情况下来处理这些问题（可以通过动态配置来进行实时的改变）。\n如果一个客户端服务的性能变差，可以通过改变线程池的指标（错误、延迟、超时、拒绝）来进行属性的调整，并且这些调整可以不影响其他的客户端请求。\n\n\n\n\n信号量\n\n信号隔离是通过限制依赖服务的并发请求数，来控制隔离开关。信号隔离方式下，业务请求线程和执行依赖服务的线程是同一个线程（例如Tomcat容器线程）\n\n\n\n\n默认情况下，Hystrix 使用线程池模式\n\n线程池与信号量区别线程池：使用的是Hystrix内部维护的线程池，每一个依赖服务都会拥有自己的小线程池\n信号量隔离：是使用发起请求的线程去调用这个依赖服务，它只是一道关卡，信号量有多少，就允许多少个tomcat线程通过，然后执行\n\n\n适用场景：\n\n线程池技术，适合绝大多数场景，比如说我们对依赖服务的网络请求的调用和访问、需要对调用的 timeout 进行控制（捕捉 timeout 超时异常）。\n信号量技术，适合说你的访问不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，并且系统内部的代码，其实不涉及任何的网络请求，那么只要做信号量的普通限流就可以了，因为不需要去捕获 timeout 类似的问题。\n\nHystrix 隔离策略细粒度控制\ncommand key ：代表了一类 command，一般来说，代表了下游依赖服务的某个接口。\ncommand group ，代表了某一个下游依赖服务，这是很合理的，一个依赖服务可能会暴露出来多个接口，每个接口就是一个 command key。command group 在逻辑上对一堆 command key 的调用次数、成功次数、timeout 次数、失败次数等进行统计，可以看到某一个服务整体的一些访问情况。一般来说，推荐根据一个服务区划分出一个线程池，command key 默认都是属于同一个线程池的。\ncommand thread pool：代表了每个command key的线程池，默认大小为10\ncoreSize：设置线程池的大小，默认是 10。一般来说，用这个默认的 10 个线程大小就够了\nqueueSizeRejectionThreshold：控制queue满了之后拒绝的阈值，和最大队列数量(maxQueueSize)不是一个意思，默认为 5\n查看默认值的位置：在HystrixThreadPoolProperties类中查看\n\n\n说白点，就是说如果你的 command key 要用自己的线程池，可以定义自己的 thread pool key，就 ok 了。\n\nHystrix 执行时内部原理\n\n\n1.创建 command\n2.调用 command 执行方法要执行 command，可以在 4 个方法中选择其中的一个：execute()、queue()、observe()、toObservable()。\n\n3.检查是否开启缓存（不太常用）如果这个 command 开启了请求缓存 Request Cache，而且这个调用的结果在缓存中存在，那么直接从缓存中返回结果。否则，继续往后的步骤。\n\n4.检查是否开启了断路器检查这个 command 对应的依赖服务是否开启了断路器。如果断路器被打开了，那么 Hystrix 就不会执行这个 command，而是直接去执行 fallback 降级机制，返回降级结果。\n\n5.检查线程池/队列/信号量是否已满如果这个 command 线程池和队列已满，或者 semaphore 信号量已满，那么也不会执行 command，而是直接去调用 fallback 降级机制\n\n6.执行 command调用 HystrixObservableCommand 对象的 construct() 方法，或者 HystrixCommand 的 run() 方法来实际执行这个 command。\n如果是采用线程池方式，并且 HystrixCommand.run() 或者 HystrixObservableCommand.construct() 的执行时间超过了 timeout 时长的话，那么 command 所在的线程会抛出一个 TimeoutException，这时会执行 fallback 降级机制，不会去管 run() 或 construct() 返回的值了。另一种情况，如果 command 执行出错抛出了其它异常，那么也会走 fallback 降级。这两种情况下，Hystrix 都会发送异常事件给断路器统计\n\n7.断路健康检查Hystrix 会把每一个依赖服务的调用成功、失败、Reject、Timeout 等事件发送给 circuit breaker 断路器。断路器就会对这些事件的次数进行统计，根据异常事件发生的比例来决定是否要进行断路（熔断）。如果打开了断路器，那么在接下来一段时间内，会直接断路，返回降级结果。\n如果在之后，断路器尝试执行 command，调用没有出错，返回了正常结果，那么 Hystrix 就会把断路器关闭。\n\n8.调用 fallback 降级机制在以下几种情况中，Hystrix 会调用 fallback 降级机制。\n\n断路器处于打开状态；\n线程池/队列/semaphore 满了；\ncommand 执行超时；\nrun() 或者 construct() 抛出异常。\n\n不同的 command 执行方式，其 fallback 为空或者异常时的返回结果不同。\n\n对于 execute()，直接抛出异常。\n对于 queue()，返回一个 Future，调用 get() 时抛出异常\n\n\n\n深入 Hystrix 断路器执行原理Hystrix 断路器有三种状态\n\n关闭（Closed）：调用依赖服务的请求正常通过\n打开（Open）：阻断对依赖服务的请求调用，直接走FallBack逻辑\n半开（Half-Open）：\n\n状态转换关系如下：\n\n\n运行机制：在一次统计时间的 滑动窗口（默认10秒） 中，最少有20次请求通过断路器，且异常比例超过50%，就会进入打开状态，在打开断路器后，接下来的3000毫秒都不会去d请求依赖服务，而是直接走的fallBack机制\n3000毫秒后，会进入半开状态，新的请求依赖服务会被执行，如果执行成功，就进入关闭状态，如果失败，则再次进入打开状态\n两种最经典的降级机制\n纯内存数据在降级逻辑中，你可以在内存中维护一个 ehcache，作为一个纯内存的基于 LRU 自动清理的缓存，让数据放在缓存内。如果说外部依赖有异常，fallback 这里直接尝试从 ehcache 中获取数据。\n默认值fallback 降级逻辑中，也可以直接返回一个默认值。\n\n","slug":"Hystrix底层原理","date":"2021-05-03T20:31:56.000Z","categories_index":"","tags_index":"中间件,底层原理,Hystrix","author_index":"谢华客"},{"id":"3864b9afa9fa3172cb932c409fc2806d","title":"LinkedHashMap源码分析","content":"LinkedHashMap源码分析LinkedHashMap 继承于 HashMap，用来存储数据的Entry也是继承HashMap的Node节点，多了两个引用before，after，用来把节点变成双向链表\nstatic class Entry&lt;K,V> extends HashMap.Node&lt;K,V> &#123;\n    Entry&lt;K,V> before, after;\n    Entry(int hash, K key, V value, Node&lt;K,V> next) &#123;\n        super(hash, key, value, next);\n    &#125;\n&#125;\n\n添加put方法并没有去重写put方法，而是直接使用了HashMap的实现，在把节点插入对应的桶的链表时，才重写了newNode方法，也就是创建新节点，通过linkNodeLast方法将Entry接在双向链表尾部，所以linkedHashMap是带有插入的顺序性的\nprivate void linkNodeLast(LinkedHashMap.Entry&lt;K,V> p) &#123;\n    LinkedHashMap.Entry&lt;K,V> last = tail;\n    tail = p;\n    if (last == null)\n        head = p;\n    else &#123;\n        p.before = last;\n        last.after = p;\n    &#125;\n&#125;\n\n访问顺序的维护当创建LinkedHashMap时，传入accessOrder参数为true，就可以开启访问顺序维护\npublic LinkedHashMap(int initialCapacity,\n                     float loadFactor,\n                     boolean accessOrder) &#123;\n    super(initialCapacity, loadFactor);\n    // 开启访问顺序维护\n    this.accessOrder = accessOrder;\n&#125;\n\nLinkedHashMap重写了get方法 ，如果accesOrder为true，就会调用afterNodeAccess方法，内部实现是将这个节点移动到双链表的末尾\n","slug":"LinkedHashMap源码分析","date":"2021-05-03T20:28:47.000Z","categories_index":"","tags_index":"Java,源码分析","author_index":"谢华客"},{"id":"7f10a4946d2eb733c758ace15b1327e4","title":"HashMap源码分析(JDK8)","content":"HashMap源码分析(JDK8)一、jdk1.8容器初始化\n无参构造函数\n\n/**\n * DEFAULT_LOAD_FACTOR = 0.75\n**/\npublic HashMap() &#123;\n    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted\n&#125;\n\n\n两个参数构造函数\n\npublic HashMap(int initialCapacity, float loadFactor) &#123;\n    this.loadFactor = loadFactor;\n    this.threshold = tableSizeFor(initialCapacity);\n&#125;\n\n使用 threshold 来暂时保存 initialCapacity，并直接计算出真正的初始容量\n二、jdk1.8添加put2.1、HashMap的 putVal 方法\n中文总结：putVal时，会先检查数组是否进行初始化，如果没有，就进行初始化\n接下来通过与数组长度-1进行与操作获得桶下标，如果桶为空，直接放在桶上\n如果不为空，则判断是否为红黑树节点，如果是，则用红黑树的putTreeVal来进行插入\n否则就遍历桶数组，如果有key和插入的key一致，则覆盖，否则将节点插在链表末尾\n插入后检查链表长度是否大于8，大于8则进行树化，然后size++，如果size大于阈值，则进行扩容操作\n\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n               boolean evict) &#123;\n    Node&lt;K,V>[] tab; Node&lt;K,V> p; int n, i;\n    // 在第一次 putVal 时才会去初始化 table 数组\n    if ((tab = table) == null || (n = tab.length) == 0)\n        n = (tab = resize()).length;\n    if ((p = tab[i = (n - 1) &amp; hash]) == null)\n        tab[i] = newNode(hash, key, value, null);\n    else &#123;\n        Node&lt;K,V> e; K k;\n        if (p.hash == hash &amp;&amp;\n            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))\n            e = p;\n        else if (p instanceof TreeNode)\n            e = ((TreeNode&lt;K,V>)p).putTreeVal(this, tab, hash, key, value);\n        else &#123;\n            for (int binCount = 0; ; ++binCount) &#123;\n                if ((e = p.next) == null) &#123;\n                    p.next = newNode(hash, key, value, null);\n                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                        treeifyBin(tab, hash);\n                    break;\n                &#125;\n                if (e.hash == hash &amp;&amp;\n                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))\n                    break;\n                p = e;\n            &#125;\n        &#125;\n        if (e != null) &#123; // existing mapping for key\n            V oldValue = e.value;\n            if (!onlyIfAbsent || oldValue == null)\n                e.value = value;\n            afterNodeAccess(e);\n            return oldValue;\n        &#125;\n    &#125;\n    ++modCount;\n    if (++size > threshold)\n        resize();\n    afterNodeInsertion(evict);\n    return null;\n&#125;\n\n2.2、HashMap的初始化方法\n中文总结：1.8的扩容和初始化都在resize方法中进行，会先通过原数组的长度来判断要进行扩容还是初始化\n当原数组长度为0时，说明是没进行初始化，会继续判断原阈值是否为0，当阈值不为0，则使用阈值进行初始化，因为初始长度暂时放在阈值字段中，如果为0，则使用默认的初始容量16，然后创建table数组返回\n\nfinal Node&lt;K,V>[] resize() &#123;\n    Node&lt;K,V>[] oldTab = table;\n    int oldCap = (oldTab == null) ? 0 : oldTab.length;\n    int oldThr = threshold;\n    int newCap, newThr = 0;\n    if (oldCap > 0) &#123;\n        if (oldCap >= MAXIMUM_CAPACITY) &#123;\n            threshold = Integer.MAX_VALUE;\n            return oldTab;\n        &#125;\n        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;\n                 oldCap >= DEFAULT_INITIAL_CAPACITY)\n            newThr = oldThr &lt;&lt; 1; // double threshold\n    &#125;\n    // 传入初始容量的情况\n    else if (oldThr > 0) // initial capacity was placed in threshold\n        newCap = oldThr;\n    else &#123;               // zero initial threshold signifies using defaults\n        newCap = DEFAULT_INITIAL_CAPACITY;\n        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n    &#125;\n    if (newThr == 0) &#123;\n        float ft = (float)newCap * loadFactor;\n        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?\n                  (int)ft : Integer.MAX_VALUE);\n    &#125;\n    threshold = newThr;\n    @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;)\n    Node&lt;K,V>[] newTab = (Node&lt;K,V>[])new Node[newCap];\n    table = newTab;\n    // 后面的扩容代码被我删除了，因为讲解的是初始化\n    return newTab;\n&#125;\n\n2.3、内部二次hash方法\n总结：获取对象本身的hash值，进行无符号右移16位，使得高16位移动到低16位，再和原来的进行异或操作\n这样高16位就可以和低16位进行特征混合，这样就可以让高十六位也参与到hash值的运算中来，降低碰撞\n\nstatic final int hash(Object key) &#123;\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n&#125;\n\n三、hashmap扩容\n总结：\n\n前面的初始化部分就不赘述了，扩容开始时，遍历每个非空桶数组，如果桶数组只有一个元素，则直接重新计算桶下标放到新数组中\n然后判断是否为树节点，如果是，则使用树的split方法进行转移\n最后的情况就是链表的转移了，首先会使用两个链表，然后对每个节点的hash值和原数组长度进行与操作，结果要么为0，就放到第一个链表当中，否则放到第二个链表当中，最后这个桶会分成两个链表，第一个结果为0的链表直接放在下标和原数组一样的新数组的桶中，另一个链表则是新数组中原数组下标+原数组长度的那个桶\n对每个桶都这样操作，就完成了元素的转移\n\n\n为什么是这样转移的？\n答：因为计算桶下标是和数组长度-1进行与操作，扩容成原来的二倍后，数组长度-1在二进制当中也就是多了一个位从0变成1，这个位正好就是原数组长度值为1的那个位，\n而计算桶数组是使用与操作，相当于新的桶数组下标会不会改变取决于hash值在那一位上是否为1，如果hash值在那一位上为0，那么重新计算桶数组下标时，那一位也不会参与运算，和原来是没任何区别的，所以下标肯定是一样的，而为1的话，就参与了运算，那结果自然是多出来了这个位置，而这个位置就是原数组长度，所以最后的下标是原下标+原数组长度\nfinal Node&lt;K,V>[] resize() &#123;\n    Node&lt;K,V>[] oldTab = table;\n    int oldCap = (oldTab == null) ? 0 : oldTab.length;\n    int oldThr = threshold;\n    int newCap, newThr = 0;\n    if (oldCap > 0) &#123;\n        // 扩容逻辑，扩大为原数组的两倍\n        if (oldCap >= MAXIMUM_CAPACITY) &#123;\n            threshold = Integer.MAX_VALUE;\n            return oldTab;\n        &#125;\n        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;\n                 oldCap >= DEFAULT_INITIAL_CAPACITY)\n            newThr = oldThr &lt;&lt; 1; // double threshold\n    &#125;\n    else if (oldThr > 0) // initial capacity was placed in threshold\n        newCap = oldThr;\n    else &#123;               // zero initial threshold signifies using defaults\n        newCap = DEFAULT_INITIAL_CAPACITY;\n        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n    &#125;\n    if (newThr == 0) &#123;\n        float ft = (float)newCap * loadFactor;\n        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?\n                  (int)ft : Integer.MAX_VALUE);\n    &#125;\n    threshold = newThr;\n    @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;)\n    // 创建新数组\n    Node&lt;K,V>[] newTab = (Node&lt;K,V>[])new Node[newCap];\n    table = newTab;\n    // 开始进行元素的转移\n    if (oldTab != null) &#123;\n        for (int j = 0; j &lt; oldCap; ++j) &#123;\n            Node&lt;K,V> e;\n            if ((e = oldTab[j]) != null) &#123;\n                oldTab[j] = null;\n                if (e.next == null)\n                    // 如果桶数组只有一个元素，则直接重新计算桶下标放到新数组中\n                    newTab[e.hash &amp; (newCap - 1)] = e;\n                else if (e instanceof TreeNode)\n                    // 如果是树节点，则使用树的split方法进行转移\n                    ((TreeNode&lt;K,V>)e).split(this, newTab, j, oldCap);\n                else &#123; // preserve order\n                    // 这部分非常关键，具体操作在总结处给出\n                    Node&lt;K,V> loHead = null, loTail = null;\n                    Node&lt;K,V> hiHead = null, hiTail = null;\n                    Node&lt;K,V> next;\n                    do &#123;\n                        next = e.next;\n                        if ((e.hash &amp; oldCap) == 0) &#123;\n                            if (loTail == null)\n                                loHead = e;\n                            else\n                                loTail.next = e;\n                            loTail = e;\n                        &#125;\n                        else &#123;\n                            if (hiTail == null)\n                                hiHead = e;\n                            else\n                                hiTail.next = e;\n                            hiTail = e;\n                        &#125;\n                    &#125; while ((e = next) != null);\n                    if (loTail != null) &#123;\n                        loTail.next = null;\n                        newTab[j] = loHead;\n                    &#125;\n                    if (hiTail != null) &#123;\n                        hiTail.next = null;\n                        newTab[j + oldCap] = hiHead;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n    return newTab;\n&#125;\n\n\n由于插入和扩容都是头插，可能在多线程的时候导致链表头尾相连，造成死循环\n\n\n总结：\n\n对于jdk1.8的HashMap来说，使用的是数组+链表+红黑树的方式来存储k-v键值对\nHashMap提供多个构造函数，对于传进来的初始大小，会在构造函数中计算出离这个初始值最近的2的次幂，作为真正的初始值，并放在阈值字段threadhold当中\n而初始化操作会在第一次putVal时进行，进行put时如果发现table数组为空并且数组长度等于0，则进行初始化，初始化和扩容都在resize方法中一起完成\n在resize方法中，会先判断原数组长度，如果为0，则表示要进行初始化，对于初始化阶段，接下来会判断原threadhold是否为0，如果不为0，则threadhold的值就是初始容量，否则使用默认的初始值16，然后使用这个初始容量来创建数组，然后返回\n而对于正常的put操作，先获取对象本身的hashcode，然后对hashcode进行无符号右移16位操作，将高16位移到低16位上，然后和原来的hashcode进行一个异或操作，异或操作是一个无进位加法，这样高16位就和低16位混合在一起，目的是为了使得高16位也参与到hash的计算中。获得hash值后，再和数组长度-1进行与操作，获得桶数组下标，接下来如果这个桶没有元素，就直接将节点放在这个桶，如果这个桶是树节点，就使用树的PutTreeVal方法进行插入，否则就是一个链表的尾插了，具体就是遍历链表，如果中间发现key值一样的节点，那就直接替换，否则到了链表末尾，就放在末尾\n插入后如果这个桶的链表长度超过8，就会转换成红黑树，而在插入操作后，如果size操作过了阈值，就进行扩容操作\n在扩容操作中，初始化的部分就不提了，会去遍历每个非空桶，如果是树节点，则使用树的split操作进行转移，而如果是链表，就会创建两个链表，然后把桶的每个元素的hash值和原数组长度进行与操作，如果为0，则放在第一个链表中，否则放在第二个链表中。完成遍历后，结果为0的链表会直接放在新数组和原来一样的下标的桶中，而另一个则是放在新数组中原下标+原数组长度的下标的桶中\n\n\n红黑树的大致实现：\n红黑树具有一些特性：它的根节点和叶子节点始终是黑色的，而红色节点的两个子节点都是黑色，也就相当于叶子节点到跟节点之间不会出现两个连续的红色节点，并且含有相同数目的黑色节点，这些性质保证了红黑树在满足平衡二叉树特性的前提下，可以做到从根节点到叶子节点的路径差不会超过两倍，对于插入的新节点都是以红色节点来插入的，插入后如果对树的规则造成了破坏，就通过左旋，右旋，以及变色来向上恢复红黑树\n可以使用平衡二叉树来代替红黑树吗\n因为二叉搜索树在极端情况下会退化成链表，所以出现了二叉平衡树，二叉平衡树要求每个节点的子树高度差不能超过1，而红黑树是是允许超过1的，最多能允许根节点到叶子节点的路径长度的最大差值为二倍\n二叉平衡树每次删除一个节点或添加一个节点，为了保持规则，需要对整个树进行维护，代价很高，而红黑树在插入和删除某个节点，只需要通过左旋，右旋和变色，维护局部的子树就可以完成恢复，所以代价更小\n\n","slug":"HashMap源码分析(JDK8)","date":"2021-05-03T17:00:48.000Z","categories_index":"","tags_index":"Java,源码分析","author_index":"谢华客"},{"id":"1009ae073b519734ad64e46d744b178f","title":"HashMap源码分析(JDK7)","content":"HashMap源码分析-JDK1.7一、jdk1.7容器初始化\n无参构造函数\n\n/**\n * DEFAULT_INITIAL_CAPACITY = 16\n * DEFAULT_LOAD_FACTOR = 0.75\n**/\npublic HashMap() &#123;\n    this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);\n&#125;\n\n\n两个参数构造函数\n\npublic HashMap(int initialCapacity, float loadFactor) &#123;\n\t// 不重要的代码已经直接不放了\n    this.loadFactor = loadFactor;\n    threshold = initialCapacity;\n    init();\n&#125;\n\n使用 threshold 来暂时保存 initialCapacity，init() 是用来初始化llinkedHashMap的\n二、jdk1.7添加put2.1、HashMap的put方法public V put(K key, V value) &#123;\n    if (table &#x3D;&#x3D; EMPTY_TABLE) &#123;\n        &#x2F;&#x2F; 初始化table数组\n        inflateTable(threshold);\n    &#125;\n    if (key &#x3D;&#x3D; null)\n        return putForNullKey(value);\n    &#x2F;&#x2F; 获取hash值\n    int hash &#x3D; hash(key);\n    &#x2F;&#x2F; 与数据长度减1进行与操作获得桶下标\n    int i &#x3D; indexFor(hash, table.length);\n    for (Entry&lt;K,V&gt; e &#x3D; table[i]; e !&#x3D; null; e &#x3D; e.next) &#123;\n        Object k;\n        if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || key.equals(k))) &#123;\n            V oldValue &#x3D; e.value;\n            e.value &#x3D; value;\n            e.recordAccess(this);\n            return oldValue;\n        &#125;\n    &#125;\n\n    modCount++;\n    &#x2F;&#x2F; 添加方法\n    addEntry(hash, key, value, i);\n    return null;\n&#125;\n\n2.2、HashMap的初始化方法初始化就是把传进来的初始容量变成一个最小的2次幂\n// 根据之前传进来的值找到一个的大于等于这个数的二次幂\nprivate void inflateTable(int toSize) &#123;\n    // 找到一个2的次幂，大于等于这个size\n    int capacity = roundUpToPowerOf2(toSize);\n\t\n    threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1);\n    table = new Entry[capacity];\n&#125;\n\n2.3、添加元素方法 addEntry直接使用头插法添加元素\nvoid addEntry(int hash, K key, V value, int bucketIndex) &#123;\n    if ((size >= threshold) &amp;&amp; (null != table[bucketIndex])) &#123;\n        // 超过阈值并且桶不为空会进行扩容\n        resize(2 * table.length);\n        hash = (null != key) ? hash(key) : 0;\n        bucketIndex = indexFor(hash, table.length);\n    &#125;\n\n    createEntry(hash, key, value, bucketIndex);\n&#125;\n\n// 真正添加元素的方法，直接使用头插法添加\nvoid createEntry(int hash, K key, V value, int bucketIndex) &#123;\n    Entry&lt;K,V> e = table[bucketIndex];\n    table[bucketIndex] = new Entry&lt;>(hash, key, value, e);\n    size++;\n&#125;\n\n2.4、内部二次hash方法\n// 面试这么回答: 对于String类，使用stringHash32来计算hash值\n// 而其他类型则采用了异或的方式，对多个地方进行异或\n// 先将hash值无符号右移20位进行一次异或，然后右移14位再进行一次，7，4也各来一次\nfinal int hash(Object k) &#123;\n    int h = hashSeed;\n    if (0 != h &amp;&amp; k instanceof String) &#123;\n        return sun.misc.Hashing.stringHash32((String) k);\n    &#125;\n\n    h ^= k.hashCode();\n\n    // This function ensures that hashCodes that differ only by\n    // constant multiples at each bit position have a bounded\n    // number of collisions (approximately 8 at default load factor).\n    h ^= (h >>> 20) ^ (h >>> 12);\n    return h ^ (h >>> 7) ^ (h >>> 4);\n&#125;\n\n三、hashmap扩容生成两倍的数组，并进行元素的重新hash插入\nvoid resize(int newCapacity) &#123;\n    Entry[] oldTable = table;\n    int oldCapacity = oldTable.length;\n    // 如果超过阈值，就直接返回，不进行扩容\n    if (oldCapacity == MAXIMUM_CAPACITY) &#123;\n        threshold = Integer.MAX_VALUE;\n        return;\n    &#125;\n\n    Entry[] newTable = new Entry[newCapacity];\n    transfer(newTable, initHashSeedAsNeeded(newCapacity));\n    table = newTable;\n    threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);\n&#125;\n\n元素转移的实现\n\n由于插入和扩容都是头插，可能在多线程的时候导致链表头尾相连，造成死循环\n\nvoid transfer(Entry[] newTable, boolean rehash) &#123;\n    int newCapacity = newTable.length;\n    // 对于每一个桶，获取到头节点进行重新的hash，也是使用的头插法\n    for (Entry&lt;K,V> e : table) &#123;\n        while(null != e) &#123;\n            Entry&lt;K,V> next = e.next;\n            if (rehash) &#123;\n                e.hash = null == e.key ? 0 : hash(e.key);\n            &#125;\n            int i = indexFor(e.hash, newCapacity);\n            e.next = newTable[i];\n            newTable[i] = e;\n            e = next;\n        &#125;\n    &#125;\n&#125;\n\n\n总结：\n\n对于jdk1.7的HashMap来说，采用的是数组加链表的形式存储数据，使用Entry来保存每个键值对，虽然提供了多个构造函数，对于传进来的初始容量，都只会把它保存在threadhold中不做任何操作， 第一次put的时，会先检查table数组是否为空，如果为空，则进行table的初始化，根据初始值获得大于等于初始值的2的次方，比如13则为16，创建桶数组\n对于put操作，会先获得对象自身的hash值，并进行第二次hash，如果是String，则调用Stringhash32方法获取hash值，而其他类型，则分别对原hash值右移20位，14位，7位，4位进行一个异或操作，获得最终的hash值，并和数组长度-1进行与操作获得数组桶下标\n遍历这个桶，如果在这个桶中找到key和要插入的key一致，则覆盖value值，如果不是则使用头插法把节点放到桶的第一个元素上\n而对于扩容，当容量超过阈值后，就进入扩容，长度为原数组的两倍，并遍历每个桶，对桶的元素进行重新hash，并插入新table，也是使用的头插法\n\n\n","slug":"HashMap源码分析(JDK7)","date":"2021-05-03T16:56:19.000Z","categories_index":"","tags_index":"Java,源码分析","author_index":"谢华客"},{"id":"f6da82311c70124223da9323fdd70f40","title":"ConcurrentHashMap源码分析(JDK8)","content":"一、jdk1.8容器初始化1、源码分析\n在jdk8的ConcurrentHashMap中一共有5个构造方法，这四个构造方法中都没有对内部的数组做初始化， 只是对一些变量的初始值做了处理\njdk8的ConcurrentHashMap的数组初始化是在第一次添加元素时完成\n\n//没有维护任何变量的操作，如果调用该方法，数组长度默认是16\npublic ConcurrentHashMap() &#123;\n&#125;\n\n//传递进来一个初始容量，ConcurrentHashMap会基于这个值计算一个比这个值大的2的幂次方数作为初始容量\npublic ConcurrentHashMap(int initialCapacity) &#123;\n    if (initialCapacity &lt; 0)\n        throw new IllegalArgumentException();\n    int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?\n               MAXIMUM_CAPACITY :\n               tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));\n    this.sizeCtl = cap;\n&#125;\n\n\n注意，调用这个方法，得到的初始容量和我们之前讲的HashMap以及jdk7的ConcurrentHashMap不同，即使你传递的是一个2的幂次方数，该方法计算出来的初始容量依然是比这个值大的2的幂次方数\n\n//调用四个参数的构造\npublic ConcurrentHashMap(int initialCapacity, float loadFactor) &#123;\n    this(initialCapacity, loadFactor, 1);\n&#125;\n\n//计算一个大于或者等于给定的容量值，该值是2的幂次方数作为初始容量\npublic ConcurrentHashMap(int initialCapacity,\n                         float loadFactor, int concurrencyLevel) &#123;\n    if (!(loadFactor > 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0)\n        throw new IllegalArgumentException();\n    if (initialCapacity &lt; concurrencyLevel)   // Use at least as many bins\n        initialCapacity = concurrencyLevel;   // as estimated threads\n    long size = (long)(1.0 + (long)initialCapacity / loadFactor);\n    int cap = (size >= (long)MAXIMUM_CAPACITY) ?\n        MAXIMUM_CAPACITY : tableSizeFor((int)size);\n    this.sizeCtl = cap;\n&#125;\n\n//基于一个Map集合，构建一个ConcurrentHashMap\n//初始容量为16\npublic ConcurrentHashMap(Map&lt;? extends K, ? extends V> m) &#123;\n    this.sizeCtl = DEFAULT_CAPACITY;\n    putAll(m);\n&#125;\n\n2、sizeCtl含义解释\n注意：以上这些构造方法中，都涉及到一个变量sizeCtl，这个变量是一个非常重要的变量，而且具有非常丰富的含义，它的值不同，对应的含义也不一样，这里我们先对这个变量不同的值的含义做一下说明，后续源码分析过程中，进一步解释\nsizeCtl为0，代表数组未初始化， 且数组的初始容量为16\nsizeCtl为正数，如果数组未初始化，那么其记录的是数组的初始容量，如果数组已经初始化，那么其记录的是数组的扩容阈值\nsizeCtl为-1，表示数组正在进行初始化\nsizeCtl小于0，并且不是-1，表示数组正在扩容， -(1+n)，表示此时有n个线程正在共同完成数组的扩容操作\n\n二、jdk1.8添加安全1、源码分析1.1、添加元素put/putVal方法public V put(K key, V value) &#123;\n    return putVal(key, value, false);\n&#125;\n\nfinal V putVal(K key, V value, boolean onlyIfAbsent) &#123;\n    //如果有空值或者空键，直接抛异常\n    if (key == null || value == null) throw new NullPointerException();\n    //基于key计算hash值，并进行一定的扰动\n    int hash = spread(key.hashCode());\n    //记录某个桶上元素的个数，如果超过8个，会转成红黑树\n    int binCount = 0;\n    for (Node&lt;K,V>[] tab = table;;) &#123;\n        Node&lt;K,V> f; int n, i, fh;\n        //如果数组还未初始化，先对数组进行初始化\n        if (tab == null || (n = tab.length) == 0)\n            tab = initTable();\n\t    //如果hash计算得到的桶位置没有元素，利用cas将元素添加\n        else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123;\n            //cas+自旋（和外侧的for构成自旋循环），保证元素添加安全\n            if (casTabAt(tab, i, null,\n                         new Node&lt;K,V>(hash, key, value, null)))\n                break;                   // no lock when adding to empty bin\n        &#125;\n        //如果hash计算得到的桶位置元素的hash值为MOVED，证明正在扩容，那么协助扩容\n        else if ((fh = f.hash) == MOVED)\n            tab = helpTransfer(tab, f);\n        else &#123;\n            //hash计算的桶位置元素不为空，且当前没有处于扩容操作，进行元素添加\n            V oldVal = null;\n            //对当前桶进行加锁，保证线程安全，执行元素添加操作\n            synchronized (f) &#123;\n                if (tabAt(tab, i) == f) &#123;\n                    //普通链表节点\n                    if (fh >= 0) &#123;\n                        binCount = 1;\n                        for (Node&lt;K,V> e = f;; ++binCount) &#123;\n                            K ek;\n                            if (e.hash == hash &amp;&amp;\n                                ((ek = e.key) == key ||\n                                 (ek != null &amp;&amp; key.equals(ek)))) &#123;\n                                oldVal = e.val;\n                                if (!onlyIfAbsent)\n                                    e.val = value;\n                                break;\n                            &#125;\n                            Node&lt;K,V> pred = e;\n                            if ((e = e.next) == null) &#123;\n                                pred.next = new Node&lt;K,V>(hash, key,\n                                                          value, null);\n                                break;\n                            &#125;\n                        &#125;\n                    &#125;\n                    //树节点，将元素添加到红黑树中\n                    else if (f instanceof TreeBin) &#123;\n                        Node&lt;K,V> p;\n                        binCount = 2;\n                        if ((p = ((TreeBin&lt;K,V>)f).putTreeVal(hash, key,\n                                                       value)) != null) &#123;\n                            oldVal = p.val;\n                            if (!onlyIfAbsent)\n                                p.val = value;\n                        &#125;\n                    &#125;\n                &#125;\n            &#125;\n            if (binCount != 0) &#123;\n                //链表长度大于/等于8，将链表转成红黑树\n                if (binCount >= TREEIFY_THRESHOLD)\n                    treeifyBin(tab, i);\n                //如果是重复键，直接将旧值返回\n                if (oldVal != null)\n                    return oldVal;\n                break;\n            &#125;\n        &#125;\n    &#125;\n    //添加的是新元素，维护集合长度，并判断是否要进行扩容操作\n    addCount(1L, binCount);\n    return null;\n&#125;\n\n\n通过以上源码，我们可以看到，当需要添加元素时，会针对当前元素所对应的桶位进行加锁操作，这样一方面保证元素添加时，多线程的安全，同时对某个桶位加锁不会影响其他桶位的操作，进一步提升多线程的并发效率\n\n1.2、数组初始化，initTable方法private final Node&lt;K,V>[] initTable() &#123;\n    Node&lt;K,V>[] tab; int sc;\n    //cas+自旋，保证线程安全，对数组进行初始化操作\n    while ((tab = table) == null || tab.length == 0) &#123;\n        //如果sizeCtl的值（-1）小于0，说明此时正在初始化， 让出cpu\n        if ((sc = sizeCtl) &lt; 0)\n            Thread.yield(); // lost initialization race; just spin\n        //cas修改sizeCtl的值为-1，修改成功，进行数组初始化，失败，继续自旋\n        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123;\n            try &#123;\n                if ((tab = table) == null || tab.length == 0) &#123;\n                    //sizeCtl为0，取默认长度16，否则去sizeCtl的值\n                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;\n                    @SuppressWarnings(\"unchecked\")\n                    //基于初始长度，构建数组对象\n                    Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n];\n                    table = tab = nt;\n                    //计算扩容阈值，并赋值给sc\n                    sc = n - (n >>> 2);\n                &#125;\n            &#125; finally &#123;\n                //将扩容阈值，赋值给sizeCtl\n                sizeCtl = sc;\n            &#125;\n            break;\n        &#125;\n    &#125;\n    return tab;\n&#125;\n\n2、图解2.1、put加锁图解\n\n\n\n三、jdk1.8扩容安全1、源码分析private final void transfer(Node&lt;K,V>[] tab, Node&lt;K,V>[] nextTab) &#123;\n    int n = tab.length, stride;\n    //如果是多cpu，那么每个线程划分任务，最小任务量是16个桶位的迁移，每个线程是 数组长度 / 8 / CPU核心个数\n    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)\n        stride = MIN_TRANSFER_STRIDE; // subdivide range\n    //如果是扩容线程，此时新数组为null\n    if (nextTab == null) &#123;            // initiating\n        try &#123;\n            @SuppressWarnings(\"unchecked\")\n            //两倍扩容创建新数组\n            Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n &lt;&lt; 1];\n            nextTab = nt;\n        &#125; catch (Throwable ex) &#123;      // try to cope with OOME\n            sizeCtl = Integer.MAX_VALUE;\n            return;\n        &#125;\n        nextTable = nextTab;\n        //记录线程开始迁移的桶位，从后往前迁移\n        transferIndex = n;\n    &#125;\n    //记录新数组的末尾\n    int nextn = nextTab.length;\n    //已经迁移的桶位，会用这个节点占位（这个节点的hash值为-1--MOVED）\n    ForwardingNode&lt;K,V> fwd = new ForwardingNode&lt;K,V>(nextTab);\n    boolean advance = true;\n    boolean finishing = false; // to ensure sweep before committing nextTab\n    for (int i = 0, bound = 0;;) &#123;\n        Node&lt;K,V> f; int fh;\n        while (advance) &#123;\n            int nextIndex, nextBound;\n            //i记录当前正在迁移桶位的索引值\n            //bound记录下一次任务迁移的开始桶位\n            \n            //--i >= bound 成立表示当前线程分配的迁移任务还没有完成\n            if (--i >= bound || finishing)\n                advance = false;\n            //没有元素需要迁移 -- 后续会去将扩容线程数减1，并判断扩容是否完成\n            else if ((nextIndex = transferIndex) &lt;= 0) &#123;\n                i = -1;\n                advance = false;\n            &#125;\n            //计算下一次任务迁移的开始桶位，并将这个值赋值给transferIndex\n            else if (U.compareAndSwapInt\n                     (this, TRANSFERINDEX, nextIndex,\n                      nextBound = (nextIndex > stride ?\n                                   nextIndex - stride : 0))) &#123;\n                bound = nextBound;\n                i = nextIndex - 1;\n                advance = false;\n            &#125;\n        &#125;\n        //如果没有更多的需要迁移的桶位，就进入该if\n        if (i &lt; 0 || i >= n || i + n >= nextn) &#123;\n            int sc;\n            //扩容结束后，保存新数组，并重新计算扩容阈值，赋值给sizeCtl\n            if (finishing) &#123;\n                nextTable = null;\n                table = nextTab;\n                sizeCtl = (n &lt;&lt; 1) - (n >>> 1);\n                return;\n            &#125;\n\t\t   //扩容任务线程数减1\n            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123;\n                //判断当前所有扩容任务线程是否都执行完成\n                if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)\n                    return;\n                //所有扩容线程都执行完，标识结束\n                finishing = advance = true;\n                i = n; // recheck before commit\n            &#125;\n        &#125;\n        //当前迁移的桶位没有元素，直接在该位置添加一个fwd节点\n        else if ((f = tabAt(tab, i)) == null)\n            advance = casTabAt(tab, i, null, fwd);\n        //当前节点已经被迁移\n        else if ((fh = f.hash) == MOVED)\n            advance = true; // already processed\n        else &#123;\n            //当前节点需要迁移，加锁迁移，保证多线程安全\n            //此处迁移逻辑和jdk7的ConcurrentHashMap相同，不再赘述\n            synchronized (f) &#123;\n                if (tabAt(tab, i) == f) &#123;\n                    Node&lt;K,V> ln, hn;\n                    if (fh >= 0) &#123;\n                        int runBit = fh &amp; n;\n                        Node&lt;K,V> lastRun = f;\n                        for (Node&lt;K,V> p = f.next; p != null; p = p.next) &#123;\n                            int b = p.hash &amp; n;\n                            if (b != runBit) &#123;\n                                runBit = b;\n                                lastRun = p;\n                            &#125;\n                        &#125;\n                        if (runBit == 0) &#123;\n                            ln = lastRun;\n                            hn = null;\n                        &#125;\n                        else &#123;\n                            hn = lastRun;\n                            ln = null;\n                        &#125;\n                        for (Node&lt;K,V> p = f; p != lastRun; p = p.next) &#123;\n                            int ph = p.hash; K pk = p.key; V pv = p.val;\n                            if ((ph &amp; n) == 0)\n                                ln = new Node&lt;K,V>(ph, pk, pv, ln);\n                            else\n                                hn = new Node&lt;K,V>(ph, pk, pv, hn);\n                        &#125;\n                        setTabAt(nextTab, i, ln);\n                        setTabAt(nextTab, i + n, hn);\n                        setTabAt(tab, i, fwd);\n                        advance = true;\n                    &#125;\n                    else if (f instanceof TreeBin) &#123;\n                        TreeBin&lt;K,V> t = (TreeBin&lt;K,V>)f;\n                        TreeNode&lt;K,V> lo = null, loTail = null;\n                        TreeNode&lt;K,V> hi = null, hiTail = null;\n                        int lc = 0, hc = 0;\n                        for (Node&lt;K,V> e = t.first; e != null; e = e.next) &#123;\n                            int h = e.hash;\n                            TreeNode&lt;K,V> p = new TreeNode&lt;K,V>\n                                (h, e.key, e.val, null, null);\n                            if ((h &amp; n) == 0) &#123;\n                                if ((p.prev = loTail) == null)\n                                    lo = p;\n                                else\n                                    loTail.next = p;\n                                loTail = p;\n                                ++lc;\n                            &#125;\n                            else &#123;\n                                if ((p.prev = hiTail) == null)\n                                    hi = p;\n                                else\n                                    hiTail.next = p;\n                                hiTail = p;\n                                ++hc;\n                            &#125;\n                        &#125;\n                        ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :\n                            (hc != 0) ? new TreeBin&lt;K,V>(lo) : t;\n                        hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :\n                            (lc != 0) ? new TreeBin&lt;K,V>(hi) : t;\n                        setTabAt(nextTab, i, ln);\n                        setTabAt(nextTab, i + n, hn);\n                        setTabAt(tab, i, fwd);\n                        advance = true;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n2、图解\n\n\n\n四、jdk1.8多线程扩容效率改进\n多线程协助扩容的操作会在两个地方被触发：\n① 当添加元素时，发现添加的元素对用的桶位为fwd节点，就会先去协助扩容，然后再添加元素\n② 当添加完元素后，判断当前元素个数达到了扩容阈值，此时发现sizeCtl的值小于0，并且新数组不为空，这个时候，会去协助扩容\n\n1、源码分析1.1、元素未添加，先协助扩容，扩容完后再添加元素final V putVal(K key, V value, boolean onlyIfAbsent) &#123;\n    if (key == null || value == null) throw new NullPointerException();\n    int hash = spread(key.hashCode());\n    int binCount = 0;\n    for (Node&lt;K,V>[] tab = table;;) &#123;\n        Node&lt;K,V> f; int n, i, fh;\n        if (tab == null || (n = tab.length) == 0)\n            tab = initTable();\n        else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123;\n            if (casTabAt(tab, i, null,\n                         new Node&lt;K,V>(hash, key, value, null)))\n                break;                   // no lock when adding to empty bin\n        &#125;\n        //发现此处为fwd节点，协助扩容，扩容结束后，再循环回来添加元素\n        else if ((fh = f.hash) == MOVED)\n            tab = helpTransfer(tab, f);\n        \n        //省略代码\n\nfinal Node&lt;K,V>[] helpTransfer(Node&lt;K,V>[] tab, Node&lt;K,V> f) &#123;\n    Node&lt;K,V>[] nextTab; int sc;\n    if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp;\n        (nextTab = ((ForwardingNode&lt;K,V>)f).nextTable) != null) &#123;\n        int rs = resizeStamp(tab.length);\n        while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp;\n               (sc = sizeCtl) &lt; 0) &#123;\n            if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||\n                sc == rs + MAX_RESIZERS || transferIndex &lt;= 0)\n                break;\n            if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123;\n                //扩容，传递一个不是null的nextTab\n                transfer(tab, nextTab);\n                break;\n            &#125;\n        &#125;\n        return nextTab;\n    &#125;\n    return table;\n&#125;\n\n1.2、先添加元素，再协助扩容private final void addCount(long x, int check) &#123;\n    //省略代码\n    \n    if (check >= 0) &#123;\n        Node&lt;K,V>[] tab, nt; int n, sc;\n  \t    //元素个数达到扩容阈值\n        while (s >= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp;\n               (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123;\n            int rs = resizeStamp(n);\n            //sizeCtl小于0，说明正在执行扩容，那么协助扩容\n            if (sc &lt; 0) &#123;\n                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||\n                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||\n                    transferIndex &lt;= 0)\n                    break;\n                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))\n                    transfer(tab, nt);\n            &#125;\n            else if (U.compareAndSwapInt(this, SIZECTL, sc,\n                                         (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2))\n                transfer(tab, null);\n            s = sumCount();\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n注意：扩容的代码都在transfer方法中，这里不再赘述\n\n2、图解\n\n\n\n五、集合长度的累计方式1、源码分析1.1、addCount方法\n① CounterCell数组不为空，优先利用数组中的CounterCell记录数量\n② 如果数组为空，尝试对baseCount进行累加，失败后，会执行fullAddCount逻辑\n③ 如果是添加元素操作，会继续判断是否需要扩容\n\nprivate final void addCount(long x, int check) &#123;\n    CounterCell[] as; long b, s;\n    //当CounterCell数组不为空，则优先利用数组中的CounterCell记录数量\n    //或者当baseCount的累加操作失败，会利用数组中的CounterCell记录数量\n    if ((as = counterCells) != null ||\n        !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123;\n        CounterCell a; long v; int m;\n        //标识是否有多线程竞争\n        boolean uncontended = true;\n        //当as数组为空\n        //或者当as长度为0\n        //或者当前线程对应的as数组桶位的元素为空\n        //或者当前线程对应的as数组桶位不为空，但是累加失败\n        if (as == null || (m = as.length - 1) &lt; 0 ||\n            (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null ||\n            !(uncontended =\n              U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123;\n            //以上任何一种情况成立，都会进入该方法，传入的uncontended是false\n            fullAddCount(x, uncontended);\n            return;\n        &#125;\n        if (check &lt;= 1)\n            return;\n        //计算元素个数\n        s = sumCount();\n    &#125;\n    if (check >= 0) &#123;\n        Node&lt;K,V>[] tab, nt; int n, sc;\n        //当元素个数达到扩容阈值\n        //并且数组不为空\n        //并且数组长度小于限定的最大值\n        //满足以上所有条件，执行扩容\n        while (s >= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp;\n               (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123;\n            //这个是一个很大的正数\n            int rs = resizeStamp(n);\n            //sc小于0，说明有线程正在扩容，那么会协助扩容\n            if (sc &lt; 0) &#123;\n                //扩容结束或者扩容线程数达到最大值或者扩容后的数组为null或者没有更多的桶位需要转移，结束操作\n                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||\n                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||\n                    transferIndex &lt;= 0)\n                    break;\n                //扩容线程加1，成功后，进行协助扩容操作\n                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))\n                    //协助扩容，newTable不为null\n                    transfer(tab, nt);\n            &#125;\n            //没有其他线程在进行扩容，达到扩容阈值后，给sizeCtl赋了一个很大的负数\n            //1+1=2 --》 代表此时有一个线程在扩容\n            \n            //rs &lt;&lt; RESIZE_STAMP_SHIFT)是一个很大的负数\n            else if (U.compareAndSwapInt(this, SIZECTL, sc,\n                                         (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2))\n                //扩容，newTable为null\n                transfer(tab, null);\n            s = sumCount();\n        &#125;\n    &#125;\n&#125;\n\n1.2、fullAddCount方法\n① 当CounterCell数组不为空，优先对CounterCell数组中的CounterCell的value累加\n② 当CounterCell数组为空，会去创建CounterCell数组，默认长度为2，并对数组中的CounterCell的value累加\n③ 当数组为空，并且此时有别的线程正在创建数组，那么尝试对baseCount做累加，成功即返回，否则自旋\n\nprivate final void fullAddCount(long x, boolean wasUncontended) &#123;\n    int h;\n    //获取当前线程的hash值\n    if ((h = ThreadLocalRandom.getProbe()) == 0) &#123;\n        ThreadLocalRandom.localInit();      // force initialization\n        h = ThreadLocalRandom.getProbe();\n        wasUncontended = true;\n    &#125;\n    //标识是否有冲突，如果最后一个桶不是null，那么为true\n    boolean collide = false;                // True if last slot nonempty\n    for (;;) &#123;\n        CounterCell[] as; CounterCell a; int n; long v;\n        //数组不为空，优先对数组中CouterCell的value累加\n        if ((as = counterCells) != null &amp;&amp; (n = as.length) > 0) &#123;\n            //线程对应的桶位为null\n            if ((a = as[(n - 1) &amp; h]) == null) &#123;\n                if (cellsBusy == 0) &#123;            // Try to attach new Cell\n                    //创建CounterCell对象\n                    CounterCell r = new CounterCell(x); // Optimistic create\n                    //利用CAS修改cellBusy状态为1，成功则将刚才创建的CounterCell对象放入数组中\n                    if (cellsBusy == 0 &amp;&amp;\n                        U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123;\n                        boolean created = false;\n                        try &#123;               // Recheck under lock\n                            CounterCell[] rs; int m, j;\n                            //桶位为空， 将CounterCell对象放入数组\n                            if ((rs = counterCells) != null &amp;&amp;\n                                (m = rs.length) > 0 &amp;&amp;\n                                rs[j = (m - 1) &amp; h] == null) &#123;\n                                rs[j] = r;\n                                //表示放入成功\n                                created = true;\n                            &#125;\n                        &#125; finally &#123;\n                            cellsBusy = 0;\n                        &#125;\n                        if (created) //成功退出循环\n                            break;\n                        //桶位已经被别的线程放置了已给CounterCell对象，继续循环\n                        continue;           // Slot is now non-empty\n                    &#125;\n                &#125;\n                collide = false;\n            &#125;\n            //桶位不为空，重新计算线程hash值，然后继续循环\n            else if (!wasUncontended)       // CAS already known to fail\n                wasUncontended = true;      // Continue after rehash\n            //重新计算了hash值后，对应的桶位依然不为空，对value累加\n            //成功则结束循环\n            //失败则继续下面判断\n            else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))\n                break;\n            //数组被别的线程改变了，或者数组长度超过了可用cpu大小，重新计算线程hash值，否则继续下一个判断\n            else if (counterCells != as || n >= NCPU)\n                collide = false;            // At max size or stale\n            //当没有冲突，修改为有冲突，并重新计算线程hash，继续循环\n            else if (!collide)\n                collide = true;\n            //如果CounterCell的数组长度没有超过cpu核数，对数组进行两倍扩容\n            //并继续循环\n            else if (cellsBusy == 0 &amp;&amp;\n                     U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123;\n                try &#123;\n                    if (counterCells == as) &#123;// Expand table unless stale\n                        CounterCell[] rs = new CounterCell[n &lt;&lt; 1];\n                        for (int i = 0; i &lt; n; ++i)\n                            rs[i] = as[i];\n                        counterCells = rs;\n                    &#125;\n                &#125; finally &#123;\n                    cellsBusy = 0;\n                &#125;\n                collide = false;\n                continue;                   // Retry with expanded table\n            &#125;\n            h = ThreadLocalRandom.advanceProbe(h);\n        &#125;\n        //CounterCell数组为空，并且没有线程在创建数组，修改标记，并创建数组\n        else if (cellsBusy == 0 &amp;&amp; counterCells == as &amp;&amp;\n                 U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123;\n            boolean init = false;\n            try &#123;                           // Initialize table\n                if (counterCells == as) &#123;\n                    CounterCell[] rs = new CounterCell[2];\n                    rs[h &amp; 1] = new CounterCell(x);\n                    counterCells = rs;\n                    init = true;\n                &#125;\n            &#125; finally &#123;\n                cellsBusy = 0;\n            &#125;\n            if (init)\n                break;\n        &#125;\n        //数组为空，并且有别的线程在创建数组，那么尝试对baseCount做累加，成功就退出循环，失败就继续循环\n        else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x))\n            break;                          // Fall back on using base\n    &#125;\n&#125;\n\n2、图解\nfullAddCount方法中，当as数组不为空的逻辑图解\n\n\n\n\n\n六、jdk1.8集合长度获取1、源码分析1.1、size方法public int size() &#123;\n    long n = sumCount();\n    return ((n &lt; 0L) ? 0 :\n            (n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :\n            (int)n);\n&#125;\n\n1.2、sumCount方法final long sumCount() &#123;\n    CounterCell[] as = counterCells; CounterCell a;\n    //获取baseCount的值\n    long sum = baseCount;\n    if (as != null) &#123;\n        //遍历CounterCell数组，累加每一个CounterCell的value值\n        for (int i = 0; i &lt; as.length; ++i) &#123;\n            if ((a = as[i]) != null)\n                sum += a.value;\n        &#125;\n    &#125;\n    return sum;\n&#125;\n\n\n注意：这个方法并不是线程安全的\n\n","slug":"ConcurrentHashMap源码分析(JDK8)","date":"2021-05-03T16:02:52.000Z","categories_index":"","tags_index":"Java,源码分析,多线程","author_index":"谢华客"},{"id":"a317c231a44cc2204c181b9cec137632","title":"ConcurrentHashMap源码分析(JDK7)","content":"一、Unsafe介绍1、Unsafe简介Unsafe类相当于是一个java语言中的后门类，提供了硬件级别的原子操作，所以在一些并发编程中被大量使用。jdk已经作出说明，该类对程序员而言不是一个安全操作，在后续的jdk升级过程中，可能会禁用该类。所以这个类的使用是一把双刃剑，实际项目中谨慎使用，以免造成jdk升级不兼容问题。\n2、Unsafe ApiConcurrentHashMap中出现的Unsafe操作解释：\narrayBaseOffset：获取数组的基础偏移量\narrayIndexScale：获取数组中元素的偏移间隔，要获取对应所以的元素，将索引号和该值相乘，获得数组中指定角标元素的偏移量\ngetObjectVolatile：获取对象上的属性值或者数组中的元素\ngetObject：获取对象上的属性值或者数组中的元素，已过时\nputOrderedObject：设置对象的属性值或者数组中某个角标的元素，更高效\nputObjectVolatile：设置对象的属性值或者数组中某个角标的元素\nputObject：设置对象的属性值或者数组中某个角标的元素，已过时\n3、代码演示public class Test02 &#123;\n\n    public static void main(String[] args) throws Exception &#123;\n        Integer[] arr = &#123;2,5,1,8,10&#125;;\n\n        //获取Unsafe对象\n        Unsafe unsafe = getUnsafe();\n        //获取Integer[]的基础偏移量\n        int baseOffset = unsafe.arrayBaseOffset(Integer[].class);\n        //获取Integer[]中元素的偏移间隔\n        int indexScale = unsafe.arrayIndexScale(Integer[].class);\n\n        //获取数组中索引为2的元素对象\n        Object o = unsafe.getObjectVolatile(arr, (2 * indexScale) + baseOffset);\n        System.out.println(o); //1\n\n        //设置数组中索引为2的元素值为100\n        unsafe.putOrderedObject(arr,(2 * indexScale) + baseOffset,100);\n\n        System.out.println(Arrays.toString(arr));//[2, 5, 100, 8, 10]\n    &#125;\n\n    //反射获取Unsafe对象\n    public static Unsafe getUnsafe() throws Exception &#123;\n        Field theUnsafe = Unsafe.class.getDeclaredField(\"theUnsafe\");\n        theUnsafe.setAccessible(true);\n        return (Unsafe) theUnsafe.get(null);\n    &#125;\n&#125;\n\n3.1、图解说明\n\n\n\n二、jdk1.7容器初始化1、源码解析\n无参构造\n\n//空参构造\npublic ConcurrentHashMap() &#123;\n    //调用本类的带参构造\n    //DEFAULT_INITIAL_CAPACITY = 16\n    //DEFAULT_LOAD_FACTOR = 0.75f\n    //int DEFAULT_CONCURRENCY_LEVEL = 16\n    this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);\n&#125;\n\n\n三个参数的构造：一些非核心逻辑的代码已经省略\n\n//initialCapacity 定义ConcurrentHashMap存放元素的容量\n//concurrencyLevel 定义ConcurrentHashMap中Segment[]的大小\npublic ConcurrentHashMap(int initialCapacity,\n                         float loadFactor, int concurrencyLevel) &#123;\n   \n    int sshift = 0;\n    int ssize = 1;\n    //计算Segment[]的大小，保证是2的幂次方数\n    while (ssize &lt; concurrencyLevel) &#123;\n        ++sshift;\n        ssize &lt;&lt;= 1;\n    &#125;\n    //这两个值用于后面计算Segment[]的角标\n    this.segmentShift = 32 - sshift;\n    this.segmentMask = ssize - 1;\n    \n    //计算每个Segment中存储元素的个数\n    int c = initialCapacity / ssize;\n    if (c * ssize &lt; initialCapacity)\n        ++c;\n    //最小Segment中存储元素的个数为2\n    int cap = MIN_SEGMENT_TABLE_CAPACITY;\n    ////矫正每个Segment中存储元素的个数，保证是2的幂次方，最小为2\n    while (cap &lt; c)\n        cap &lt;&lt;= 1;\n    //创建一个Segment对象，作为其他Segment对象的模板\n    Segment&lt;K,V> s0 =\n        new Segment&lt;K,V>(loadFactor, (int)(cap * loadFactor),\n                         (HashEntry&lt;K,V>[])new HashEntry[cap]);\n    Segment&lt;K,V>[] ss = (Segment&lt;K,V>[])new Segment[ssize];\n    //利用Unsafe类，将创建的Segment对象存入0角标位置\n    UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]\n    this.segments = ss;\n&#125;\n\n\n综上：ConcurrentHashMap中保存了一个**默认长度为16的Segment[]，每个Segment元素中保存了一个默认长度为2的HashEntry[]**，我们添加的元素，是存入对应的Segment中的HashEntry[]中。所以ConcurrentHashMap中默认元素的长度是32个，而不是16个\n\n2、图解\n\n3、Segment是什么？static final class Segment&lt;K,V> extends ReentrantLock implements Serializable &#123;\n\t...\n&#125;\n\n\n我们发现Segment是继承自ReentrantLock的，学过线程的兄弟都知道，它可以实现同步操作，从而保证多线程下的安全。因为每个Segment之间的锁互不影响，所以我们也将ConcurrentHashMap中的这种锁机制称之为分段锁，这比HashTable的线程安全操作高效的多。\n\n4、HashEntry是什么？//ConcurrentHashMap中真正存储数据的对象\nstatic final class HashEntry&lt;K,V> &#123;\n    final int hash; //通过运算，得到的键的hash值\n    final K key; // 存入的键\n    volatile V value; //存入的值\n    volatile HashEntry&lt;K,V> next; //记录下一个元素，形成单向链表\n\n    HashEntry(int hash, K key, V value, HashEntry&lt;K,V> next) &#123;\n        this.hash = hash;\n        this.key = key;\n        this.value = value;\n        this.next = next;\n    &#125;\n&#125;\n\n三、jdk1.7添加安全1、源码分析1.1、ConcurrentHashMap的put方法public V put(K key, V value) &#123;\n    Segment&lt;K,V> s;\n    if (value == null)\n        throw new NullPointerException();\n    //基于key，计算hash值\n    int hash = hash(key);\n    //因为一个键要计算两个数组的索引，为了避免冲突，这里取高位计算Segment[]的索引\n    int j = (hash >>> segmentShift) &amp; segmentMask;\n    //判断该索引位的Segment对象是否创建，没有就创建\n    if ((s = (Segment&lt;K,V>)UNSAFE.getObject          // nonvolatile; recheck\n         (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) //  in ensureSegment\n        s = ensureSegment(j);\n    //调用Segmetn的put方法实现元素添加\n    return s.put(key, hash, value, false);\n&#125;\n\n1.2、ConcurrentHashMap的ensureSegment方法&#x2F;&#x2F;创建对应索引位的Segment对象，并返回\nprivate Segment&lt;K,V&gt; ensureSegment(int k) &#123;\n    final Segment&lt;K,V&gt;[] ss &#x3D; this.segments;\n    long u &#x3D; (k &lt;&lt; SSHIFT) + SBASE; &#x2F;&#x2F; raw offset\n    Segment&lt;K,V&gt; seg;\n    &#x2F;&#x2F;获取，如果为null，即创建\n    if ((seg &#x3D; (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) &#x3D;&#x3D; null) &#123;\n        &#x2F;&#x2F;以0角标位的Segment为模板\n        Segment&lt;K,V&gt; proto &#x3D; ss[0]; &#x2F;&#x2F; use segment 0 as prototype\n        int cap &#x3D; proto.table.length;\n        float lf &#x3D; proto.loadFactor;\n        int threshold &#x3D; (int)(cap * lf);\n        HashEntry&lt;K,V&gt;[] tab &#x3D; (HashEntry&lt;K,V&gt;[])new HashEntry[cap];\n        &#x2F;&#x2F;获取，如果为null，即创建\n        if ((seg &#x3D; (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u))\n            &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; recheck\n            &#x2F;&#x2F;创建\n            Segment&lt;K,V&gt; s &#x3D; new Segment&lt;K,V&gt;(lf, threshold, tab);\n            &#x2F;&#x2F;自旋方式，将创建的Segment对象放到Segment[]中，确保线程安全\n            while ((seg &#x3D; (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u))\n                   &#x3D;&#x3D; null) &#123;\n                if (UNSAFE.compareAndSwapObject(ss, u, null, seg &#x3D; s))\n                    break;\n            &#125;\n        &#125;\n    &#125;\n    &#x2F;&#x2F;返回\n    return seg;\n&#125;\n\n1.3、Segment的put方法final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123;\n    //尝试获取锁，获取成功，node为null，代码向下执行\n    //如果有其他线程占据锁对象，那么去做别的事情，而不是一直等待，提升效率\n    //scanAndLockForPut 稍后分析\n    HashEntry&lt;K,V> node = tryLock() ? null :\n        scanAndLockForPut(key, hash, value);\n    V oldValue;\n    try &#123;\n        HashEntry&lt;K,V>[] tab = table;\n        //取hash的低位，计算HashEntry[]的索引\n        int index = (tab.length - 1) &amp; hash;\n        //获取索引位的元素对象\n        HashEntry&lt;K,V> first = entryAt(tab, index);\n        for (HashEntry&lt;K,V> e = first;;) &#123;\n            //获取的元素对象不为空\n            if (e != null) &#123;\n                K k;\n                //如果是重复元素，覆盖原值\n                if ((k = e.key) == key ||\n                    (e.hash == hash &amp;&amp; key.equals(k))) &#123;\n                    oldValue = e.value;\n                    if (!onlyIfAbsent) &#123;\n                        e.value = value;\n                        ++modCount;\n                    &#125;\n                    break;\n                &#125;\n                //如果不是重复元素，获取链表的下一个元素，继续循环遍历链表\n                e = e.next;\n            &#125;\n            else &#123; //如果获取到的元素为空\n                //当前添加的键值对的HashEntry对象已经创建\n                if (node != null)\n                    node.setNext(first); //头插法关联即可\n                else\n                    //创建当前添加的键值对的HashEntry对象\n                    node = new HashEntry&lt;K,V>(hash, key, value, first);\n                //添加的元素数量递增\n                int c = count + 1;\n                //判断是否需要扩容\n                if (c > threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY)\n                    //需要扩容\n                    rehash(node);\n                else\n                    //不需要扩容\n                    //将当前添加的元素对象，存入数组角标位，完成头插法添加元素\n                    setEntryAt(tab, index, node);\n                ++modCount;\n                count = c;\n                oldValue = null;\n                break;\n            &#125;\n        &#125;\n    &#125; finally &#123;\n        //释放锁\n        unlock();\n    &#125;\n    return oldValue;\n&#125;\n\n1.4、Segment的scanAndLockForPut方法\n该方法在线程没有获取到锁的情况下，去完成HashEntry对象的创建，提升效率\n但是这个操作个人感觉有点累赘了。\n\nprivate HashEntry&lt;K,V> scanAndLockForPut(K key, int hash, V value) &#123;\n    //获取头部元素\n    HashEntry&lt;K,V> first = entryForHash(this, hash);\n    HashEntry&lt;K,V> e = first;\n    HashEntry&lt;K,V> node = null；\n    int retries = -1; // negative while locating node\n    while (!tryLock()) &#123;\n        //获取锁失败\n        HashEntry&lt;K,V> f; // to recheck first below\n        if (retries &lt; 0) &#123;\n            //没有下一个节点，并且也不是重复元素，创建HashEntry对象，不再遍历\n            if (e == null) &#123;\n                if (node == null) // speculatively create node\n                    node = new HashEntry&lt;K,V>(hash, key, value, null);\n                retries = 0;\n            &#125;\n            else if (key.equals(e.key))\n                //重复元素，不创建HashEntry对象，不再遍历\n                retries = 0;\n            else\n                //继续遍历下一个节点\n                e = e.next;\n        &#125;\n        else if (++retries > MAX_SCAN_RETRIES) &#123;\n            //如果尝试获取锁的次数过多，直接阻塞\n            //MAX_SCAN_RETRIES会根据可用cpu核数来确定\n            lock();\n            break;\n        &#125;\n        else if ((retries &amp; 1) == 0 &amp;&amp;\n                 (f = entryForHash(this, hash)) != first) &#123;\n            //如果期间有别的线程获取锁，重新遍历\n            e = first = f; // re-traverse if entry changed\n            retries = -1;\n        &#125;\n    &#125;\n    return node;\n&#125;\n\n2、模拟多线程的代码流程\n这里“通话”和“重地”的哈希值是一样的，那么他们添加时，会存入同一个Segment对象，必然会存在锁竞争\n\npublic static void main(String[] args) throws Exception &#123;\n    final ConcurrentHashMap chm = new ConcurrentHashMap();\n\n    new Thread()&#123;\n        @Override\n        public void run() &#123;\n            chm.put(\"通话\",\"11\");\n            System.out.println(\"-----------\");\n        &#125;\n    &#125;.start();\n\n\t//让第一个线程先启动，进入put方法\n    Thread.sleep(1000);\n\n    new Thread()&#123;\n        @Override\n        public void run() &#123;\n            chm.put(\"重地\",\"22\");\n            System.out.println(\"===========\");\n        &#125;\n    &#125;.start();\n&#125;\n\n2.1、多线程环境下的条件断点设置\n\n\n\n2.2、运行结果\n会发现两个线程，分别停在不同的断点位置，这就是多线程锁互斥产生的结果\n然后就可以分别让不同的线程向下执行，查看代码走向了。\n\n\n\n\n\n四、jdk1.7扩容安全1、源码分析private void rehash(HashEntry&lt;K,V> node) &#123;\n    HashEntry&lt;K,V>[] oldTable = table;\n    int oldCapacity = oldTable.length;\n    //两倍容量\n    int newCapacity = oldCapacity &lt;&lt; 1;\n    threshold = (int)(newCapacity * loadFactor);\n    //基于新容量，创建HashEntry数组\n    HashEntry&lt;K,V>[] newTable =\n        (HashEntry&lt;K,V>[]) new HashEntry[newCapacity];\n    int sizeMask = newCapacity - 1;\n   \t//实现数据迁移\n    for (int i = 0; i &lt; oldCapacity ; i++) &#123;\n        HashEntry&lt;K,V> e = oldTable[i];\n        if (e != null) &#123;\n            HashEntry&lt;K,V> next = e.next;\n            int idx = e.hash &amp; sizeMask;\n            if (next == null)   //  Single node on list\n                //原位置只有一个元素，直接放到新数组即可\n                newTable[idx] = e;\n            else &#123; // Reuse consecutive sequence at same slot\n                //=========图一=====================\n                HashEntry&lt;K,V> lastRun = e;\n                int lastIdx = idx;\n                for (HashEntry&lt;K,V> last = next;\n                     last != null;\n                     last = last.next) &#123;\n                    int k = last.hash &amp; sizeMask;\n                    if (k != lastIdx) &#123;\n                        lastIdx = k;\n                        lastRun = last;\n                    &#125;\n                &#125;\n                //=========图一=====================\n                \n                //=========图二=====================\n                newTable[lastIdx] = lastRun;\n                //=========图二=====================\n                // Clone remaining nodes\n                //=========图三=====================\n                for (HashEntry&lt;K,V> p = e; p != lastRun; p = p.next) &#123;\n                    V v = p.value;\n                    int h = p.hash;\n                    int k = h &amp; sizeMask;\n                    HashEntry&lt;K,V> n = newTable[k];\n                    //这里旧的HashEntry不会放到新数组\n                    //而是基于原来的数据创建了一个新的HashEntry对象，放入新数组\n                    newTable[k] = new HashEntry&lt;K,V>(h, p.key, v, n);\n                &#125;\n                //=========图三=====================\n            &#125;\n        &#125;\n    &#125;\n    //采用头插法，将新元素加入到数组中\n    int nodeIndex = node.hash &amp; sizeMask; // add the new node\n    node.setNext(newTable[nodeIndex]);\n    newTable[nodeIndex] = node;\n    table = newTable;\n&#125;\n\n2、图解\n图一\n\n\n\n\n图二\n\n\n\n\n图三\n\n\n\n\n\n五、jdk1.7集合长度获取1、源码分析public int size() &#123;\n    // Try a few times to get accurate count. On failure due to\n    // continuous async changes in table, resort to locking.\n    final Segment&lt;K,V>[] segments = this.segments;\n    int size;\n    boolean overflow; // true if size overflows 32 bits\n    long sum;         // sum of modCounts\n    long last = 0L;   // previous sum\n    int retries = -1; // first iteration isn't retry\n    try &#123;\n        for (;;) &#123;\n            //当第5次走到这个地方时，会将整个Segment[]的所有Segment对象锁住\n            if (retries++ == RETRIES_BEFORE_LOCK) &#123;\n                for (int j = 0; j &lt; segments.length; ++j)\n                    ensureSegment(j).lock(); // force creation\n            &#125;\n            sum = 0L;\n            size = 0;\n            overflow = false;\n            for (int j = 0; j &lt; segments.length; ++j) &#123;\n                Segment&lt;K,V> seg = segmentAt(segments, j);\n                if (seg != null) &#123;\n                    //累加所有Segment的操作次数\n                    sum += seg.modCount;\n                    int c = seg.count;\n                    //累加所有segment中的元素个数 size+=c\n                    if (c &lt; 0 || (size += c) &lt; 0)\n                        overflow = true;\n                &#125;\n            &#125;\n            //当这次累加值和上一次累加值一样，证明没有进行新的增删改操作，返回sum\n            //第一次last为0，如果有元素的话，这个for循环最少循环两次的\n            if (sum == last)\n                break;\n            //记录累加的值\n            last = sum;\n        &#125;\n    &#125; finally &#123;\n        //如果之前有锁住，解锁\n        if (retries > RETRIES_BEFORE_LOCK) &#123;\n            for (int j = 0; j &lt; segments.length; ++j)\n                segmentAt(segments, j).unlock();\n        &#125;\n    &#125;\n    //溢出，返回int的最大值，否则返回累加的size\n    return overflow ? Integer.MAX_VALUE : size;\n&#125;\n\n","slug":"ConcurrentHashMap源码分析(JDK7)","date":"2021-05-03T15:49:58.000Z","categories_index":"","tags_index":"Java,源码分析,多线程","author_index":"谢华客"},{"id":"293c17b4d2a4292133cc4d1ffd7f8725","title":"计算机网络","content":"计算机网络Http和Https的区别？\n其实HTTPS就是从HTTP加上加密处理（一般是SSL安全通信线路）+认证+完整性保护\n区别：\nhttps需要拿到ca证书，需要钱的\n端口不一样，http是80，https443\nhttp是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。\nhttp和https使用的是完全不同的连接方式（http的连接很简单，是无状态的；HTTPS 协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。）\n\n\n\n\n\nHTTPS也就是在TCP协议和HTTP协议之间加上了一层TLS/SSL协议\n\nTLS/SSL工作原理TLS/SSL的功能实现主要依赖于三类基本算法：非对称加密和对称加密、散列函数 Hash\n其利用非对称加密实现身份认证和密钥协商，对称加密算法采用协商的密钥对数据加密，基于散列函数验证信息的完整性\n\n\nRSA身份验证的隐患身份验证和密钥协商是TLS的基础功能，要求的前提是合法的服务器掌握着对应的私钥。但RSA算法无法确保服务器身份的合法性，因为公钥并不包含服务器的信息，存在安全隐患:\n\n客户端C和服务器S进行通信，中间节点M截获了二者的通信;\n节点M自己计算产生一对公钥pub_M和私钥pri_M;\nC向S请求公钥时，M把自己的公钥pub_M发给了C;\nC使用公钥 pub_M加密的数据能够被M解密，因为M掌握对应的私钥pri_M，而 C无法根据公钥信息判断服务器的身份，从而 C和 * M之间建立了”可信”加密连接;\n中间节点 M和服务器S之间再建立合法的连接，因此 C和 S之间通信被M完全掌握，M可以进行信息的窃听、篡改等操作。\n另外，服务器也可以对自己的发出的信息进行否认，不承认相关信息是自己发出。\n\n因此这个方案至少存在两个问题：中间人攻击和信息抵赖\n\n身份验证CA和证书解决上述身份验证问题的关键是确保获取的公钥途径是合法的，能够验证服务器的身份信息，为此需要引入权威的第三方机构CA(如沃通CA)。CA 负责核实公钥的拥有者的信息，并颁发认证”证书”，同时能够为使用者提供证书验证服务，即PKI体系(PKI基础知识)。\n基本的原理为，CA负责审核信息，然后对关键信息利用私钥进行”签名”，公开对应的公钥，客户端可以利用公钥验证签名。CA也可以吊销已经签发的证书，基本的方式包括两类 CRL 文件和 OCSP。CA使用具体的流程如下：\n\n\n服务方S向第三方机构CA提交公钥、组织信息、个人信息(域名)等信息并申请认证;\nCA通过线上、线下等多种手段验证申请者提供信息的真实性，如组织是否存在、企业是否合法，是否拥有域名的所有权等;\n如信息审核通过，CA会向申请者签发认证文件-证书。 证书包含以下信息：申请者公钥、申请者的组织信息和个人信息、签发机构 CA的信息、有效时间、证书序列号等信息的明文，同时包含一个签名，签名的产生算法：首先，使用散列函数计算公开的明文信息的信息摘要，然后，采用 CA的私钥对信息摘要进行加密，密文即签名;\n客户端 C 向服务器 S 发出请求时，S 返回证书文件;\n客户端 C读取证书中的相关的明文信息，采用相同的散列函数计算得到信息摘要，然后，利用对应 CA的公钥解密签名数据，对比证书的信息摘要，如果一致，则可以确认证书的合法性，即公钥合法;\n客户端然后验证证书相关的域名信息、有效时间等信息;\n客户端会内置信任CA的证书信息(包含公钥)，如果CA不被信任，则找不到对应 CA的证书，证书也会被判定非法。\n在这个过程注意几点：\n申请证书不需要提供私钥，确保私钥永远只能服务器掌握;\n证书的合法性仍然依赖于非对称加密算法，证书主要是增加了服务器信息以及签名;\n内置 CA 对应的证书称为根证书，颁发者和使用者相同，自己为自己签名，即自签名证书（为什么说”部署自签SSL证书非常不安全”）\n证书=公钥+申请者与颁发者信息+签名\n\nHTTPS接入优化CDN接入HTTPS 增加的延时主要是传输延时 RTT，RTT 的特点是节点越近延时越小，CDN 天然离用户最近，因此选择使用 CDN 作为 HTTPS 接入的入口，将能够极大减少接入延时。CDN 节点通过和业务服务器维持长连接、会话复用和链路质量优化等可控方法，极大减少 HTTPS 带来的延时。\n会话缓存虽然前文提到 HTTPS 即使采用会话缓存也要至少1*RTT的延时，但是至少延时已经减少为原来的一半，明显的延时优化;同时，基于会话缓存建立的 HTTPS 连接不需要服务器使用RSA私钥解密获取 Pre-master 信息，可以省去CPU 的消耗。如果业务访问连接集中，缓存命中率高，则HTTPS的接入能力讲明显提升。当前TRP平台的缓存命中率高峰时期大于30%，10k/s的接入资源实际可以承载13k/的接入，收效非常可观。\n硬件加速为接入服务器安装专用的SSL硬件加速卡，作用类似 GPU，释放 CPU，能够具有更高的 HTTPS 接入能力且不影响业务程序的。测试某硬件加速卡单卡可以提供35k的解密能力，相当于175核 CPU，至少相当于7台24核的服务器，考虑到接入服务器其它程序的开销，一张硬件卡可以实现接近10台服务器的接入能力。\n远程解密本地接入消耗过多的 CPU 资源，浪费了网卡和硬盘等资源，考虑将最消耗 CPU 资源的RSA解密计算任务转移到其它服务器，如此则可以充分发挥服务器的接入能力，充分利用带宽与网卡资源。远程解密服务器可以选择 CPU 负载较低的机器充当，实现机器资源复用，也可以是专门优化的高计算性能的服务器。当前也是 CDN 用于大规模HTTPS接入的解决方案之一。\nSPDY/HTTP2前面的方法分别从减少传输延时和单机负载的方法提高 HTTPS 接入性能，但是方法都基于不改变 HTTP 协议的基础上提出的优化方法，SPDY/HTTP2 利用 TLS/SSL 带来的优势，通过修改协议的方法来提升 HTTPS 的性能，提高下载速度等。\n常用的加密算法非对称加密：ECC(椭圆曲线加密算法)、DH加密算法\n对称加密：AES加密算法、DES加密算法、RC4流加密算法\n散列算法：MD5算法，SHA安全散列算法\n七层模型详解应用层\n应用层的任务是解决不同主机之间的应用进程的通信的\n\n域名系统DNS域名系统是用来将域名解析成IP地址的，域名将IP地址的解析过程如下：当某一个应用进程需要把主机名解析为IP地址时，就调用解析程序，成为DNS的一个客户，把待解析的域名放在DNS请求报文中，以UDP用户数据报的形式发送给本地DNS服务器\n文件传输协议FTP\n控制连接端口号21，数据连接端口号20\n\nFTP在运输层中选择的协议是TCP协议，需要复制整个文件，其特点是：如果要存取一个服务器上的文件，就需要获得这个文件的副本，如果要修改这个文件，则在本地上的副本上进行修改后，再传输给服务器。\n如果不想这样，就要使用网络文件传输协议NFS，它允许应用进程打开一个远地文件，并在文件上进行读写，NFS在运输层采用的是UDP协议\nFTP进行连接时，会在运输层创建两个并行的TCP连接，分别叫做控制连接和数据连接， 控制连接占用端口21，用来进行主机间的通信连接，而传输文件使用的是数据连接，占用的端口号是20\nHTTP超文本传输协议HTTP在运输层中采用的协议是TCP协议，虽然在HTTP通信之前需要在运输层进行TCP的连接，但是HTTP本身是无连接的，也是无状态的。\nHTTP报文的结构HTTP请求报文和响应报文的格式都是一样的，由三部分组成：\n\n开始行，在请求报文当中称为请求行，在响应报文当中称为状态行\n首部行，都是以首部字段和对应的值组成的\n实体主体，请求报文中存放请求体，响应报文当中存放响应体\n\n\n运输层\n运输层的任务是为不同主机的通信提供数据传输服务\n运输层采用一个16位端口号来标志一个端口，所以也就允许65535个不同的端口\n\n运输层的两个主要协议\n\n用户数据报协议UDP\n传输控制协议TCP\n\nUDP协议\nUDP是无连接的，尽最大可能交付，不保证可靠交付\nUDP面向报文的，UDP直接将数据报添加首部后就进行发送\n\nUDP的首部格式\nUDP首部只含有8个字节，由四个字段组成，每个字段都是两个字节\n\n\n源端口：需要对方回信时使用，不需要可全0\n目的端口：终点交付报文的端口\n长度，UDP用户数据报的长度，最小值是8（仅含有首部）\n校验和，检测在传输过程中是否由错\n\n\nTCP协议TCP协议是面向字节流的，TCP把应用程序交下来的数据仅仅看成字节流\nTCP报文的首部格式TCP报文的首部最少为20个字节，有20个字节是固定的，后面4n字节是根据需要而添加上去的\n\n源端口和目的端口：各占2个字节，发送方的端口和目的地的端口\n\n校验和：和UDP一样，两个字节，校验的内容包括首部和数据两个部分，计算时需要添加伪首部\n\n序号：占用4个字节，范围是[0, 2^32 - 1]，序号增加到2^32之后，又会变回0，也就是说序列号是对2^32进行取模运算的，TCP数据报的每个字节都需要进行编号，而序号就是这个数据报要发送的节点流的第一个序号。\n\n确认号：占用4个字节，是期望收到对方下一个报文的序号\n\n总之：若确认号为N，则表明到目前为止序号为N - 1的数据报都已经被正常接收\n\n\n数据偏移：占用4位，指出TCP数据报数据部分距离数据报开始有多远，也相当于指明了首部占用了多少位\n\n窗口：占用2个字节，所以窗口值得范围为[0, 2^16 - 1]，表明接收方允许发送发最多能发送的字节数量\n\n还有控制位，来表明报文段的性质\n\n确认ACK，仅当ACK=1时确认号字段才有效，TCP规定，连接建立后所有传送的报文段都必须把ACK置1\n同步SYN，在连接建立时用来同步序号，当SNY=1，ACK为0时代表这个报文为连接请求报文，而SYN=1和ACK为1代表整个报文为连接接受报文\nFIN终止，当FIN=1时，表示此报文的发送方数据已经发送完毕，并要求释放连接\n\n\n\nTCP可靠传输的实现1.以字节为单位的滑动窗口\n滑动窗口由窗口前沿和后沿的位置来共同决定，发送方根据接收方的窗口值，构造出自己的发送窗口，发送窗口由三个指针来确定，从左到右叫做p1,p2,p3。\n\n在p1之前的的字节序号表示已经发送并收到确认的字节\np1和p2之间代表已经发送的数据，但是没有收到确认的部分\n而p2和p3之间代表的是可用窗口，里面的数据是可以发送但是没有发送的\n对于收到接受方发送的确认号，就会向右移动p1，也会根据新的接收方窗口值来决定是否移动p3\n而对于接收方来说，只会确认按序到达的序号\n\n\n流量控制：发送方发送的数据是不能大于接收方的窗口值的，发送方会根据接收方的窗口值作为参考来构造之间的滑动窗口，来进行数据的发送，确保接收方可以容纳收到的数据，\n\n流量控制可能会出现死锁的情况，当接收方将窗口值设置为0后，在后面又有空间可以存放数据，于是发送一个新的窗口值的报文，但是报文丢失了，于是发送方就一直等待，出现死锁局面\n解决的方法是设有一个持续计时器，当收到零窗口时，会开启计时器，计时器到期后会发送一个探测报文，那么对方就会在确认报文当中给出窗口值\n而窗口中的数据发送的时机是什么呢？在TCP的实现中广泛使用Nagle算法：先将窗口中的第一个字节发送出去，然后把后面的字节都缓存起来，当收到第一个字节的确认后，再一次性发送窗口里面的数据\n糊涂窗口综合症：指的是TCP接收方窗口值已满，但是每次都从窗口值读取一个字节，发送确认，导致每个数据报只会传送1个字节\n\n\n拥塞控制\n\n判断网络拥塞的依据就是出现了超时\n\n\nTCP进行拥塞控制的算法有四种：慢开始，拥塞避免，快重传，快恢复\n\n慢开始：在刚刚开发送报文段时，先把拥塞窗口设置为不超过2到4个的最大报文段，而每收到对新的报文段的确认后，把拥塞窗口值增加确认的数据量，但是要小于最大报文段，也就是说，每经过一个轮次，拥塞窗口就会加倍\n\n为了防止拥塞窗口增长过大引起网络拥塞，TCP使用一个慢开始门限状态变量来控制，当小于慢开始门限时，使用慢开始算法，大于慢开始门限后，改用拥塞避免算法\n\n\n拥塞避免：每经过一个轮次就把发送方的拥塞窗口加1，有加法增大的特点，如果增大到一定程度后出现了网络拥塞，就将慢开始门限设置为当前拥塞窗口值的一半，窗口值重新设置为1，进入慢开始阶段\n\n快重传：算法首先要求接收方在收到报文后要立即发送确认，即使收到了不按照顺序的报文段，也要立即发送已收到报文段的重复确认。而如果发送方一连接收到3个重复确认，就知道这个这个确认号后的数据没有成功发送，立即重传\n\n快恢复：而经过快重传后，发送方知道没有收到的确认不是因为超时，而是丢失了，就不进入慢开始，而是将慢开始门限设置为当前报文段的一半，但是直接将窗口值设置为门限值，直接进入拥塞避免\n\n\n\n校验和：通过校验和来检验报文在传输过程中是否出现了差错\n\n停止等待协议：发送方发送完成一个报文后，会停止发送，直到收到确认\n\n超时重传：发送完一个报文后，TCP会启动一个定时器，如果定时器过期后还没收到确认，就会进行这个报文的重传\n\n\nTCP建立连接和释放连接TCP建立连接的过程叫做握手\n\n过程白话：\n\n在建立连接时，客户端发出连接请求报文段，这时首部的同步位SYN=1，同时选择一个初始序号x，发送报文，进入同步已发送状态\n服务端收到请求连接报文后，如果同意连接，就会发送连接接受报文，首部同步位SYN置为1，ACK位置为1，同时选出自己的初始序号y，而确认号是x+1，代表确认的是上一个请求连接报文，同时进入请求接受状态\n客户端收到确认后，还要给出确认，将首部的ACK置为1，自己的序号为x+1，确认号为y+1，代表确认的是序号为y的报文，进入已建立连接状态\n而服务段收到确认后，也会进入已连接状态\n\nTCP释放过程叫做挥手\n\n过程白话：\n\n当客户端发送完数据，打算释放连接时，就会发送一个连接释放请求报文，将首部终止位FIN=1，序号假设为u，进入第一阶段的FIN_WAIT\n服务端收到连接释放请求报文后，可能还有数据要传送，不会立即同意，而是先发送一个确认报文，确认号为u+1，代表确认是上一条报文，进入COLSE_WAIT状态\n而客户端收到这个确认报文后，就进入FIN_WATI_2状态，等待服务端发送的连接释放报文\n服务端发送完数据后，就会发送连接释放报文，将终止位FIN置为1，确认位置为1，确认号还是重复的u+1，代表是根据第一个连接释放请求做出的响应，进入LAST_ACK状态\n客户端收到连接释放报文后，就发送确认报文，确认号为收到的连接释放报文的序号+1，进入TIME_WAIT状态，等待两个MSL时间，也就是两个最长报文寿命\n\n为什么TIME_WAIT状态下要等2MSL时间呢\n保证客户端发送的最后一个确认报文能到达服务端，这个确认报文可能丢失了，因此处于LAST_ACK状态的服务端会因为收不到确认而重新发送连接释放请求，而客户端就可以在两个最长报文寿命期间收到，然后重新确认\n\ncookie和session的作用和区别session：存储在服务器上\n当客户端访问服务器应用的一个页面时，服务器卫客户端创建页面的同时也会为客户端创建一个独一无二的SessionID，如果是tomcat生成的，那叫做jsesessionID，接下来在服务端的内存当中开辟一块内存叫做session，session中以键值对存储信息，并把sessionID赋值给session，自动过期时间是30min，并在响应头中的set-cookie字段中设置sessionID\n那具体是怎么创建出来的呢？对于不同语言来说实现是不一样的，对于Java来说，sessionID是第一次产生是服务端第一次调用httpserverltRequest.getSession(true)时，才会被创建出来\n\n可以参考博客\n\ncookie：存储在客户端中，客户端访问服务器后服务器通过set-cookie的方式返回一些数据给客户端，然后客户端保存到本地上，然后客户端在下次访问的时候把这些cookie带上，服务端就能判断用户的状态了\n浏览器禁用cookie后的session处理可以使用URL重写来解决，把sessionID写在URL的后面，返回给客户端，而客户端每次进行访问时url后面都带上这个sessionId\n","slug":"计算机网络","date":"2021-05-03T12:29:51.000Z","categories_index":"","tags_index":"计算机基础,计算机网络","author_index":"谢华客"},{"id":"6d685cebe78237e58f2eba5924bfc97a","title":"基于hexo + github创建个人博客","content":"基于hexo和Github快速创建博客搭建大致流程\n创建仓库：&lt;github用户名&gt;.github.io (严格遵守格式)\n\n创建两个分支：master 和 hexo\nmaster用来保存生成的网页静态文件，而 hexo 用来保存博客的原始文件\n\n设置hexo为默认分支（因为更新博客或者修改博客只需要更新原始文件，然后通过hexo生成静态文件到master分支当中）\n\n把这个仓库克隆到本地\ngit clone git@github.com:stephentse9527&#x2F;stephentse9527.github.io.git\n在本地目录中，依次执行 npm install hexo、hexo init&lt;博客目录&gt; 、npm install、npm install hexo-deployer-git、npm install hexo-image-link --save\n在操作之前，应先把目录中的所有文件移动到其他地方，因为 hexo init 需要对应博客目录为空\n\n选择一款博客主题，我这里选的是 Aurora\n\n修改_config.yml中的 deploy 参数，分支应为 master，仓库为我们的 Github Pages\ndeploy:\n  type: git\n  repository: https://github.com/stephentse9527/stephentse9527.github.io.git\n  branch: master\n\n\n这样搭建后，在Github的 username.github.io 仓库就有两个分支，一个master存放生成的静态网页，一个hexo分支用来存放网站的原始文件\n\n日常更新博客流程在本地更新博客时：\n对原始文件进行改动后，依次执行\ngit add --all\ngit commit -m &quot;message&quot;\ngit push origin hexo\n\n将改动推送到 Github hexo 分支中\n\n根据原始文件生成静态网页\n&#x2F;&#x2F; 清空，刷新，部署\nhexo clean &amp;&amp; hexo g &amp;&amp; hexo d\n\n在其他电脑维护博客时：\n直接克隆hexo分支到电脑上，依次执行 npm install hexo、npm install、npm install hexo-deployer-git（不需要hexo init这条指令）\n然后和普通操作一样改动原始文件后，push即可\n\n","slug":"基于hexo-github创建个人博客","date":"2021-05-02T23:07:17.000Z","categories_index":"","tags_index":"博客","author_index":"谢华客"}]