{"title":"中间件高可用知识点","uid":"33521bd94ee66cdecae1afca83643ee9","slug":"中间件高可用知识点","date":"2021-05-03T20:47:18.000Z","updated":"2022-09-15T14:22:17.560Z","comments":true,"path":"api/articles/中间件高可用知识点.json","keywords":null,"cover":null,"content":"<h1 id=\"不同中间件的高可用架构\"><a href=\"#不同中间件的高可用架构\" class=\"headerlink\" title=\"不同中间件的高可用架构\"></a>不同中间件的高可用架构</h1><h2 id=\"RabbitMQ高可用\"><a href=\"#RabbitMQ高可用\" class=\"headerlink\" title=\"RabbitMQ高可用\"></a>RabbitMQ高可用</h2><ul>\n<li>RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现 RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。</li>\n</ul>\n<ol>\n<li><strong>单机模式</strong>，就是 Demo 级别的，一般就是你本地启动了玩玩儿的?，没人生产用单机模式</li>\n<li><strong>普通集群模式</strong>：<ul>\n<li>意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。</li>\n<li>你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作</li>\n</ul>\n</li>\n<li><strong>镜像集群模式</strong>：<ul>\n<li>这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</li>\n<li>这样的好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"Redis高可用\"><a href=\"#Redis高可用\" class=\"headerlink\" title=\"Redis高可用\"></a>Redis高可用</h2><p>Redis高可用集群一般是和支撑高并发的主从架构配合使用的</p>\n<p>前置知识：</p>\n<h5 id=\"quorum\"><a href=\"#quorum\" class=\"headerlink\" title=\"quorum\"></a>quorum</h5><p>quorum的值是手动设置的，每次做主备切换，需要 quorum 数量的哨兵认为主节点客观宕机(odown)</p>\n<blockquote>\n<p><code>quorum</code> 的值一般设置为 Sentinel 个数的<strong>二分之一加 1</strong>，例如 3 个 Sentinel 就设置为 2</p>\n</blockquote>\n<h5 id=\"majority\"><a href=\"#majority\" class=\"headerlink\" title=\"majority\"></a>majority</h5><p>进行主备切换时，选举出一个哨兵来做切换，这个哨兵需要 majority 的士兵的授权才能正式授权，<code>majority是哨兵数量 / 2 + 1</code></p>\n<blockquote>\n<p>当 quorum &lt; majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换</p>\n<p>但是如果 quorum &gt;= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。</p>\n</blockquote>\n<h4 id=\"哨兵的介绍\"><a href=\"#哨兵的介绍\" class=\"headerlink\" title=\"哨兵的介绍\"></a>哨兵的介绍</h4><p>sentinel，中文名是哨兵。哨兵是 Redis 集群架构中非常重要的一个组件，主要有以下功能：</p>\n<ul>\n<li><strong>集群监控</strong>：负责监控 Redis 主节点和 从节点 进程是否正常工作。</li>\n<li><strong>消息通知</strong>：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>\n<li><strong>故障转移</strong>：如果 master node 挂掉了，会自动转移到 slave node 上。</li>\n<li><strong>配置中心</strong>：如果故障转移发生了，通知 client 客户端新的 master 地址。</li>\n</ul>\n<p>哨兵用于实现 Redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。</p>\n<ul>\n<li>故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。</li>\n<li>即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。</li>\n</ul>\n<h4 id=\"哨兵模式工作原理\"><a href=\"#哨兵模式工作原理\" class=\"headerlink\" title=\"哨兵模式工作原理\"></a>哨兵模式工作原理</h4><ol>\n<li>每个 Sentinel 以每秒一次的频率向它所知的 Master，Slave 以及其他 Sentinel 节点发送一个 <code>PING</code> 命令；</li>\n<li>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过配置文件 <code>own-after-milliseconds</code> 选项所指定的值，则这个实例会被 Sentinel 标记为<strong>主观下线</strong>；</li>\n<li>如果一个 主节点 被标记为主观下线，那么正在监视这个 Master 的所有 Sentinel 要以每秒一次的频率确认主节点是否真的进入主观下线状态；</li>\n<li>当有<strong>足够数量的 Sentinel</strong>（大于等于配置文件指定的值）在<strong>指定的时间范围内确认</strong> Master 的确进入了主观下线状态，则 Master 会被标记为<strong>客观下线</strong>；</li>\n<li>如果 Master 处于 <strong>ODOWN 状态</strong>，则投票自动选出新的主节点。将剩余的从节点指向新的主节点继续进行数据复制；</li>\n<li>在正常情况下，每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 <code>INFO</code> 命令；当 Master 被 Sentinel 标记为客观下线时，Sentinel 向已下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次；</li>\n<li>若没有足够数量的 Sentinel 同意 Master 已经下线，Master 的客观下线状态就会被移除。若 Master 重新向 Sentinel 的 PING 命令返回有效回复，Master 的主观下线状态就会被移除。</li>\n</ol>\n<p>而哨兵之间是如何进行互相发现和交换信息的呢？</p>\n<h4 id=\"哨兵集群的自动发现机制\"><a href=\"#哨兵集群的自动发现机制\" class=\"headerlink\" title=\"哨兵集群的自动发现机制\"></a>哨兵集群的自动发现机制</h4><p>每隔2秒钟，每个哨兵都会往自己监控的某个 主从节点 对应的 <code>__sentinel__:hello</code> channel 里<strong>发送一个消息</strong>，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。</p>\n<p>每个哨兵也会去<strong>监听</strong>自己监控的每个 主从节点 对应的 <code>__sentinel__:hello</code> channel，然后去感知到同样在监听这个 节点 的其他哨兵的存在。</p>\n<p>每个哨兵还会跟其他哨兵交换对 <code>master</code> 的监控配置，互相进行监控配置的同步。</p>\n<h4 id=\"定时任务\"><a href=\"#定时任务\" class=\"headerlink\" title=\"定时任务\"></a>定时任务</h4><p>Sentinel 内部有 3 个定时任务，分别是：</p>\n<ul>\n<li>每 <strong>1</strong> 秒每个 Sentinel 对其他 Sentinel 和 Redis 节点执行 <code>PING</code> 操作（监控），这是一个<strong>心跳检测</strong>，是失败判定的依据。</li>\n<li>每 <strong>2</strong> 秒每个 Sentinel 通过 Master 节点的 channel 交换信息（Publish/Subscribe）；</li>\n<li>每 <strong>10</strong> 秒每个 Sentinel 会对 Master 和 Slave 执行INFO命令，这个任务主要达到两个目的：<ul>\n<li>发现 Slave 节点；</li>\n<li>确认主从关系。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"sdown-和-odown-转换机制\"><a href=\"#sdown-和-odown-转换机制\" class=\"headerlink\" title=\"sdown 和 odown 转换机制\"></a>sdown 和 odown 转换机制</h4><ul>\n<li>sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机</li>\n<li>odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机</li>\n</ul>\n<p>sdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 <code>is-master-down-after-milliseconds</code> 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。</p>\n<h4 id=\"slave-gt-master-选举算法\"><a href=\"#slave-gt-master-选举算法\" class=\"headerlink\" title=\"slave-&gt;master 选举算法\"></a>slave-&gt;master 选举算法</h4><p>如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：</p>\n<ul>\n<li>slave 优先级</li>\n<li>复制 offset</li>\n<li>run id</li>\n</ul>\n<p>如果一个 slave 跟 master 断开连接的时间已经超过了 <code>down-after-milliseconds</code> 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>接下来会对 slave 进行排序：</p>\n<ul>\n<li>按照 slave 优先级进行排序，slave priority 越低，优先级就越高</li>\n<li>如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高</li>\n<li>如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave</li>\n</ul>\n<h3 id=\"Redis-cluster\"><a href=\"#Redis-cluster\" class=\"headerlink\" title=\"Redis cluster\"></a>Redis cluster</h3><p>Redis cluster是Redis的另一种集群方案</p>\n<h4 id=\"Redis-cluster-介绍\"><a href=\"#Redis-cluster-介绍\" class=\"headerlink\" title=\"Redis cluster 介绍\"></a>Redis cluster 介绍</h4><ul>\n<li>自动将数据进行分片，每个 master 上放一部分数据</li>\n<li>提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的</li>\n<li>要开放两个端口号，比如一个是6379，另外一个就是 + 1W的端口号，比如16379</li>\n</ul>\n<h4 id=\"节点是如何进行通信\"><a href=\"#节点是如何进行通信\" class=\"headerlink\" title=\"节点是如何进行通信\"></a>节点是如何进行通信</h4><p>Redis 维护集群元数据采用另一个方式， <code>gossip</code> 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更</p>\n<blockquote>\n<p>gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后</p>\n</blockquote>\n<h4 id=\"gossip-协议\"><a href=\"#gossip-协议\" class=\"headerlink\" title=\"gossip 协议\"></a>gossip 协议</h4><p>gossip 协议包含多种消息，包含 <code>ping</code> , <code>pong</code> , <code>meet</code> , <code>fail</code> 等等。</p>\n<ul>\n<li>meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信</li>\n</ul>\n<p>其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群</p>\n<ul>\n<li>ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据</li>\n<li>pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新</li>\n<li>fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦</li>\n</ul>\n<h3 id=\"分布式寻址算法\"><a href=\"#分布式寻址算法\" class=\"headerlink\" title=\"分布式寻址算法\"></a>分布式寻址算法</h3><ul>\n<li>hash 算法（大量缓存重建）</li>\n<li>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）</li>\n<li>Redis cluster 的 hash slot 算法</li>\n</ul>\n<h4 id=\"hash-算法\"><a href=\"#hash-算法\" class=\"headerlink\" title=\"hash 算法\"></a>hash 算法</h4><p>来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致<strong>大部分的请求过来，全部无法拿到有效的缓存</strong>，导致大量的流量涌入数据库。</p>\n<h4 id=\"一致性-hash-算法\"><a href=\"#一致性-hash-算法\" class=\"headerlink\" title=\"一致性 hash 算法\"></a>一致性 hash 算法</h4><p>一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。</p>\n<p>来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环<strong>顺时针“行走”</strong>，遇到的第一个 master 节点就是 key 所在位置。</p>\n<p>在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。</p>\n<p>然而，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成<strong>缓存热点</strong>的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。</p>\n<h4 id=\"Redis-cluster-的-hash-slot-算法\"><a href=\"#Redis-cluster-的-hash-slot-算法\" class=\"headerlink\" title=\"Redis cluster 的 hash slot 算法\"></a>Redis cluster 的 hash slot 算法</h4><p>Redis cluster 有固定的 <code>16384</code> 个 hash slot，对每个 <code>key</code> 计算 <code>CRC16</code> 值，然后对 <code>16384</code> 取模，可以获取 key 对应的 hash slot。</p>\n<p>Redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 <code>hash tag</code> 来实现。</p>\n<p>任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器</p>\n<h3 id=\"Redis-cluster-的高可用与主备切换原理\"><a href=\"#Redis-cluster-的高可用与主备切换原理\" class=\"headerlink\" title=\"Redis cluster 的高可用与主备切换原理\"></a>Redis cluster 的高可用与主备切换原理</h3><p>Redis cluster 的高可用的原理，几乎跟哨兵是类似的。</p>\n<h4 id=\"判断节点宕机\"><a href=\"#判断节点宕机\" class=\"headerlink\" title=\"判断节点宕机\"></a>判断节点宕机</h4><p>如果一个节点认为另外一个节点宕机，那么就是 <code>pfail</code> ，<strong>主观宕机</strong>。如果多个节点都认为另外一个节点宕机了，那么就是 <code>fail</code> ，<strong>客观宕机</strong>，跟哨兵的原理几乎一样，sdown，odown。</p>\n<p>在 <code>cluster-node-timeout</code> 内，某个节点一直没有返回 <code>pong</code> ，那么就被认为 <code>pfail</code> 。</p>\n<p>如果一个节点认为某个节点 <code>pfail</code> 了，那么会在 <code>gossip ping</code> 消息中， <code>ping</code> 给其他节点，如果<strong>超过半数</strong>的节点都认为 <code>pfail</code> 了，那么就会变成 <code>fail</code> 。</p>\n<h4 id=\"从节点过滤\"><a href=\"#从节点过滤\" class=\"headerlink\" title=\"从节点过滤\"></a>从节点过滤</h4><p>对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。</p>\n<p>检查每个 slave node 与 master node 断开连接的时间，如果超过了 <code>cluster-node-timeout * cluster-slave-validity-factor</code> ，那么就<strong>没有资格</strong>切换成 <code>master</code> 。</p>\n<h4 id=\"从节点选举\"><a href=\"#从节点选举\" class=\"headerlink\" title=\"从节点选举\"></a>从节点选举</h4><p>每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。</p>\n<p>所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node <code>（N/2 + 1）</code> 都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。</p>\n<p>从节点执行主备切换，从节点切换为主节点。</p>\n<h4 id=\"与哨兵比较\"><a href=\"#与哨兵比较\" class=\"headerlink\" title=\"与哨兵比较\"></a>与哨兵比较</h4><p>整个流程跟哨兵相比，非常类似，所以说，Redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。</p>\n","feature":null,"text":"不同中间件的高可用架构RabbitMQ高可用 RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现 RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。 单机模式，就是 ...","link":"","photos":[],"count_time":{"symbolsCount":"6.3k","symbolsTime":"6 mins."},"categories":[],"tags":[{"name":"系统设计","slug":"系统设计","count":2,"path":"api/tags/系统设计.json"},{"name":"高可用","slug":"高可用","count":1,"path":"api/tags/高可用.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%8D%E5%90%8C%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">不同中间件的高可用架构</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#RabbitMQ%E9%AB%98%E5%8F%AF%E7%94%A8\"><span class=\"toc-text\">RabbitMQ高可用</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Redis%E9%AB%98%E5%8F%AF%E7%94%A8\"><span class=\"toc-text\">Redis高可用</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#quorum\"><span class=\"toc-text\">quorum</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#majority\"><span class=\"toc-text\">majority</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%93%A8%E5%85%B5%E7%9A%84%E4%BB%8B%E7%BB%8D\"><span class=\"toc-text\">哨兵的介绍</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">哨兵模式工作原理</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E7%9A%84%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0%E6%9C%BA%E5%88%B6\"><span class=\"toc-text\">哨兵集群的自动发现机制</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1\"><span class=\"toc-text\">定时任务</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#sdown-%E5%92%8C-odown-%E8%BD%AC%E6%8D%A2%E6%9C%BA%E5%88%B6\"><span class=\"toc-text\">sdown 和 odown 转换机制</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#slave-gt-master-%E9%80%89%E4%B8%BE%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">slave-&gt;master 选举算法</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Redis-cluster\"><span class=\"toc-text\">Redis cluster</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Redis-cluster-%E4%BB%8B%E7%BB%8D\"><span class=\"toc-text\">Redis cluster 介绍</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%8A%82%E7%82%B9%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E9%80%9A%E4%BF%A1\"><span class=\"toc-text\">节点是如何进行通信</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#gossip-%E5%8D%8F%E8%AE%AE\"><span class=\"toc-text\">gossip 协议</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%88%86%E5%B8%83%E5%BC%8F%E5%AF%BB%E5%9D%80%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">分布式寻址算法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#hash-%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">hash 算法</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%B8%80%E8%87%B4%E6%80%A7-hash-%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">一致性 hash 算法</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Redis-cluster-%E7%9A%84-hash-slot-%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">Redis cluster 的 hash slot 算法</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Redis-cluster-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">Redis cluster 的高可用与主备切换原理</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%88%A4%E6%96%AD%E8%8A%82%E7%82%B9%E5%AE%95%E6%9C%BA\"><span class=\"toc-text\">判断节点宕机</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%BB%8E%E8%8A%82%E7%82%B9%E8%BF%87%E6%BB%A4\"><span class=\"toc-text\">从节点过滤</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%BB%8E%E8%8A%82%E7%82%B9%E9%80%89%E4%B8%BE\"><span class=\"toc-text\">从节点选举</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%B8%8E%E5%93%A8%E5%85%B5%E6%AF%94%E8%BE%83\"><span class=\"toc-text\">与哨兵比较</span></a></li></ol></li></ol></li></ol></li></ol>","author":{"name":"谢华客","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"记录一些笔记和心情的地方","socials":{"github":"https://github.com/stephentse9527","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Synchronized关键字底层原理","uid":"e70e2ff17ca94471876ef71091a97a2a","slug":"Synchronized关键字底层原理","date":"2021-05-03T20:50:19.000Z","updated":"2022-09-15T14:22:17.536Z","comments":true,"path":"api/articles/Synchronized关键字底层原理.json","keywords":null,"cover":[],"text":"Synchronized 关键字底层原理其实在 jdk1.6 之前的 synchronized 锁都是重量级锁，从 jdk1.6 开始对锁进行了优化，加入了从无锁-偏向锁-轻量级锁-自旋-重量级锁的升级流程，锁的状态都保存在对象的对象头中，所以需要了解Java对象头 理解Java...","link":"","photos":[],"count_time":{"symbolsCount":"4.4k","symbolsTime":"4 mins."},"categories":[],"tags":[{"name":"Java","slug":"Java","count":7,"path":"api/tags/Java.json"},{"name":"多线程","slug":"多线程","count":3,"path":"api/tags/多线程.json"},{"name":"底层原理","slug":"底层原理","count":4,"path":"api/tags/底层原理.json"}],"author":{"name":"谢华客","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"记录一些笔记和心情的地方","socials":{"github":"https://github.com/stephentse9527","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"操作系统之IO多路复用详解","uid":"6cd30b54600ff936f0e357293094df28","slug":"操作系统之IO多路复用详解","date":"2021-05-03T20:44:59.000Z","updated":"2022-09-15T14:22:17.560Z","comments":true,"path":"api/articles/操作系统之IO多路复用详解.json","keywords":null,"cover":null,"text":"用户空间与内核空间操作系统为了保证内核安全，将内存空间分为两部分：用户空间和内核空间，用户的程序都运行在用户空间上，而对于管理系统的进程，内存，设备，文件等操作，都只能由运行在内核空间的核心进程来进行 文件描述符fd文件描述符（File descriptor）是一个用于表述指向文...","link":"","photos":[],"count_time":{"symbolsCount":"2.6k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","count":4,"path":"api/tags/计算机基础.json"},{"name":"操作系统","slug":"操作系统","count":3,"path":"api/tags/操作系统.json"}],"author":{"name":"谢华客","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"记录一些笔记和心情的地方","socials":{"github":"https://github.com/stephentse9527","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}